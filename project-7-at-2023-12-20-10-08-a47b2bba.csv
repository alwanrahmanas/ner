"annotation_id","annotator","content","created_at","id","label","lead_time","updated_at"
1,"1","Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Pembangunan Sistem Informasi Desa Cinta Statistik 
(Desa Cantik) Berbasis Web 
Studi kasus: Desa Kepurun, Kecamatan Manisrenggo, Kabupaten 
Klaten 

Dwi Joko Purnomo (221910685, 4SI1) 
Dosen Pembimbing: Firdaus M.B.A. 

Ringkasan— Salah satu langkah yang dilakukan Badan Pusat 
Statistik  (BPS)  untuk  mewujudkan  Satu  Data  Indonesia  (SDI) 
adalah  melalui  program  Desa  Cinta  Statistik  (Desa  Cantik). 
Program  Desa  Cantik  memiliki  tujuan  utama  yaitu  untuk 
mendukung  upaya  pengentasan  kemiskinan.  BPS  Kabupaten 
Klaten  mengajukan  Desa  Kepurun  sebagai  desa  pelopor  yang 
akan  dilibatkan  dalam  program  Desa  Cantik.  Pada  Desa 
Kepurun,  pemanfaatan  data  kependudukan  dinilai  belum 
optimal. Hal ini dikarenakan, kurangnya pemahaman mengenai 
ilmu statistik oleh pemerintah setempat. Berdasarkan wawancara 
dengan Kepala Desa Kepurun, pemanfaatan data kependudukan 
akan  lebih  optimal  dengan  adanya  sebuah  sistem  informasi.  
Penelitian ini bertujuan untuk membangun sistem informasi Desa 
Cinta Statistik berbasis website. Metode perancangan sistem yang 
digunakan adalah Systems Development Life Cycle (SDLC) dengan 
model waterfall. Berdasarkan hasil pengujian Blackbox dan survei 
SUS diperoleh bahwa fitur utama sistem dapat berfungsi dengan 
baik dan dapat diterima oleh pengguna. 

Kata Kunci— Desa Cantik, Sistem Informasi, Website 

I.  LATAR BELAKANG 

Badan  Pusat  Statistik 

(BPS)  merupakan  Lembaga 
Pemerintah  Non  Kementerian  (LPNK)  yang  bertanggung 
jawab  langsung  kepada  Presiden.  Berdasarkan  peraturan 
statistic yang tercantum dalam UU Statistik No.16 tahun 1997, 
BPS  memberikan  panduan  berkaitan  dengan  pelaksanaan 
kegiatan statistik dengan tujuan untuk meningkatkan kontribusi 
dan  apresiasi  masyarakat  terhadap  statistik,  memperluas 
pengembangan Sistem Statistik Nasional (SSN), dan ikut serta 
dalam upaya pembangunan nasional.  

Berdasarkan Perpres No. 39 tahun 2019 tentang Satu Data 
Indonesia  (SDI),  disebutkan  bahwa  tujuan  SDI  adalah  untuk 
mengatur pengelolaan data baik yang dihasilkan oleh instansi 
pusat maupun instansi daerah dalam mendukung perencanaan, 
pelaksanaan, evaluasi, dan pengendalian pembangunan. Selain 
mengatur  pengelolaan  data,  pengaturan  SDI  juga  bertujuan 
untuk menyediakan data yang akurat, mutakhir, terpadu, dapat 
dipertanggungjawabkan serta mudah diakses. Salah satu upaya 
BPS  untuk  mewujudkan  SDI  adalah  dengan  menyusun 
program Desa Cinta Statistik (Desa Cantik). 

Program Desa Cantik adalah program yang bertujuan untuk 
meningkatkan  pemahaman,  kesadaran,  dan  peran  aktif 
perangkat desa/kelurahan dan masyarakat dalam melaksanakan 
kegiatan  statistic.  Hal  ini  dilakukan  dengan  memperhatikan 
standar pengelolaan data  statistik untuk menjaga kualitas dan 
keterbandingan indikator statistik. Selain itu, program ini juga 
bertujuan untuk mengoptimalkan penggunaan dan pemanfaatan 

data  statistik  agar  program  pembangunan  di  desa/kelurahan 
dapat  tepat  sasaran  dan  membentuk  agen  statistik  di  tingkat 
desa/kelurahan.  Tujuan  utama  Program  Desa  Cantik  adalah 
mendukung upaya pengentasan kemiskinan. 

Berdasarkan UU No. 6 Tahun 2014 tentang Desa, sebuah 
desa merupakan desa dan desa adat atau yang disebut dengan 
lain,  selanjutnya  disebut  desa,  adalah  kesatuan 
nama 
masyarakat  hukum  yang  memiliki  batas  wilayah  yang 
berwenang 
urusan 
pemerintahan,  kepentingan  masyarakat  setempat  berdasarkan 
Prakarsa  masyarakat,  hak  asal-usul,  dan/atau  hak  tradisional 
yang diakui dan dihormati dalam sistem pemerintahan Negara 
Kesatuan Republik Indonesia.  

untuk  mengatur 

dan  mengurus 

informasi  melalui  sistem 

Pasal  86  ayat  (1)  dan  (2)  dalam  UU  No.6  Tahun  2014 
tentang  Desa  menyatakan  bahwa  desa  berhak  memperoleh 
informasi  desa  yang 
akses 
dikembangkan oleh Pemerintah Daerah Kabupaten/Kota. Oleh 
karena  itu,  pemerintah  dan  pemerintah  daerah  memiliki 
kewajiban untuk mengembangkan sistem informasi desa serta 
membangun kawasan perdesaan.  

Klaten  adalah  salah  satu  kabupaten  di  Provinsi  Jawa 
Tengah. Kabupaten Klaten memiliki 391 desa dan 10 kelurahan 
[1].  Karakteristik  letak  desa/kelurahan  di  Kabupaten  Klaten 
sebagian  besar  berada  di  daerah  dataran.  Ada  400 
desa/kelurahan berada di daerah dataran dan 1 desa/kelurahan 
di lereng/puncak. Salah satu desa di Kabupaten Klaten adalah 
Desa Kepurun. Desa Kepurun merupakan desa yang diajukan 
oleh  BPS  Kabupaten  Klaten  untuk  Program  Desa  Cantik. 
Masyarakat  Desa  Kepurun  mayoritas  bekerja  di  bidang 
pertanian dan peternakan.  

data 

kependudukan 

Berdasarkan  hasil  wawancara  dengan  Kepala  Desa 
Kepurun, 
diperoleh  dari  Dinas 
Kependudukan  dan  Pencatatan  Sipil.  Untuk  mengakses 
informasi  mengenai  data  desa  di  Desa  Kepurun  harus 
mendatangi  kantor  kepala  desa  setempat  dan  membawa 
persyaratan  berupa  surat  permintaan  data.  Dikatakan  bahwa 
dengan  adanya  sistem  informasi  visualisasi  data,  proses 
perencanaan pembangunan desa akan lebih efektif. Sedangkan 
informasi tentang pemerintahan desa dan realisasi APBDes di 
Desa Kepurun belum dipublikasikan ke masyarakat umum.  

Berdasarkan  Undang-Undang  No.6  Tahun  2014  tentang 
Desa  dan  mempertimbangkan  manfaat  dari  perkembangan 
teknologi informasi. Pekerjaan perangkat desa di Desa Kepurun 
akan lebih efisien dan efektif apabila dilengkapi dengan sistem 
informasi  yang  memberikan  layanan  informasi  yang  mudah 

 1 / 8 

 
 
 
 
diakses,  cepat  sehingga  dapat  membantu  proses  perencanaan 
pembangunan desa. Dengan adanya sistem informasi berbasis 
website,  diharapkan  semua  pihak  yang  berkepentingan  dapat 
merasakan manfaat yang positif.  

II.  TUJUAN PENELITIAN 

Tujuan  penelitian  ini  secara  umum  yaitu  membangun 
sistem informasi Desa Cantik (Cinta Statistik) berbasis website. 
Selain  tujuan  umum  di  atas,  terdapat  beberapa  tujuan  khusus 
dalam penelitian ini sebagai berikut. 

1.  Membangun sistem  update  data  kependudukan yang 

lebih praktis, real-time, dan efisien. 

2.  Membangun  sistem  informasi  yang  dapat  mengelola 
data kependudukan dan dapat digunakan untuk media 
pelayanan publik.  

III. PENELITIAN TERKAIT 

Terdapat beberapa penelitian terkait dengan penelitian ini. 
Penelitian  yang  berjudul  “Penerapan  Sistem  Informasi  Profil 
Berbasis Web di Desa Bandarsari” yang dilakukan oleh Sucipto 
et  al.,  (2022)  bertujuan  untuk  mengimplementasikan  sistem 
informasi  profil  berbasis  web  yang  memudahkan  masyarakat 
dalam  mencari  dan  mengakses 
informasi  mengenai 
perkembangan  desa.  Metode  pengembangan  sistem  pada 
penelitian ini menggunakan bahasa pemrograman PHP dengan 
framework Laravel. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Metode  pengembangan  sistem  yang  digunakan  dalam 
penelitian  ini  adalah  System  Development  Life  Cycle 
(SDLC)  dengan  model  waterfall.  Metode  ini  cocok 
digunakan  untuk  pembangunan  sistem  yang  dapat 
diidentifikasi kebutuhannya dari awal.  Pada SDLC model 
waterfall,  pembangunan  sistem  dilakukan  secara  bertahap 
dan  terurut.  Tahapan  SDLC  model  waterfall  terdiri  dari 
Requirements 
Systems 
Development,  Systems 
Implementation  and  Coding, 
Testing,  Deployment,  dan  Systems  Operations  and 
Maintenance.  

and  Analysis, 

gathering 

C.  Metode Pengujian Sistem 

Pada tahap pengujian sistem, metode yang akan digunakan 
yaitu  Blackbox  testing  untuk  menguji  kesesuaian  antara 
input  dan  output  sistem.  Untuk  pengujian  kepuasan 
pengguna terhadap sistem yang telah dibuat menggunakan 
System  Usability  Scale  (SUS).  Kuesioner  SUS  akan 
dibagikan  melalui  google  form  kepada  pengguna  sistem 
yaitu  kepala  desa,  sekretaris  desa,  dan  masyarakat  Desa 
Kepurun. 

V.  KERANGKA PIKIR 

Hadi 

(2022)  melakukan  penelitian  yang  berjudul 
“Pembangunan Sistem Informasi Desa Cinta Statistik (DESA 
CANTIK)  Berbasis  Web  (Studi  kasus:  Nagari  Sijunjung, 
Kecamatan Sijunjung, Kabupaten Sijunjung)”. Hasil penelitian 
ini  adalah  sebuah  sistem  informasi  berbasis  web  yang  dapat 
digunakan perangkat desa sebagai sarana penyedia informasi di 
Nagari 
dengan 
mengidentifikasi masalah yang ada melalui wawancara dengan 
koordinator  fungsi  statistik  sosial  di  Badan  Pusat  Statistik 
Kabupaten Sijunjung. Pengembangan sistem dalam penelitian 
ini  menggunakan  metode  System  Development  Life  Cycle 
(SDLC).  Sistem  dievaluasi  menggunakan  uji  Blackbox  dan 
dilanjut dengan pengukuran System Usability Scale (SUS). 

Sijunjung. 

Penelitian 

dimulai 

ini 

A.  Metode Pengumpulan Data 

IV. METODE PENELITIAN  

A.1. Wawancara 

Wawancara  dilakukan  dengan  tujuan  memperoleh 
terkait  sistem  berjalan  dan 
informasi  dan  data 
kebutuhan sistem. Wawancara dilakukan secara tatap 
muka dengan Kepala Desa Kepurun. 

A.2. Studi Pustaka 

Studi pustaka pada penelitian ini dilakukan dengan 
cara  membaca  artikel,  publikasi,  buku  elektronik, 
peraturan  pemerintah  yang  berkaitan  dengan  topik 
penelitian. 
A.3. Kuesioner  

Kuesioner digunakan untuk mengumpulkan data 
pada tahap evaluasi sistem. Metode pengumpulan data 
yang  akan  digunakan  pada  tahap  evaluasi  adalah 
System  Usability  Scale  (SUS).  Kuesioner  akan 
dibagikan kepada pengguna sistem yaitu kepala desa, 
sekretaris desa, dan masyarakat Desa Kepurun melalui 
google form. 
B.  Metode Pembangunan Sistem 

Gambar 1. Kerangka Pikir 
Kerangka  pikir  penelitian  seperti  yang  dijelaskan  pada 
Gambar  1  berisi  gambaran  alur  pemikiran  peneliti  dalam 
melakukan  penelitian.  Diawali  dengan  menganalisis  proses 
bisnis yang berjalan saat ini ditemukan beberapa permasalahan 
yang  dirincikan  pada  Gambar  1.  Berdasarkan  permasalahan 
tersebut,  diajukan  sebuah  solusi  yaitu  membangun  sistem 
informasi Desa Cinta Statistik (Desa Cantik) berbasis website. 
Setelah  melakukan  implementasi  dari  solusi  kemudian  akan 

 2 / 8 

 
 
 
dilakukan  pengujian  sistem  yang  telah  dibangun  dengan 
menggunakan  black  box 
testing  serta  evaluasi  sistem 
menggunakan System Usability Scale (SUS).  
VI. HASIL DAN PEMBAHASAN 

A.  Proses Bisnis Berjalan 

Setelah  melakukan  wawancara  dengan  narasumber 

dihasilkan beberapa proses sistem berjalan sebagai berikut. 

A.1. Sistem berjalan update data kependudukan 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

memeriksa ketersediaan data di komputer desa. Jika data 
yang  diminta  oleh  pemohon  tersedia,  operator  akan 
mencetak  data  tersebut  dalam  bentuk  hard  file  dan 
menyerahkannya kepada pemohon. 

Pada  Gambar  2.  disajikan  dalam  bentuk  diagram 
berupa  salah  satu  proses  sistem  berjalan  yang  telah 
diidentifikasi  yaitu  proses  sistem  berjalan  update  data 
kependudukan  di  Desa  Kepurun.  Sistem  update  data 
kependudukan di Desa Kepurun dilakukan oleh sekretaris 
desa dengan mengumpulkan data dari dokumen-dokumen 
fisik  yang  dikumpulkan  pada  periode  waktu  tertentu. 
Dalam  kasus  dinamika  penduduk  seperti  kematian 
penduduk,  masyarakat  diwajibkan  mendatangi  kantor 
desa untuk meminta surat keterangan kematian dari desa. 
Setelah 
pengajuan 
administrasi  kependudukan  secara  mandiri  melalui 
aplikasi  SAKURA  Dukcapil  Kabupaten  Klaten. 
Sekretaris  desa  akan  mengumpulkan  data  kematian 
dengan  bantuan  excel.  Setelah  itu,  sekretaris  desa 
menghapus 
data 
kependudukan. 

itu,  masyarakat  melakukan 

penduduk 

terkait 

pada 

data 

Gambar 2. Proses sistem berjalan update data kependudukan 

A.2. Pelayanan publik 

Dalam  pelaksanaan  pelayanan  publik  di  Desa 
Kepurun, pemohon yang mempunyai kepentingan terkait 
permintaan  data  desa  harus  mendatangi  kantor  desa 
setempat  dengan  membawa  persyaratan  yaitu  surat 
permintaan  data.  Setelah  mendatangi  kantor  desa, 
pemohon  bisa  menuju  bagian  operator  desa  kemudian 
menyerahkan surat permintaan data. Operator desa yang 
bertugas  memeriksa  surat  permintaan  data  kemudian 

Gambar 3. Proses sistem berjalan pelayanan publik 

B.  Analisis Permasalahan 

Pada  proses  sistem  berjalan  saat  ini,  setelah  dilakukan 
analisis dan identifikasi terdapat beberapa permasalahan yang 
ditemukan. Permasalahan tersebut digambarkan pada Gambar 
4 dalam bentuk diagram fishbone. 

C.  Analisis Kebutuhan Sistem 

Gambar 4. Diagram fishbone 

Untuk  melakukan  analisis  kebutuhan  sistem,  digunakan 
analisis  PIECES  yang  membagi  kebutuhan  sistem  kedalam 
enam  komponen  yaitu  performance,  information,  economy, 
control, efficiency, dan service yang dapat dilihat pada Tabel I.. 
TABEL I 
ANALISIS PIECES SISTEM BERJALAN DAN SISTEM USULAN 
Analisis 
Performance 

Sistem Usulan 

-  Kegiatan 

Sistem Berjalan 
Sistem yang ada belum 
menjadikan 
dapat 
kegiatan  pengelolaan 
data 
kependudukan 
menjadi realtime. 

pengelolaan 
data  kependudukan  dapat 
dilakukan  secara  efisien 
dan realtime. 
realisasi 
Informasi 
APBDes  dan 
struktur 
organisasi  dapat  diakses 
dari mana saja. 

- 

Information 

Pengguna  data  perlu 
mendatangi 
kantor 
desa  untuk  mengakses 

Sistem  dapat  mempermudah 
pengguna  data  saat  mencari 
data  kependudukan  umum, 

 3 / 8 

 
 
 
 
 
 
 
Economy 
Control 

Efficency 

Service 

kependudukan 

data 
umum. 
- 
Hanya  perangkat  desa 
yang  berwenang  yang 
bisa  mengakses  data 
kependudukan. 
Pengelolaan 
dinamika 
dilakukan 
manual. 

data 
penduduk 
secara 

Proses  pengguna  data 
untuk dapat mengakses 
data terbilang lama. 

dan 

APBDes, 

realisasi 
struktur organisasi. 
- 
Pengguna 
dapat 
mengakses  informasi  sesuai 
role-nya. 

data 

Pengelolaan  data  dinamika 
penduduk  dapat  dilakukan 
melalui  halaman  admin  dan 
langsung  masuk  ke  data 
dinamika penduduk. 
- 

Proses  pengguna  data 
untuk  dapat  mengakses 
data terbilang cepat. 
Sistem  dapat  membantu 
desa 
perangkat 
mengelola 
data 
kependudukan,  realisasi 
APBDes,  dan  struktur 
organisasi. 

- 

D.  Arsitektur Sistem Usulan 

Pada penelitian ini sistem yang akan dibangun merupakan 
sistem  berbasis  web.  Web  dapat  diakses  oleh  pengguna 
yang  terhubung  dengan  server  web  melalui  jaringan 
internet.  Semua  data  yang  digunakan  dalam  proses  bisnis 
sistem disimpan di server basis data. 

E.  Rancangan Basis Data 

Gambar 5. Arsitektur sistem usulan 

Rancangan basis data terdiri dari entitas-entitas yang terkait 
dalam  sistem  seperti  entitas  penduduk,  imigrasi,  emigrasi, 
kelahiran, 
dan 
pemerintahan.  Rancangan  basis  data  digambarkan  dalam 
bentuk Entity Relationship Diagram seperti pada Gambar 6. 

activity_log, 

kematian, 

apbd, 

user, 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

F.  Use Case Diagram Sistem Usulan 

Gambar 6. Rancangan Basis Data 

1.  Use Case Diagram untuk Admin 

desa), 

admin 

pemerintahan, 

Dalam diagram use case sistem informasi desa cantik 
untuk admin, terdapat empat peran yaitu super admin 
(kepala 
admin 
kependudukan,  dan  admin  APBD.  Super  admin 
memiliki hak akses untuk mengelola data user dan log 
user.  Admin  pemerintahan  memiliki  hak  akses  untuk 
mengelola  data  pemerintahan.  Admin  penduduk 
memiliki  hak  akses  untuk  mengelola  data  penduduk 
dan  mengelola  data  dinamika  penduduk.  Dan  admin 
APBD  memiliki  hak  akses  untuk  mengelola  data 
APBD.  Berikut  adalah  diagram  use  case  yang 
menggambarkan keempat peran tersebut. 

 4 / 8 

 
 
 
 
 
 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Activity diagram adalah diagram yang menggambarkan 
alur kegiatan dan fungsi pada sistem yang telah dibangun. 
Terdapat dua bagian activity diagram dalam sistem ini. 
Berikut adalah activity diagram sistem untuk admin. 
1.  Activity Diagram Login 

Pada menu login, admin diharuskan memasukkan 
email dan password.  Setelah memasukkan  username 
dan  password  maka  akan  dilakukan  validasi  apakah 
username  dan  password  benar  atau  salah.  Jika 
username  dan  password  salah, maka akan diarahkan 
kembali  ke  halaman 
login.  Jika  username  dan 
password  benar,  maka  akan  dilakukan  validasi  akun 
admin.  Jika  akun  admin  pemerintahan,  maka  akan 
masuk  halaman  data  pemerintahan.  Jika  akun  admin 
kependudukan,  maka  akan  masuk  halaman  data 
penduduk. Jika akun admin APBD, maka akan masuk 
halaman  data  APBD.  Jika  akun  super  admin,  maka 
akan masuk halaman data user. 

Gambar 7. Use Case Diagram untuk Admin 

2.  Use Case Diagram untuk Masyarakat 

Dalam diagram use case sistem informasi desa cantik 
untuk  masyarakat,  terdapat  fitur  yang  dapat  diakses 
tanpa melakukan proses login. Pengguna dapat melihat 
struktur organisasi desa, statistik desa, dan mengunduh 
statistik yang tersedia. Berikut ini adalah diagram use 
case untuk masyarakat. 

Gambar 8. Use Case Diagram untuk Masyarakat 

G.  Activity Diagram Sistem Usulan 

Gambar 9. Activity Diagram Login 
2.  Activity Diagram Kelola Data Pemerintahan 
Admin  pemerintahan  dapat  mengakses  halaman 
pemerintahan. Langkah pertama admin yang memiliki hak 
akses  masuk  ke  halaman  pemerintahan.  Di  halaman 
pemerintahan menampilkan data perangkat desa yang sudah 
ditambahkan.  Untuk  melakukan 
dan 
penghapusan  data,  admin dapat  menekan  tombol  edit  dan 
hapus. Setelah menekan tombol  edit, admin merubah data 
perangkat desa terkait dan kemudian menekan tombol edit. 
Tombol tambah dapat digunakan untuk menambahkan data 
perangkat  desa.  Setelah  menekan  tombol  tambah,  admin 

perubahan 

 5 / 8 

 
 
 
 
 
dapat  mengisi  form  yang  tersedia  dan  menekan  tombol 
tambah. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Admin  APBD  dapat  mengakses  halaman  APBD. 
Langkah pertama admin yang memiliki hak akses masuk ke 
halaman  APBD.  Di  halaman  APBD  menampilkan  data 
APBD  yang  sudah  ditambahkan.  Untuk  melakukan 
perubahan,  admin  dapat  menekan  tombol  edit.  Setelah 
menekan  tombol  edit,  admin  dapat  merubah  data  APBD 
terkait dan kemudian menekan tombol edit. Tombol import 
dapat digunakan untuk menambahkan data APBD. Setelah 
menekan tombol import, admin dapat meng-upload file dan 
menekan tombol import. 

Gambar 10. Activity Diagram Kelola Data Pemerintahan 

3.  Activity Diagram Kelola Data Penduduk 

Admin kependudukan dapat mengakses halaman data 
penduduk.  Langkah  pertama  admin  yang  memiliki  hak 
akses masuk ke halaman data penduduk. Di halaman data 
penduduk  menampilkan  data  penduduk  yang  sudah 
ditambahkan.  Untuk  melakukan  perubahan,  admin  dapat 
menekan tombol edit. Setelah menekan tombol edit, admin 
merubah  data  penduduk  terkait  dan  kemudian  menekan 
tombol  edit.  Tombol  import  dapat  digunakan  untuk 
menambahkan data penduduk. Menu import digunakan saat 
pertama  kali  sistem  diimplementasikan.  Hal  ini  untuk 
memudahkan  admin  dalam  menginput  banyak  data 
penduduk sekaligus. Tombol emigrasi dan tombol kematian 
digunakan  untuk  mengatasi  kasus  dinamika  penduduk. 
Untuk mengunduh data penduduk dapat dilakukan dengan 
menekan  tombol  export  kemudian  data  akan  terunduh 
sesuai format yang dipilih. 

Gambar 12. Activity Diagram Kelola Data APBD 

5.  Activity Diagram Kelola Data User 

Gambar 11. Activity Diagram Kelola Data Penduduk 

4.  Activity Diagram Kelola Data APBD 

 6 / 8 

 
 
 
 
 
 
Gambar 13. Activity Diagram Kelola Data User 

3.  Activity Diagram Statistik 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Pengguna dapat melihat statistik desa dengan memilih 
menu  statistik.  Setelah  memilih  menu  statistik,  pengguna 
akan diarahkan ke  halaman  statistik.  Kemudian pengguna 
dapat  melihat  statistik  desa  yang  tersedia  dan  dapat 
mengunduhnya. 

Super  admin  dapat  mengakses  halaman  data  user. 
Langkah pertama admin yang memiliki hak akses masuk ke 
halaman data user. Di halaman data user menampilkan data 
data  user  yang  sudah  ditambahkan.  Untuk  melakukan 
perubahan,  admin  dapat  menekan  tombol  edit.  Setelah 
menekan  tombol  edit,  admin  dapat  merubah  data  user 
terkait dan kemudian menekan tombol edit. Tombol tambah 
dapat  digunakan  untuk  menambahkan  user.  Setelah 
menekan  tombol  tambah,  admin  dapat  mengisi  form  dan 
menekan tombol tambah. 

Berikut  adalah  activity  diagram 

sistem  untuk 

masyarakat. 
1.  Activity Diagram Landing Page 

Untuk  mengakses  halaman  landing  page,  pengguna 
tidak perlu melakukan login. Pengguna dapat mengakses 
website melalui internet dan halaman landing page adalah 
halaman pertama yang terbuka. 

Gambar 14. Activity Diagram Landing Page 

2.  Activity Diagram Pemerintahan 

Pengguna dapat melihat informasi mengenai struktur 
organisasi  desa  dengan  memilih  menu  pemerintahan. 
Setelah  memilih  menu  pemerintahan,  pengguna  akan 
diarahkan ke halaman struktur organisasi. 

H.  Implementasi Sistem 

Gambar 16. Activity Diagram Statistik 

Implementasi Antarmuka Landing Page 

1. 
Ketika membuka halaman web akan muncul halaman 
landing page sebagai berikut. 

Gambar 17. Implementasi Antarmuka Landingpage 

Implementasi Antarmuka Pemerintahan 

2. 
Pada halaman pemerintahan, pengguna dapat melihat 
sturktur organisasi desa. 

Gambar 15. Activity Diagram Pemerintahan 

Gambar 18. Implementasi Antarmuka Pemerintahan 

 7 / 8 

 
 
 
 
 
 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Implementasi Antarmuka Statistik 

3. 
Di halaman statistik, terdapat sidebar pilihan jenis 
statistik. Setelah memilih pilihan jenis statistik yang dicari 
akan terlihat grafik dan tabel tentang statistik tersebut dan 
dapat mengunduhnya. 

Implementasi Antarmuka Data User 

7. 
Halaman ini hanya dapat diakses oleh admin dengan role 
super admin dimana di dalamnya terdapat daftar data user, 
menu tambah data, edit data, dan logout. 

Gambar 23. Implementasi Antarmuka Data User 

I.  Uji Coba dan Evaluasi 

Dalam  penelitian  ini,  uji  coba  dan  evaluasi  sistem 
menggunakan  blackbox testing  dan SUS. Dari hasil  black 
box  testing,  terlihat  bahwa    fungsi-fungsi  dalam  sistem 
berjalan sesuai dengan yang diharapkan. Berdasarkan hasil 
pengujian  SUS  menunjukkan  nilai  sebesar  75,5  sehingga 
sistem  ini  berada  pada  rentang  74-80,3  dengan  grade  B 
dimana  sistem  yang  dibangun  masuk  kategori  good  dan 
dapat diterima oleh pengguna. 

VII. 

PENUTUP 

Berdasarkan  penelitian  yang  telah  dilakukan,  terdapat 

beberapa kesimpulan yang dapat ditarik:  

1.  Telah  dibangun  sistem  informasi  Desa  Cinta  Statistik 
(Desa  Cantik)  berbasis  web  yang  dapat  membantu 
pekerjaan perangkat Desa Kepurun. 

2.  Telah  dibangun  sistem  informasi  Desa  Cinta  Statistik 
(Desa  Cantik)  berbasis  web  yang  memiliki  modul 
pengelolaan data kependudukan dan pelayanan publik. 
3.  Hasil  pengujian  dan  evaluasi  menunjukkan  bahwa 
sistem  informasi  berfungsi  sesuai  yang  diharapkan 
dalam  black-box  testing.  Evaluasi  SUS  menunjukkan  
skor  75,5,  menandakan  bahwa  secara  keseluruhan 
sistem informasi yang dibangun masuk grade B dimana 
sistem  yang  dibangun  masuk kategori  good  dan  dapat 
diterima oleh pengguna. 

DAFTAR PUSTAKA 
[1]  PODES, STATISTIK POTENSI DESA KABUPATEN KLATEN 

2020. 

[2]  A. Sucipto et al., “PENERAPAN SISTEM INFORMASI PROFIL 

BERBASIS WEB DI DESA BANDARSARI,” Journal of 
Technology and Social for Community Service (JTSCS), vol. 3, pp. 
29–37, 2022. 

[3]  M. I. Hadi, “Pembangunan Sistem Informasi Desa Cinta Statistik 
(DESA CANTIK) Berbasis Web (Studi kasus: Nagari Sijunjung, 
Kecamatan Sijunjung, Kabupaten Sijunjung),” 2022.  

Gambar 19. Implementasi Antarmuka Statistik 

Implementasi Antarmuka Admin Pemerintahan 

4. 
Halaman ini dapat diakses oleh admin dengan role admin 
pemerintahan.  Pada  halaman 
ini  menampilkan  data 
perangkat desa, menu tambah data, search, dan logout.  

Gambar 20. Implementasi Antarmuka Landing Page 

Implementasi Antarmuka Data Penduduk 

5. 
Halaman ini dapat diakses oleh admin dengan role admin 
kependudukan.  Pada  halaman 
ini  menampilkan  data 
penduduk,  menu  import  data,  export  data,  search,  dan 
logout. 

Gambar 21. Implementasi Antarmuka Data Penduduk 
6. 
Implementasi Antarmuka Dashboard Admin APBD 
Halaman  ini  hanya  dapat diakses  oleh  admin  dengan role 
admin  APBD  dimana  di  dalamnya  terdapat  daftar  data 
APBD, menu import, dan logout. 

Gambar 22. Implementasi Antarmuka Admin APBD 

 8 / 8 

 
 
 
 
 
 
 
 
 
 
","2023-12-19T06:47:40.537139Z",221910685,"[{""start"":1066,""end"":1131,""text"":""membangun sistem informasi Desa\\nCinta Statistik berbasis website"",""labels"":[""Tujuan""]},{""start"":1182,""end"":1243,""text"":""Systems Development Life Cycle (SDLC) dengan\\nmodel waterfall"",""labels"":[""Metode""]},{""start"":1314,""end"":1394,""text"":""fitur utama sistem dapat berfungsi dengan\\nbaik dan dapat diterima oleh pengguna"",""labels"":[""Temuan""]},{""start"":5928,""end"":6004,""text"":"" membangun\\nsistem informasi Desa Cantik (Cinta Statistik) berbasis website"",""labels"":[""Tujuan""]},{""start"":7022,""end"":7088,""text"":""System Development Life Cycle\\n(SDLC) dengan model waterfall"",""labels"":[""Metode""]},{""start"":22803,""end"":22875,""text"":""sistem informasi Desa Cinta Statistik\\n(Desa Cantik) berbasis web"",""labels"":[""Temuan""]},{""start"":22955,""end"":23104,""text"":"" sistem informasi Desa Cinta Statistik\\n(Desa Cantik) berbasis web yang memiliki modul\\npengelolaan data kependudukan dan pelayanan publik"",""labels"":[""Temuan""]},{""start"":23164,""end"":23218,""text"":""sistem informasi berfungsi sesuai yang diharapkan"",""labels"":[""Temuan""]},{""start"":23330,""end"":23463,""text"":""sistem informasi yang dibangun masuk grade B dimana\\nsistem yang dibangun masuk kategori good dan dapat\\nditerima oleh pengguna"",""labels"":[""Temuan""]}]",272.476,"2023-12-19T06:47:40.537139Z"
2,"1","Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Peramalan Emisi Karbon Dioksida di Indonesia serta 
Analisi Faktor-Faktor yang Memengaruhinya 

Muhammad Daffa Taufiq Hadikara (221910705, 4SD2) 
Dosen Pembimbing: Nucke Widowati Kusumo Projo S.Si., M.Sc., Ph.D. 

Ringkasan—  CO2  memegang  perananan  penting  dalam 
perubahan  iklim  global.  Tujuan  dari  penelitian  ini  adalah 
meramalkan  emisi  CO2  di  Indonesia  dan  menganalisis  faktor-
faktor  yang  memengaruhinya.  Metode  ARIMA  dan  multilayer 
perceptron  digunakan  untuk  mendapatkan  metode  peramalan 
terbaik, serta analisis RLB digunakan untuk menganalisis faktor-
faktor yang berkontribusi terhadap perubahan emisi CO2. Hasil 
analisis menunjukkan bahwa emisi CO2 di Indonesia mengalami 
peningkatan  yang  cukup  signifikan  dalam  beberapa  dekade 
terakhir,  sejalan  dengan  pertumbuhan  ekonomi  dan  populasi. 
Faktor-faktor  yang  memengaruhi  secara  signifikan  terhadap 
emisi  CO2  di  Indonesia  meliputi  kepadatan  penduduk,  serta 
konsumsi  energi  fosil  dan  terbarukan,  namun  pertumbuhan 
ekonomi tidak memiliki dampak secara signifikan terhadap emisi 
CO2. Berdasarkan hasil peramalan, didapatkan jumlah emisi CO2 
di  Indonesia  sebesar 712  juta  ton/tahun. Jumlah  tersebut masih 
berada  di  bawah  target  pemerintah  yang  berada  di  sekitar  912 
juta  ton/tahun.  Dengan  menggunakan  model  peramalan  yang 
tepat,  penelitian  ini  dapat  membantu  pemangku  kepentingan 
untuk mengidentifikasi faktor-faktor yang berdampak signifikan 
terhadap emisi CO2 di Indonesia.  

Kata  Kunci—  Kebijakan,  Lingkungan,  Ekonomi,  ARIMA, 

Multilayer Perceptron, Regresi Linier Berganda.  

I.  LATAR BELAKANG 

Udara  memegang  peran  krusial  dalam  eksistensi  makhluk 
hidup,  terutama  manusia,  sebagai  salah  satu  elemen  penting 
bagi  kehidupan.  Manusia  bergantung  pada  udara  yang bersih 
sebagai  asupan  pernapasan.  Menurut  WHO  pada  tahun  2018 
terdapat  lebih  dari  90%  populasi  di  dunia  menghirup  udara 
dengan  tingkat  populasi  bahaya,  bahkan  3  miliar  orang  yang 
didominasi oleh wanita dan anak-anak masih menghirup asap 
yang  mematikan[1].  Hal  ini  diakibatkan  oleh  rendahnya 
kualitas  udara  yang  disebabkan  oleh  berbagai  aktivitas  yang 
dilakukan  manusia.  Diantara  sekian  banyak  polutan-polutan 
yang mencemari udara, gas karbon dioksida (CO2) merupakan 
polutan yang menyumbang emisi terbesar. 

Berdasarkan  laporan  IPCC  tahun  2023,  suhu  global  telah 
meningkat  sebesar  1,1  derajat  celcius  sejak  abad  ke-19  [2]. 
Pada KTT iklim PBB tahun 2021 di Glasgow, para pemimpin 
dunia berkomitmen untuk berada pada jalur yang akan menjaga 
kenaikan suhu global di bawah 1,5 derajat celcius [3]. Tetapi 
dengan  tingkat  emisi  saat  ini,  beberapa  ilmuwan  mengatakan 
bahwa kita mendekati jalur yang akan menyebabkan kenaikan 
3 derajat celcius pada akhir abad ini. Berdasarkan data IQAir 
tahun 2022, Indonesia berada di peringkat ke-26 negara paling 
berpolusi dari 131 negara [4].  

Sumber: IQAir 
Gambar  1.  Emisi  CO2  berdasarkan  Sumbernya  di  Indonesia, 
2019 

Berdasarkan  Kesepakatan  Paris  yang  telah  diratifikasi, 
Indonesia  menjadi  salah  satu  dari  195  negara  yang 
berkomitmen untuk mengurangi emisi gas rumah kaca hingga 
tahun  2030  sebesar  29  persen  dengan  usaha  sendiri  dan  41 
persen dengan dukungan Internasional [5]. 

ini 

jumlah  penduduk  diiringi  dengan 

Kerusakan  lingkungan  seperti  peningkatan  emisi  yang 
juga  disebabkan  karena  adanya 
terjadi  pada  saat 
peningkatan 
laju 
pertumbuhan  penduduk  yang  tinggi  dan  tidak  terkendali 
sehingga memberikan tekanan pada sumber daya alam. Selain 
itu,  penyebab  meningkatnya  emisi  CO2  dikarenakan 
penggunaan  energi  tanpa  memerhatikan  dampak  terhadap 
lingkungan. 

Indonesia memiliki potensi sumber daya energi terbarukan 
yang  sangat  tinggi  dan  beragam  hingga  tersebar  di  seluruh 
wilayah. Namun, potensi energi terbarukan ini belum diiringi 
dengan  pemanfaatan  yang  optimal.  Pengembangan  energi 
terbarukan  mendorong  adanya  transisi  energi  yang  ramah 
lingkungan serta mengurangi risiko tinggi terhadap lingkungan 
Pengembangan energi terbarukan di Indonesia mengacu pada 
Peraturan Pemerintah nomor 79 tahun 2014 tentang kebijakan 
energi nasional dan Peraturan Presiden nomor 22 tahun 2017 
tentang  rencana  umum  energi  nasional  yang  menyatakan 
bahwa  prioritas  pengembangan  energi  utama  adalah  energi 
terbarukan. 

Pembangunan  ekonomi  pada  saat  ini  tidak  lagi  berfokus 
pada  angka  pertumbuhan  ekonomi  yang  tinggi  melainkan 
mengacu  pada  suatu  arah  pembangunan  ekonomi  yang  baru, 
yaitu pembangunan ekonomi yang berkelanjutan. Pelaksanaan 
pembangunan berkelanjutan telah diperkuat oleh kesepakatan 
para pemimpin bangsa, antara lain dalam Deklarasi Rio pada 
KTT Bumi tahun 1992, Deklarasi Millenium PBB tahun 2000, 
dan  Deklarasi  Jogannesburg  pada  KTT  Bumi  tahun  2002. 
Pembangunan  ekonomi  berkelanjutan  bertujuan  untuk 
memenuhi  kebutuhan  dan  meningkatkan  kualitas  hidup 

 1 / 8 

 
 
 
 
 
 
 
 
manusia  dengan  tetap  memerhatikan  kehidupan  generasi 
mendatang. 

membuktikan  adanya  hipotesis  EKC  baik  pada  deforestasi 
maupun pada ketiga polutan tersebut. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Menyikapi  permasalahan  diatas,  maka  perlu  adanya 
komitmen yang kuat dalam mengatasi tingginya tingkat emisi 
CO2  di  Indonesia.  Upaya-upaya  yang  mulai  dilakukan  oleh 
negara-negara maju adalah dengan membuat kebijakan untuk 
mengurangi  penggunaan  bahan  bakar  fosil.  Namun,  rencana-
rencana  tersebut  perlu  adanya  persiapan  yang  matang  untuk 
memperkirakan  sejauh  mana 
implementasi  dan  upaya 
penanganan  emisi  CO2  akan  dilakukan,  sehingga  akan 
mengurangi  biaya  produksi  dan  mengurangi 
terjadinya 
kegagalan dalam pengimplementasiannya. Salah satu cara yang 
dapat dilakukan, yaitu dengan melakukan peramalan keadaan 
emisi CO2 untuk periode berikutnya dan menganalisis faktor-
faktor yang memengaruhinya. 

Penelitian 

ini  menggunakan  metode  ARIMA  dalam 
meramalkan  emisi  CO2.  Keterbatasan  dalam  model  ARIMA 
adalah  linearitas.  Korelasi  linier  diasumsikan  di  antara  nilai-
nilai  runtun  waktu  sebelumnya  sehingga  tidak  ada  pola  non-
linier  yang  dapat  ditangkap  oleh  model  ARIMA  [6].  Data 
runtun  waktu  yang  memiliki pola  non-linier  lebih  sulit untuk 
diramalkan  dengan  metode  ARIMA.  Untuk  mengatasi 
permasalahan tersebut, maka terdapat metode peramalan yang 
lainnya seperti ANN (Artificial Neural Network). 

ANN banyak digunakan untuk kasus regresi, klasifikasi, dan 
peramalan.  ANN  tidak  memerlukan  asumsi  yang  harus 
dipenuhi  dalam  pengolahan  data.  Keterbatasn  yang  dimiliki 
oleh ARIMA dapat diatasi oleh ANN agar pola data non-linier 
dapat  didefinisikan  dan  membuat  akurasi  dalam  melakukan 
peramalan  menjadi  lebih  baik.  ANN  akan  terbentuk  secara 
adaptif berdasarkan data yang telah ada [6]. Kelebihan utama 
dari model ANN adalah model tersebut dalam mendefinisikan 
pola  non-linier  dalam  data  runtun  waktu  sehingga  dapat 
memaksimalkan  akurasi  hasil  peramalan  emisi  CO2  yang 
memiliki pola data yang cenderung fluktuatif. 

II.  TUJUAN PENELITIAN 

Berdasarkan  identifikasi  masalah,  maka  ditetapkan  tujuan 

dari penelitian ini yaitu sebagai berikut: 
1.  Menggambarkan  kondisi  emisi  karbon  dioksida  di 
Indonesia serta faktor-faktor yang memengaruhinya 

2.  Mendapatkan  metode 

untuk 
memodelkan  peramalan  emisi  karbon  dioksida  di 
Indonesia 

peramalan 

terbaik 

3.  Menganalisis  faktor-faktor  yang  memengaruhi  emisi 

karbon dioksida di Indonesia 

III. PENELITIAN TERKAIT 

Penelitian  mengenai  hubungan/pengaruh  variabel  bebas 
yang  digunakan  dalam  penelitian  ini  terhadap  kerusakan 
lingkungan telah banyak dilakukan. Begitu pula teori tentang 
Environmental  Kuznets  Curve  (EKC)  di  beberapa  negara. 
Namun,  di  antara  penelitian-penelitian  tersebut  memberikan 
hasil yang berbeda-beda. 

Panayotou [7] menguji hipotesis EKC untuk deforestasi di 
68  negara  dan  untuk  SO2,  NO2,  dan  solid  particulate  matter 
(SPM)  di  55  negara,  yang  terdiri  dari  negara  yang  sedang 
berkembang  dan  maju.  Dengan  analisis  OLS,  penelitian  ini 

income,  high 

terhadap  emisi  CO2 

Leitão[8]  meneliti  hipotesis  EKC  dan  pengaruh  variabel 
lainnya 
terkait  dengan  fenomena 
globalisasi di Portugal, Spanyol, Yunani, dan Irlandia periode 
1980-2010. Beberapa variabel bebas yang diteliti di antaranya 
adalah  pertumbuhan  ekonomi,  konsumsi  energi,  dan  indeks 
globalisasi,  yang  dihipotesiskan  berpengaruh  positif  terhadap 
emisi  CO2.  Melalui  analisis  regresi  data  panel  dengan  model 
fixed effect, penelitian ini menyimpulkan bahwa terdapat kurva 
U  terbalik  antara  pertumbuhan  ekonomi  dan  emisi  CO2. 
Kemudian,  Mamun  et  al.[9]  ingin  melihat  hubungan  antara 
emisi CO2 dengan pertumbuhan ekonomi dan jumlah penduduk 
selama periode 1980-2009 di 136 negara yang dikelompokkan 
ke  dalam  lima  kelompok,  yaitu  low  income,  lower-middle 
income  negara 
income,  upper-middle 
organization  for  economic  co-operation  and  development 
(OECD),  dan  high  income  negara  non-OECD.  Penelitian  ini 
mendapati  eksistensi  EKC  di  semua  kelompok  high  income 
negara  non-OECD.  Penelitian  ini  juga  menyimpulkan  bahwa 
transformasi ekonomi menuju sektor jasa menyebabkan polusi 
yang lebih tinggi di negara  high income dan sedikit polusi di 
negara low dan middle income. Selain itu, adanya liberalisasi 
ekonomi  akan  mengurangi  emisi  CO2,  sedangkan  jumlah 
penduduk meningkatkan emisi CO2 di semua kelompok dalam 
jangka  panjang.  Ari  dan  Zeren[10]  menyatakan  bahwa  emisi 
CO2  akan  meningkat  pada  tahap  pertama  pertumbuhan 
ekonomi, tetapi setelah tingkat pendapatan tertentu emisi CO2 
terus 
akan  berkurang  sementara  pertumbuhan  ekonomi 
berlanjut. Sumargo dan Fadhilah [11] menganalisis hubungan 
antara  pertumbuhan  ekonomi  dan  kerusakan  lingkungan 
selama tahun 1965 sampai dengan 2014. Metode analisis yang 
digunakan  dalam  penelitian  ini  adalah  Error  Correction 
Mechanism (ECM). Hasil yang diperoleh menunjukkan bahwa 
pertumbuhan ekonomi berpengaruh signifikan positif terhadap 
emisi CO2. 

Sementara  itu,  Arouri  et  al.[12]  memperoleh  hasil  yang 
berbeda  terkait  dengan  EKC.  Penelitian  tersebut  meneliti 
hubungan antara emisi CO2, konsumsi energi, dan PDB di 12 
negara  Middle  East  and  North  African  periode  1981-2005 
dengan Error Correction Mechanism (ECM). Hasil penelitian 
ini menyimpulkan bahwa hipotesis EKC untuk CO2 di negara-
negara tersebut tidak terbukti. Untuk konsumsi energi, variabel 
ini  berpengaruh  positif  terhadap  emisi  CO2  pada  jangka 
panjang. 

Kemudian, penelitian lainnya juga dilakukan untuk melihat 
variabel-variabel lainnya yang berpengaruh terhadap emisi CO2. 
Alam  et  al.[13]  meneliti  hubungan  antara  variabel  bebas 
dengan CO2 di India. Hasil penelitian ini menunjukkan bahwa 
tidak ada hubungan jangka panjang antara pendapatan dengan 
emisi  CO2  di  India,  tetapi  terjadi  hubungan  antara  konsumsi 
energi  dengan  emisi  CO2.  Adeyuwi  dan  Awodumi[14] 
menganalisis hubungan antara energi terbarukan, pertumbuhan 
ekonomi, dan emisi CO2 di negara-negara Afrika tahun 1980-
2010. Metode analisis yang digunakan adalah model persamaan 
simultan  yang  diestimasi  dengan  metode  three  stage  least 
square 
(3SLS).  Hasil  penelitian  menunjukkan  adanya 
hubungan  simultan  yang  signifikan  antara  energi  terbarukan, 

 2 / 8 

 
 
pertumbuhan  ekonomi,  dan  emisi  CO2  di  lima  negara  Afrika 
Barat  (Nigeria,  Burnika  Faso,  Gambia,  Mali,  dan  Togo). 
Pabuçcu  dan  Bayramoğlu[15]menganalisis  bahwa  dengan 
menggunakan  metode  jaringan  syaraf  tiruan,  diperkirakan 
tingkat emisi gas rumah kaca di Turki sebesar 1244,13 mt pada 
tahun  2030.  Hal  tersebut  berada  di  atas  angka  yang  telah  di 
targetkan,  yaitu  929  mt.  Sehingga,  Turki  direkomendasikan 
untuk  menggunakan  energi  terbarukan  untuk  meningkatkan 
efisiensi energi. 

Untuk itu, berdasarkan penelitian-penelitian terdahulu yang 
telah  dipaparkan  maka  dalam  penelitian  ini  variabel-variabel 
yang akan digunakan adalah emisi CO2, kepadatan penduduk, 
pdb per kapita, konsumsi energi fosil (minyak, gas, batubara) 
dan  terbarukan  (air,  surya,  angin,  panas  bumi,  biomassa,  dan 
lainnya). 

Adapun  perbedaan  antara  penelitian  ini  dan  penelitian-
penelitian terdahulu yang telah dilakukan adalah penelitian ini 
berfokus pada negara Indonesia. Selain itu, periode penelitian 
yang  digunakan 
lebih  mutakhir  dibandingkan 
penelitian-penelitian  sebelumnya.  Metode  yang  digunakan 
pada  penelitian  ini  berbeda  dengan  metode  pada  penelitian 
sebelum-sebelumnya. 

terbilang 

IV. METODE PENELITIAN  

A.  Metode Pengumpulan Data 

Data  yang  digunakan  pada  penelitian  ini  merupakan  data 
sekunder  yang  diperoleh  dari  sumber  yang  berbeda,  yaitu 
Emissions  Database 
for  Global  Atmospheric  Research 
(EDGAR),  The  World  Bank,  dan  BP  Statistical  Review  of 
World Energy. 

Variabel  yang  digunakan  dalam  penelitian  ini  dipilih 
berdasarkan  determinan  kuat  emisi  gas  rumah  kaca  yang 
diperoleh dari penelitian  terkait. Variabel yang dipilih adalah 
emisi  CO2,  kepadatan  penduduk,  pdb  per  kapita,  konsumsi 
energi fosil (minyak, gas, batubara) dan terbarukan (air, angin, 
surya, panas bumi, biomassa, dan lainnya). 

Jenis Variabel 
Variabel 
Terikat 

Variabel Bebas 

TABEL I 
Variabel Penelitian 

Nama Variabel 

Emisi CO2 

Kepadatan Penduduk 
PDB per Kapita 
Konsumsi Minyak Bumi 
Konsumsi Gas Alam 
Konsumsi Batubara 
Konsumsi Energi Tenaga 
Air 
Konsumsi Energi Tenaga 
Surya 
Konsumsi Energi Tenaga 
Angin 
Konsumsi Energi Tenaga 
Panas Bumi, Biomassa, 
dan Lainnya 

Sumber Data 
Emissions Database for 
Global Atmosphetic 
(EDGAR) 

The World Bank 

BP Statistical Review of 
World Energy 

B.  Metode Analisis Data 

Analisis  yang  digunakan  dalam  penelitian  ini  adalah 
analisis deskriptif dan inferensia. Analisis deskriptif digunakan 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

dalam  penenlitian  ini  untuk  mempermudah  penafsiran  grafik 
dan tabel. Analisis ini digunakan untuk memberikan gambaran 
mengenai emisi CO2 dan variabel-variabel lain yang digunakan 
dalam  penelitian  ini.  Selain  itu,  analisis  deskriptif  mampu 
memberikan  pemahaman  awal  yang  dapat  digunakan  dalam 
analisis  lanjutan  yaitu  analisis  inferensia.  Metode  yang 
digunakan  untuk  analisis  inferensia  adalah  ARIMA  dan 
Multilayer Perceptron untuk peramalan emisi CO2 dan analisis 
regresi 
yang 
memengaruhinya. Proses tahapan ketiga metode tersebut dapat 
dilihat  pada  gambar  2.  Ketiga  metode  diolah  menggunakan 
Rstudio.  

untuk  menganalisis 

faktor-faktor 

Gambar  2.  Flowchart  Metode  ARIMA  (atas  kiri),  Multilayer  Perceptron 
(bawah), dan RLB (atas kanan) 
C.  Evaluasi Model 

dibandingkan 

Hasil  permodelan  forecasting  dari  metode  regresi  linier 
berganda, multilayer perceptron, dan support vector regression 
ini 
nilai 
kemudian 
menggunakan  beberapa  metode  evaluasi  yaitu  MAPE  (Mean 
Absolute Percentage Error) dan MAE (Mean Absolute Error). 
Untuk MAPE terdapat kriteria yaitu [16]: 
1.  Nilai MAPE dibawah 10%, maka peramalan sangat baik, 
2.  Nilai  MAPE  berada  dalam  rentang  10%-20%,  maka 

error.  Penelitian 

peramalan baik, 

3.  Nilai  MAPE  berada  dalam  rentang  20%-50%,  maka 

peramalan cukup baik, dan 

4.  Nilai MAPE lebih besar dari 50%, maka peramalan buruk. 

V.  KERANGKA PIKIR 

Dalam  menyusun  kebijakan  dan  pengambilan  keputusan, 
peramalan menjadi salah satu aspek yang penting. Untuk itu, 
perlu adanya suatu metode peramalan yang dapat meramalkan 
dengan  baik  nilai  suatu  variabel  di  masa  depan  agar  dapat 
membantu  menghasilkan  keputusan  yang 
tepat  dalam 
menghadapi suatu permasalahan. Selain itu, kita perlu melihat 
faktor-faktor  yang  memengaruhi  emisi  karbon  dioksida  di 
Indonesia.  Dengan  mengetahui 
tersebut, 
diharapkan  Indonesia  mampu  mengurangi  emisi  kabon 

faktor-faktor 

 3 / 8 

 
 
 
 
 
 
 
 
dioksida sesuai dengan perjanjian iklim paris. Sehingga, untuk 
menjawab  tujuan  dari  penelitian  ini  dibuatlah  kerangka  pikir 
penelitian seperti pada gambar 3. 

Gambar 3. Kerangka Pikir Penelitian 

VI. HASIL DAN PEMBAHASAN 

A.  Analisis Deskriptif 

Peningkatan  gas  rumah  kaca  sebagai  penyebab  fenomena 
perubahan iklim dan pemanasan global telah menjadi masalah 
yang  rumit  untuk  diatasi.  Gas  rumah  kaca  yang  paling 
bertanggung  jawab  terhadap  fenomena  ini  adalah  gas  CO2. 
Selain  itu,  gas  ini  berkontribusi  paling  besar  terhadap  gas 
rumah kaca global. Menurut U.S. Greenhouse Gas Emissions, 
CO2 menyumbang hingga 80% terhadap gas rumah kaca global 
di atmosfer pada tahun 2019. 

Limbah
7%

Kebakar
an Hutan
25%

Energi
34%

FOLU
25%

Pertania
IPPU
n
3%
6%

Sumber: BPS (diolah) 

Gambar 4. Emisi CO2 berdasarkan Sumbernya di Indonesia, 2019 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

35
30
25
20
15
10
5
0

a
t
i
p
a
k

r
e
p
2
O
C

i
s
i

m
e

)
n
o
t
(

0
7
9
1

4
7
9
1

8
7
9
1

2
8
9
1

6
8
9
1

0
9
9
1

4
9
9
1

8
9
9
1

2
0
0
2

6
0
0
2

0
1
0
2

4
1
0
2

8
1
0
2

Tahun

Sumber: EDGAR (diolah) 

Gambar 5. Perkembangan Emisi CO2 di Indonesia, 1970-2020 

Dilihat dari sumbernya, pada 2019 emisi CO2 di Indonesia 
paling banyak berasal dari energi (Gambar  4). Sementara itu, 
dari  perkembangannya  selama  periode  1970–2020,  secara 
umum emisi CO2 perkapita di Indonesia cenderung meningkat, 
meskipun  berfluktuatif  pada  periode  tertentu  serta  terjadi 
penurunan pada tahun 2013 dan 2020 (Gambar 5). 

Peningkatan  jumlah  penduduk  di  Indonesia  tentunya  akan 
berdampak pada meningkatnya kebutuhan hidup seperti lahan 
pemukiman,  kebutuhan  sumber  energi,  dan  barang  konsumsi 
lainnya. Pada akhirnya hal ini akan memberi tekanan terhadap 
lingkungan  ini  sendiri  akibat  eksploitasi  lingkungan  yang 
dilakukan. 

200

150

100

50

0

k
u
d
u
d
n
e
P
n
a
t
a
d
a
p
e
K

0
7
9
1

4
7
9
1

8
7
9
1

2
8
9
1

6
8
9
1

0
9
9
1

4
9
9
1

8
9
9
1

2
0
0
2

6
0
0
2

0
1
0
2

4
1
0
2

8
1
0
2

Tahun

Sumber: World Bank(diolah) 

Gambar 6. Perkembangan Kepadatan (juta/km2) di Indonesia, 1970-2020 

Indonesia  berjumlah  63-64 

Gambar  6  menggambarkan  perkembangan  kepadatan 
penduduk di Indonesia selama 51 tahun. Terlihat bahwa grafik 
tersebut  cenderung  meningkat.  Pada  1970,  kepadatan 
penduduk 
jiwa  per  km2. 
Peningkatan  jumlah  penduduk  di  Indonesia  tentunya  akan 
berdampak pada meningkatnya kebutuhan hidup seperti lahan 
pemukiman,  kebutuhan  sumber  energi,  dan  barang  konsumsi 
lainnya. Pada akhirnya hal ini akan memberi tekanan terhadap 
lingkungan  ini  sendiri  akibat  eksploitasi  lingkungan  yang 
dilakukan. 

 4 / 8 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Sumber: World Bank (diolah) 

Gambar  7.  Perkembangan  PDB  dan  Pertumbuhan  PDB  di  Indonesia,  1970-
2020 

Gambar  7 menggambarkan perkembangan PDB per kapita 
di  Indonesia.  PDB  per  kapita  di  Indonesia  sejak  tahun  1970 
hingga  2020  selalu  memiliki  nilai  pertumbuhan  yang  positif, 
kecuali 1998, 1999 dan 2020. Hal tersebut dikarenakan adanya 
krisis moneter pada tahun 1998-1999 dan pandemi COVID-19 
pada  tahun  2020.  Selain  itu,  perekonomian  Indonesia  pada 
tahun  2000  hingga  2019  terlihat  mulai  stabil.  Pertumbuhan 
PDB per kapita di Indonesia dalam rentang tahun 2000 hingga 
2019 berada di angka 3-7 persen. 

Aktivitas konsumsi energi atau penggunaan energi memiliki 
kaitan yang sangat erat dengan emisi CO2. Adanya peningkatan 
konsumsi  energi,  terutama  dari  aktivitas  pembakaran  atau 
penggunaan  bahan  bakar  fosil,  akan  berdampak  pada 
meningkatnya emisi CO2. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

dan  penambahan  stasiun  pengisian  bahan  bakar  gas  (SPBG). 
Adapun kegiatan aksi mitigasi dari sisi konsumsi adalah dengan 
efisiensi  konsumsi  energi  di  sektor  industri  dan  bangunan 
(komersial dan rumah tangga) [5]. 

Jika  dilihat  pada  gambar  8,  sejak  adanya  komitmen  pada 
tahun 2009, peningkatan konsumsi energi fosil terbesar terjadi 
pada  tahun  2018.  Adapun  penurunan  konsumsi  energi  fosil 
terbesar  terjadi  pada  tahun  2013  dan  2020.  Hal  ini  sejalan 
dengan  penurunan  emisi  yang  juga  terjadi  secara  signifikan 
pada  tahun  2013  dan  2020.  Penurunan  konsumsi  energi  fosil 
pada  tahun  2020  ini  sangat  erat  kaitannya  dengan  penurunan 
aktivitas ekonomi akibat adanya pandemi COVID-19. Adapun 
jika dilihat dari konsumsi energi terbarukan, sejak tahun 2017, 
penggunaan energi terbarukan justru mulai terlihat mengalami 
peningkatan  hingga  tahun  2020.  Hal  ini  menunjukkan  bahwa 
aksi untuk mitigasi CO2 dengan transisi ke energi terbarukan 
benar-benar sudah mulai diterapkan. 
B.  Permodelan dengan ARIMA 

fluktuatif 

Dalam peramalan emisi CO2 dengan menggunakan metode 
ARIMA,  syarat  awal  yang  harus  dipenuhi  adalah  data  harus 
stasioner. Berdasarkan gambar 4, dapat kita lihat bahwa emisi 
CO2  di  Indonesia  mempunyai  pola  yang  fluktuatif  dan  data 
yang 
stasioner.  Akibat 
ketidakpastian  ini,  peneliti  melakukan  pengujian  hipotesis 
untuk  menguji  apakah  data  emisi  CO2  stasioner  atau  tidak. 
Pengujian  dilakukan  dengan  menggunakan  uji  Augmented 
Dickey-Fuller  (ADF)  dengan  tingkat  signifikansi  sebesar  5 
persen. Hipotesis nol pengujian ini adalah 𝛿 = 0 atau data tidak 
stasioner. Berikut adalah tabulasi ringkasan hasil uji ADF: 

cenderung 

tidak 

TABEL II 
Hasil uji unit root dengan statistik ADF 
p-value 
0,7901 
0,01 

𝜏 hitung 
-1,4634 
-4,4186 

Variabel 
CO2 
D (CO2) 

Dari  hasil  pengujian  ADF,  terlihat  bahwa  data  hasil  first 
difference  telah  stasioner.  Sehingga,  permodelan  dilakukan 
dengan menggunakan model ARIMA (p,1,q). 

Selanjutnya,  mengidentifikasi  orde  AR,  MA,  dan  ARMA. 
Berdasarkan  hasil  dari  korelogram,  didapatkan  model  untuk 
ARIMA(0,1,1), 
peramalan 
ARIMA(1,1,1), ARIMA(0,1,2), ARIMA(2,1,0), ARIMA(2,1,1) 
ARIMA(1,1,2), dan ARIMA(2,1,2).  

ARIMA(1,1,0), 

adalah 

Sumber: EDGAR (diolah) 

Gambar 8. Perkembangan Konsumsi Energi Fosil dan Terbarukan di Indonesia, 
1970-2020 

Kebijakan  yang  dilakukan  dalam  konsumsi  energi,  sejalan 
dengan tujuan NDC untuk mengurangi emisi gas rumah kaca. 
Sebagaimana yang  diketahui bahwa  sektor  energi  merupakan 
sektor  yang  memiliki  kontribusi  paling  besar  dalam 
menyumbangkan  emisi  gas  rumah  kaca.  Untuk  mewujudkan 
target NDC, bentuk aksi mitigasi yang dilakukan pada sektor 
energi  dari  sisi  produksi  diantaranya  adalah  dengan 
menggunakan energi terbarukan untuk supply listrik, penerapan 
teknologi  bersih  (fuel  switching),  penambahan  jaringan  gas, 

Setelah mendapatkan kemungkinan model untuk peramalan, 
selanjutnya  mengestimasi  parameter  untuk  masing-masing 
kemungkinan model yang diajukan. Berdasarkan hasil estimasi 
dari masing-masing model diperoleh tabel III yang digunakan 
dalam menentukan model terbaik. 

TABEL III 
Estimasi Parameter Model ARIMA 

Model 

AIC 

AICc 

BIC 

ARIMA(1,1,0) 

ARIMA(0,1,1) 

ARIMA(1,1,1) 

ARIMA(0,1,2) 

448,98 

447,4 

449,29 

449,29 

449,23 

447,66 

449,81 

449,81 

452,8 

451,23 

455,02 

455,03 

 5 / 8 

 
 
 
 
 
 
 
 
ARIMA(2,1,0) 

ARIMA(2,1,1) 

ARIMA(1,1,2) 

ARIMA(1,1,0) with 
drift 
ARIMA(0,1,1) with 
drift 
ARIMA(1,1,1) with 
drift 
ARIMA(0,1,2) with 
drift 
ARIMA(2,1,0) with 
drift 
ARIMA(2,1,1) with 
drift 
ARIMA(1,1,2) with 
drift 

450,18 

451,28 

451,29 

450,7 

452,17 

452,17 

455,91 

458,93 

458,93 

440,61 

441,13 

446,35 

440,59 

441,11 

446,32 

440,87 

441,76 

448,52 

435,96 

436,84 

443,6 

434,15 

435,04 

441,8 

436,07 

437,44 

445,63 

437,95 

439,32 

447,51 

Pemilihan  model  terbaik  dapat  dilihat  melalui  AIC,  AICc, 
dan BIC terkecil. Berdasarkan hasil pada tabel 3, maka dapat 
diputuskan  bahwa  model  ARIMA(2,1,0)  with  drift  adalah 
model terbaik dalam melakukan permalan.  

Model terbaik yang dapat digunakan untuk peramalan adalah 
model  yang  memiliki  residual  yang  bersifat  white  noise.  Uji 
Ljung-Box  digunakan  untuk  melihat  apakah  residual  bersifat 
white noise atau tidak. Berdasarkan uji Ljung-Box, didapatkan 
bahwa  nilai  p-value  > 𝑎,  sehingga  dapat  disimpulkan  bahwa 
residual  bersifat  white  noise  dan  model  ARIMA(2,1,0)  with 
drift merupakan model terbaik. 

C.  Permodelan dengan Multilayer Perceptron 

Pemodelan  dengan  multilayer  perceptron  menggunakan 
bantuan software R dengan menggunakan fungsi  neuralnet () 
pada package neuralnet. 

Data dibagi menjadi 80% data latih dan 20% data uji. Data 
latih  digunakan  untuk  membentuk  model  dengan  fungsi 
aktivasi  logistic  dan  tangent  hyperbolicus,  serta  hidden  layer 
yang digunakan maksimal 2 layer dengan masing-masing layer 
berada dalam rentang 0-5 node, Setelah model terbentuk, model 
diuji menggunakan data uji dan didapatkan hasil pada tabel IV. 
Model terbaik yang dapat digunakan untuk peramalan adalah 
model yang memiliki nilai RMSE, MAE, dan MAPE terkecil. 

TABEL IV 
Hasil Model Multilayer Perceptron dengan Funsgi Aktivasi Logistic 

Hidden layer 
II 
I 
0 
1 
0 
2 
0 
3 
0 
4 
0 
5 
1 
1 
2 
1 
3 
1 
4 
1 
5 
1 
1 
2 
2 
2 
3 
2 
4 
2 
5 
2 

RMSE 

8,2733 
8,2741 
8,2726 
8,2725 
8,2743 
8,2791 
8,2773 
8,2755 
8,2756 
8,2765 
8,2803 
8,2725 
8,2761 
8,2776 
8,2766 

MAE 

6,855 
6,8633 
6,8604 
6,8581 
6,8647 
6,8821 
6,8731 
6,8646 
6,8654 
6,8573 
6,881 
6,8607 
6,8623 
6,8618 
6,8649 

MAPE 

6,5471 
6,5555 
6,5431 
6,5566 
6,5529 
6,5868 
6,5825 
6,5741 
6,5724 
6,55621 
6,5872 
6,5716 
6,5702 
6,5651 
6,5637 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

3 
3 
3 
3 
3 
4 
4 
4 
4 
4 
5 
5 
5 
5 
5 

1 
2 
3 
4 
5 
1 
2 
3 
4 
5 
1 
2 
3 
4 
5 

8,2788 
8,2776 
8,2807 
8,277 
8,2735 
8,2791 
8,277 
8,2716 
8,2773 
8,2776 
8,276 
8,2777 
8,2785 
8,2768 
8,2795 

6,8799 
6,8656 
6,8737 
6,8667 
6,8622 
6,8722 
6,8628 
6,8608 
6,8667 
6,8653 
8,8689 
6,8648 
6,8728 
6,8662 
6,8696 

6,5855 
6,5695 
6,572 
6,5692 
6,5554 
6,5705 
6,5599 
6,5557 
6,558 
6,5623 
6,5738 
6,5694 
6,5706 
6,5596 
6,5583 

Berdasarkan 

IV,  diperoleh  model  multilayer 
perceptron dengan fungsi aktivasi logistic terbaik adalah model 
dengan satu hidden layer yang memiliki jumlah neuron tiga. 

tabel 

TABEL V 
Hasil Model Multilayer Perceptron dengan Funsgi Aktivasi Tangent Hyperbolicus 

Hidden layer 
II 
I 
(2) 
(1) 
0 
1 
0 
2 
0 
3 
0 
4 
0 
5 
1 
1 
2 
1 
3 
1 
4 
1 
5 
1 
1 
2 
2 
2 
3 
2 
4 
2 
5 
2 
1 
3 
2 
3 
3 
3 
4 
3 
5 
3 
1 
4 
2 
4 
3 
4 
4 
4 
5 
4 
1 
5 
2 
5 
3 
5 
4 
5 
5 
5 

RMSE 

(3) 
8,271 
8,2731 
8,2721 
8,2713 
8,2681 
8,2743 
8,2745 
8,2734 
8,2647 
8,2656 
8,2728 
8,2723 
8,2736 
8,2699 
8,2589 
8,275 
8,2724 
8,2634 
8,2502 
8,269 
8,2682 
8,273 
8,2622 
8,2523 
8,2434 
8,2723 
8,267 
8,2559 
8,2416 
8,2656 

MAE 

(4) 
6,856 
6,8595 
6,8525 
6,8524 
6,851 
6,8594 
6,8524 
6,856 
6,8414 
6,8517 
6,8622 
6,8514 
6,8507 
6,8504 
6,8315 
6,8561 
6,85 
6,842 
6,8331 
6,8418 
6,8549 
6,8556 
6,8308 
6,8183 
6,8252 
6,8573 
6,8521 
6,8171 
6,8302 
6,8373 

MAPE 

(5) 
6,5433 
6,5404 
6,5414 
6,5284 
6,5308 
6,5503 
6,5348 
6,5399 
6,5159 
6,5285 
6,5482 
6,5448 
6,5372 
6,5267 
6,5072 
6,5412 
6,5388 
6,5211 
6,5139 
6,5026 
6,5314 
6,5399 
6,5005 
6,4836 
6,5058 
6,5434 
6,5338 
6,4791 
6,5142 
6,5112 

Berdasarkan tabel V, diperoleh model multilayer perceptron 
dengan  fungsi  aktivasi  tangent  hyperbolicus  terbaik  adalah 
model dengan dua hidden layer yang memiliki jumlah neuron 
lima dan tiga. 

TABEL VI 
Hasil Model Multilayer Perceptron dengan Funsgi Aktivasi Logistic 

Fungsi 
Aktivasi 

Hidden layer 

I 

II 

RMSE 

MAE 

MAPE 

 6 / 8 

 
 
 
 
 
 
 
 
 
Logistic 
Tangent 
Hyperbolicus 

3 

5 

0 

3 

8,2726 

8,2559 

6,8604 

6,8171 

6,5431 

6,4791 

Berdasarkan 

tabel  VI,  diperoleh  model  multilayer 
perceptron  terbaik  adalah  model  dengan  fungsi  tangent 
hyperbolicus. 

D.  Pemilihan Model Terbaik 

Setelah  melakukan  pemodelan  dengan  menggunakan 
ARIMA  dan  multilayer  perceptron,  penting  dilakukan 
perbandingan  hasil  peramalan  yang  didapat  dari  metode-
metode ini untuk menunjukkan metode mana yang memberikan 
akurasi terbaik. 

No 

1 

2 

TABEL VII 
Hasil Model Multilayer Perceptron dengan Funsgi Aktivasi Logistic 

Metode 

RMSE  MAE  MAPE 

ARIMA(2,1,0) 
with drift 
MLP, 
aktivasi 
hyperbolicus, 
hidden  layer  5  dan 
3 

fungsi 
tangent 

16,904 

12,4255 

7,0065 

8,2559 

6,8171 

6,4791 

Tabel  7  menunjukkan  bahwa  metode  yang  menghasilkan 
RMSE,  MAE,  dan  MAPE  terkecil  adalah  metode  multilayer 
perceptron  dengan  fungsi  aktivasi  tangent  hyperbolicus  dan 
dua hidden layer yang memiliki node lima dan tiga. 

Gambar  9  menunjukkan  grafik  hasil  Peramalan  model 

terbaik untuk data emisi CO2. 

Gambar 9. Grafik Emisi CO2 di Indonesia Hasil Peramalan Terbaik 

E.  Analisis Faktor-Faktor yang Memengaruhi 

Uji Asumsi Klasik 

TABEL VIII 
Hasil Pengujian Asumsi Klasik 

Statistik Uji 

𝑝 − 𝑣𝑎𝑙𝑢𝑒 

Data Asli 

Statistik 
Uji 
Transformasi 

𝑝 − 𝑣𝑎𝑙𝑢𝑒 

Normalitas 
Homoskedastisitas 
Non-autokorelasi 
Non-
multikolinieritas 

0,98415 
2,3049 
1,2206 
- 

0,7238 
0,9857 
7,787e-05 
> 10 

0,97047 
4,7774 
2,1764 
- 

0,2418 
0,8533 
0,6696 
< 10 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Berdasarkan  hasil  pengolahan  data  pada  tabel  VIII,  hasil 
output pada tabel menunjukkan bahwa data emisi CO2 terdapat 
pelanggaran  pada  non-autokorelasi  dan  non-multikolinieritas. 
Karena  ada  asumsi  klasik  yang  terlanggar,  maka  dilakukan 
transformasi  data.  Berdasarkan  hasil  pengolahan  pada  tabel 
VIII,  hasil  output  pada  tabel  menunjukkan  bahwa  data  yang 
telah dilakukan transformasi sudah memenuhi seluruh asumsi 
klasik. 

Secara  simultan,  hasil  uji  Fisher  menunjukkan  bahwa  p-
value lebih kecil daripada tingkat signifikansi yang digunakan. 
Berdasarkan  hasil  tersebut,  maka  keputusan  yang  diperoleh 
adalah  tolak  H0,  sehingga  dapat  disimpulkan  bahwa  dengan 
tingkat  kepercayaan  95%,  minimal  ada  satu  variabel  yang 
berpengaruh terhadap CO2. Selain itu, nilai R2 byang dihasilkan 
dalam model ini sebesar 0,7602. Hal ini menunjukkan bahwa 
variabel  bebas  mampu  menjelaskan  variasi  variabel  terikat 
sebesar 76,02% dan 23,98% dijelaskan oleh variabel lain yang 
tidak dimasukkan dalam model. 

Hasil  pengujian  parsial  menggunakan  uji  t,  menunjukkan 
bahwa dari 9 variabel bebas yang digunakan hanya terdapat 4 
variabel  yang  berpengaruh  signifikan,  yaitu  kepadatan 
penduduk,  konsumsi  minyak,  batubara,  dan  tenaga  air, 
sedangkan sisanya tidak berpengaruh secara signifikan. 

Hasil analisis regresi menunjukkan bahwa konsumsi minyak 
dan batubara berpengaruh positif dan signifikan, sedangkan gas 
tidak  signifikan.  Selain  itu,  konsumsi  tenaga  air  berpengaruh 
negatif dan signifikan, sedangkan tenaga surya tidak signifikan. 
Konsumsi energi angin dan panas bumi berpengaruh positif dan 
tidak signifikan, hal ini dikarenakan penggunaan energi angin 
dan panas bumi masih sangat jarang digunakan di Indonesia. 
Kepadatan  penduduk  berpengaruh  positif  dan  signifikan, 
sedangan  PDB  berpengaruh  negarif  dan  tidak  signifikan.  Hal 
tersebut  sesuai  dengan penelitian  terdahulu yang  menyatakan 
bahwa PDB tidak berpengaruh signifikan terhadap emisi CO2 
dan tidak berpengaruh terhadap jangka panjang. 

VII. 

PENUTUP 

Berdasarkan  hasil  dan  pembahasan  pada  bab  sebelumnya, 

maka diperoleh kesimpulan sebagai berikut: 
1.  Emisi  CO2  dan  faktor-faktor  yang  memengaruhinya 
cenderung mengalami peningkatan dari tahun 1970-2020.  
2.  Model peramalan emisi CO2 adalah multilayer perceptron. 
Hasil  peramalan  menunjukkan  bahwa  pada  tahun  2030, 
jumlah emisi CO2 sebesar 721,5427 juta ton/tahun. Hal ini 
masih berada di bawah target pemerintah Indonesia, yaitu 
920 juta ton/tahun. 

3.  Berdasarkan hasil analisis, kepadatan penduduk, konsumsi 
minyak,  dan  konsumsi  batubara  secara  signifikan 
berpengaruh  positif  terhadap  emisi  CO2  per  kapita. 
Sedangkan,  konsumsi 
tenaga  air  secara  signifikan 
berpengatuh negatif. 

Berdasarkan kesimpulan yang telah dipaparkan, saran yang 

dapat diberikan penelitian ini adalah sebagai betikut. 
1.  Konsumsi energi terbarukan (air, surya, panas bumi, angin, 
dan 
lain-lain)  memainkan  peranan  penting  dalam 
mengurangi  emisi  CO2  di  Indonesia.  Oleh  karena  itu, 

 7 / 8 

 
 
 
 
 
 
 
 
 
 
pemerintah 

perlu  merancang 

ekonomi  yang 
untuk  mewujudkan  pembangunan 
berkelanjutan, 
dan 
menerapkan  kebijakan  serta memberikan  dukungan yang 
efektif  untuk  mempromosikan  investasi  dalam  teknologi 
rendah karbon (energi terbarukan). Pemerintah hendaknya 
juga  meningkatkan  pasokan  sumber  energi  terbarukan 
dalam pasokan energi di Indonesia. 

2.  Dalam  membuat 

ekonomi, 

kebijakan 

pertumbuhan 

pembangunan 

untuk 
peningkatan 
pemerintah 
hendaknya mengutamakan pertimbangan dampak terhadap 
pertumbuhan 
lingkungan 
disamping  mewujudkan 
lebih 
cara 
ekonomi  yang 
mengoptimalkan  penerapan  analisis  mengenai  dampak 
lingkungan dalam kegiatan pembangunan. 

lebih  besar  dengan 

3.  Untuk  penelitian  selanjutnya,  dapat  mempertimbangkan 
pengaruh  variabel  ekonomi  maupun  sosial  lainnya  yang 
memiliki  kaitan  dengan  emisi  CO2  di  Indonesia  seperti 
keterbukaan perdagangan, jumlah wisatawan, dan variabel 
lainnya.  Selain  itu,  diperlukan  metode  lainnya  dalam 
meramalkan emisi CO2 supaya mendapatkan metode yang 
lebih  baik  dalam  meramalkan  emisi  CO2,  sehingga 
kebijakan yang akan dibuat lebih sesuai. 

[1] 
[2] 

[3] 

[4] 

[5] 

[6] 

[7] 

[8] 

[9] 

[10] 

[11] 

[12] 

[13] 

DAFTAR PUSTAKA 
WHO, “World Health Statistics,” 2018. 
IPCC, “Urgent climate action can secure a liveable future for all,” 
INTERLAKEN, 2023. [Online]. Available: www.ipcc.ch 
UN Climate Change, “COP26 THE GLASGOW CLIMATE 
PACT,” Glasgow, 2021. 
IQAir, “Negara dan Wilayah Paling Berpolusi di Dunia (Data 
Historis 2018-2022),” https://www.iqair.com/, 2022. 
Direktorat Jenderal Pengendalian Perubahan Iklim, “Kontribusi 
Penurunan Emisi GRK Nasional menuju NDC 2030,” 
https://ditjenppi.menlhk.go.id/, 2017. 
G. P. Zhang, “Time Series Forecasting Using a Hybrid ARIMA and 
Neural Network Model,” 2003. [Online]. Available: 
www.elsevier.com/locate/neucom 
Todor. Panayotou, Empirical Tests and Policy Analysis of 
Environmental Degradation at Different Stages of Economic 
Development. International Labour Office, 1993. 
N. C. Leitão, “The Environmental Kuznets curve and Globalization: 
The Empirical Evidence for Portugal, Spain, Greece and Ireland,” 
2013. [Online]. Available: http://aessweb.com/journal-
detail.php?id=5049 
M. Al Mamun, K. Sohag, M. A. Hannan Mia, G. Salah Uddin, and 
I. Ozturk, “Regional Differences in the Dynamic Linkage between 
CO2 Emissions, Sectoral Output and Economic Growth,” 
Renewable and Sustainable Energy Reviews, vol. 38. Elsevier Ltd, 
pp. 1–11, 2014. doi: 10.1016/j.rser.2014.05.091. 
A. Gör AyĢe ARI and A. Gör Fatma ZEREN, “CO2 Emisyonu ve 
Ekonomik Büyüme: Panel Veri Analizi,” 2011. 
B. Sumargo and E. Fadlilah, “Detection of Pseudo Economic 
Growth Towards Environmental Damage in Indonesia Using Error 
Correction Model,” in IOP Conference Series: Materials Science 
and Engineering, Institute of Physics Publishing, Jul. 2019. doi: 
10.1088/1757-899X/546/2/022029. 
M. E. H. Arouri, A. Ben Youssef, H. M’henni, and C. Rault, 
“Energy Consumption, Economic Growth and CO2 Emissions in 
Middle East and North African countries,” Energy Policy, vol. 45, 
pp. 342–349, Jun. 2012, doi: 10.1016/j.enpol.2012.02.042. 
M. J. Alam, I. A. Begum, J. Buysse, S. Rahman, and G. Van 
Huylenbroeck, “Dynamic Modeling of Causal Relationship between 
Energy Consumption, CO2 Emissions and Economic Growth in 
India,” Renewable and Sustainable Energy Reviews, vol. 15, no. 6. 
Elsevier Ltd, pp. 3243–3251, 2011. doi: 10.1016/j.rser.2011.04.029. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

[14] 

[15] 

[16] 

A. O. Adewuyi and O. B. Awodumi, “Biomass energy 
consumption, economic growth and carbon emissions: Fresh 
evidence from West Africa using a simultaneous equation model,” 
Energy, vol. 119, pp. 453–471, 2017, doi: 
10.1016/j.energy.2016.12.059. 
H. Pabuçcu and T. Bayramoğlu, “EMISSIONS FORECAST WITH 
NEURAL NETWORKS WITH: THE CASE OF TURKEY,” Gazi 
Üniversitesi İktisadi ve İdari Bilimler Fakültesi Dergisi, vol. 18, no. 
3, pp. 762–778, 2016. 
P. C. Chang, Y. W. Wang, and C. H. Liu, “The development of a 
weighted evolving fuzzy neural network for PCB sales forecasting,” 
Expert Syst Appl, vol. 32, no. 1, pp. 86–96, Jan. 2007, doi: 
10.1016/j.eswa.2005.11.021. 

 8 / 8 

 
 
  
","2023-12-19T07:50:23.908494Z",221910705,"[{""start"":505,""end"":539,""text"":""ARIMA dan multilayer\\nperceptron"",""labels"":[""Metode""]},{""start"":746,""end"":851,""text"":""emisi CO2 di Indonesia mengalami\\npeningkatan yang cukup signifikan dalam beberapa dekade\\nterakhir"",""labels"":[""Temuan""]},{""start"":1200,""end"":1272,""text"":""didapatkan jumlah emisi CO2\\ndi Indonesia sebesar 712 juta ton\/tahun"",""labels"":[""Temuan""]},{""start"":6192,""end"":6205,""text"":"""",""labels"":[""Metode""]},{""start"":6674,""end"":6705,""text"":"""",""labels"":[""Metode""]},{""start"":32307,""end"":32361,""text"":"""",""labels"":[""Temuan""]},{""start"":32364,""end"":32470,""text"":"""",""labels"":[""Temuan""]},{""start"":400,""end"":437,""text"":""meramalkan emisi CO2 di Indonesia"",""labels"":[""Tujuan""]}]",3926.838,"2023-12-20T00:19:03.442909Z"
3,"1","  Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

Klasifikasi dan Prediksi Kelangsungan Hidup 
Penderita Kanker Hati 

Salwa Anisa Luthfi (221910715, 4SD1) 
Dosen Pembimbing: Robert Kurniawan, SST, M.Si 

Ringkasan— Penyakit kanker merupakan salah satu penyebab 
angka kematian yang tinggi di Indonesia dan diperkirakan akan 
terus  meningkat.  Salah  satu  jenis  kanker  yang  mematikan  dan 
sulit  disembuhkan  adalah  kanker  hati.  Meskipun  begitu,  tidak 
menutup  kemungkinan  bahwa  penderita  kanker  hati  akan 
sembuh. Tujuan umum dilakukannya penelitian ini adalah untuk 
melakukan klasifikasi dan prediksi kelangsungan hidup penderita 
kanker  hati  sedangkan  tujuan  khusus  dari  penelitian  ini  yaitu 
menguji  performa  algoritma  klasifikasi  dan  prediksi  serta 
mengetahui variabel-variabel mana yang berpengaruh signifikan. 
Pada  penelitian  ini  akan  digunakan  metode  iterative  random 
forest,  gradient  boosting,  dan  regresi  logistik.  Hasil  pengolahan 
data menunjukkan bahwa metode penanganan missing value yang 
digunakan  tidak  mempengaruhi  hasil  akurasi  atau  performa 
algoritma.  Algoritma  iterative  random  forest  yang  digunakan 
dalam penelitian ini memiliki akurasi sebesar 72,16%. Tidak jauh 
berbeda  dengan  random  forest,  algoritma  gradient  boosting 
memiliki  akurasi  sebesar  70,32%.  Sedangkan  metode  regresi 
logistik  memiliki  performa  yang  lebih  bagus  dengan  akurasi 
88,34%. 

Kata Kunci — random forest, gradient boosting, regresi logistik, 

klasifikasi, kanker hati 

I.  LATAR BELAKANG 

Organ  hati  atau  lever  merupakan  salah  satu  organ  vital 
manusia  yang  berperan  penting  dalam  sistem  metabolisme. 
Meskipun bukan organ utama dalam sistem ekskresi, lever juga 
memiliki  peran  penting  untuk  mendetoksifikasi  atau 
membersihkan  darah.  Kelainan  pada  fungsi  hati  dapat 
menyebabkan  berbagai  macam  penyakit,  seperti  sirosis  hati, 
hepatitis, dan kanker hati. Beberapa penyakit tertentu memiliki 
gejala  awal  yang  biasanya  tidak  disadari  atau  dirasakan  oleh 
penderita.  Penderita penyakit hati  baru merasakan gejala  saat 
penyakit  memasuki  tingkat  lanjut  atau  mendekati  fase  gagal 
organ (Centers of Disease Control and Prevention, 2022). 

Salah satu penyakit yang menyerang hati adalah kanker hati. 
Kanker  hati  merupakan  penyakit  mematikan  keempat  di 
Indonesia  (Global  Cancer  Observatory,  2020).  Perkiraan 
jumlah  kasus  kanker  hati  pada  tahun  2020  di  Indonesia 
mencapai  21.392  kasus,  dimana 
Indonesia  menduduki 
peringkat  kedelapan  di  dunia  dan  peringkat  ketiga  di  Asia 
Tenggara. Sedangkan perkiraan jumlah kematian akibat kanker 
hati pada tahun 2020 di Indonesia mencapai 20.920 kematian, 
dimana  Indonesia  menempati  posisi  kedelapan  di  dunia  dan 
ketiga se-Asia Tenggara (Global Cancer Observatory, 2020). 
Kanker  hati  umumnya  disebabkan  oleh  infeksi  hepatitis 
kronis, namun ada beberapa faktor pemicu lain seperti obesitas, 
diabetes, dan konsumsi alkohol (Yamashita dan Kaneko, 2016). 
Meskipun  tidak  memiliki  gejala  spesifik  pada  tahap  awal 
kanker  hati,  penyakit  ini  dapat  dideteksi  jika  seseorang 
melakukan  pemeriksaan  darah  secara  rutin  untuk  memeriksa 
fungsi  hati  (Gleneagles,  2022).  Tentunya  hal  ini  merupakan 

salah  satu  tantangan  kesehatan  yang  besar  di  Indonesia. 
Pendeteksian dan pencegahan sejak dini merupakan titik awal 
penanganan tantangan kesehatan di Indonesia. 

Diagnosis  menurut  Thorndike  dan  Hagen  dalam  jurnalnya 
(2011)  diartikan  sebagai  upaya  atau  proses  menemukan 
kelemahan  atau  penyakit  apa  yang  dialami  seseorang  dengan 
melalui  pengujian  dan  studi  yang  seksama  mengenai  gejala-
gejalanya. Diagnosis penyakit lebih sering dibuat berdasarkan 
intuisi  dan  pengalaman  dokter  dibandingkan  berdasarkan 
pengetahuan yang tersembunyi dalam database. Hal ini dapat 
menyebabkan  kesalahan  diagnosis  dan  berpengaruh  terhadap 
pengobatan  yang  diberikan  kepada  pasien  (Denisko  & 
Hoffman, 2018). Data mining dan machine learning memiliki 
potensi  untuk  memberikan  informasi  dan  pengetahuan  yang 
dapat membantu meningkatkan kualitas hasil diagnosis secara 
signifikan  (Chen,  et.al.,  2021).  Aplikasi  data  mining  dan 
machine  learning  yang  sukses  memberikan  dorongan  kepada 
pihak-pihak 
informasi  dan 
pengetahuan tersebut  dalam  bidang kesehatan  (Lashari,  et.al., 
2018).  

terkait  untuk  memanfaatkan 

Ada  banyak  metode  dalam  machine 

learning  yang 
digunakan untuk menyelesaikan tugas klasifikasi. Dari metode 
yang  ada,  penulis  menggunakan  algoritma  iterative  random 
forest,  gradient  boosting, dan regresi logistik. Random  forest 
awalnya  diusulkan  oleh  Tin  Kam  Ho  yang  menyusun 
pengklasifikasi  berbasis  tree  dengan  akurasi  yang  dapat 
ditingkatkan.  Inti  dari  metode  yang  disebut  random  decision 
tree  ini  adalah  membangun  banyak  tree  pada  subspace  yang 
dipilih  secara  acak.  Metode  tersebut  diuji  menggunakan 
percobaan pengenalan angka tulisan tangan. Percobaan tersebut 
membuktikan  bahwa  metode  ini  memiliki  kompleksitas  yang 
lebih  konsisten  dan  menandakan  adanya  peluang  untuk 
perbaikan lebih lanjut (Ho, 1995).  

Random  forest  mulai  menjadi  perhatian  setelah  Breiman 
mempublikasikan  makalahnya  yang  berjudul  “Random 
Forests”  pada  tahun  2001.  Dalam  karyanya,  Breiman  sangat 
dipengaruhi  oleh  makalah  Amit  Y.  dan  Geman  D.  yang 
melakukan  pendekatan  dengan  memilih  fitur  yang  informatif 
dan membangun pengklasifikasi berbasis tree (Amit & Geman, 
1996).  Random  forest  adalah  algoritma  yang  efektif  dalam 
prediksi dan tidak overfit (Breiman, 2001). 

Prosedur berbasis tree lain seperti CART, Node Harvest, dan 
Forest  Garrote mengabaikan  kemungkinan  untuk mendeteksi 
relasi tingkat tinggi tanpa memengaruhi akurasi dalam prediksi. 
Random  forest  merupakan  alternatif  yang  menarik  untuk 
iterative 
digunakan.  Dalam  perkembangannya,  algoritma 
random  forest  (iRF)  diusulkan  untuk  mengatasi  keterbatasan 
dalam  algoritma  berbasis  tree.  Metode  iRF  mengembangkan 
random forest berbobot fitur untuk mengurangi dimensi secara 
halus dan menstabilkan hasil klasifikasi. (Basu, et.al., 2018). 

 1 / 6 

 
 
 
AdaBoost  adalah  algoritma  boosting  efektif  pertama  yang 
dasarnya  adalah  mengambil  sampel  dan  menggabungkannya 
secara  adaptif.  Algoritma  ini  dapat  mengatasi  masalah  pada 
algoritma  boosting  yang  sudah  ada  sebelumnya.  AdaBoost 
memiliki  sifat  tertentu  yang  membuat  algoritma  ini  lebih 
praktis  dan 
lebih  mudah  diimplementasikan  dibanding 
algoritma pendahulunya. (Freund and Schapire, 1996) 

LK_TreeBoost 

Dalam penelitiannya, Friedman menemukan bahwa metode 
AdaBoost bukan merupakan metode terbaik jika dibandingkan 
metode 
AdaBoost 
dan 
digeneralisasikan  ke  gradient  boosting  untuk  menangani 
kesalahan  dalam  algoritma  (Friedman,  2000).  Gradient 
boosting  merupakan  salah  satu 
teknik  yang  mampu 
menyesuaikan weak learner terhadap residual secara berulang-
ulang  sehingga  dapat  meningkatkan  performa  model  (Zhang, 
et.al., 2019). 

LogitBoost. 

Ada  pula  metode 

lain  yang  dapat  digunakan  untuk 
menyelesaikan  tugas  pengklasifikasian,  yaitu  regresi  logistik. 
Regresi logistik adalah suatu teknik statistika yang digunakan 
untuk  mengetahui  hubungan  antara  dua  variabel  atau  lebih. 
Analisis  regresi  logistik  merupakan  salah  satu  jenis  analisis 
regresi dimana variabel respon bersifat kategorik dan variabel 
prediktor  bersifat  kategorik  atau  numerik.  Apabila  variabel 
respon terdiri dari dua kategorik disebut regresi logistik biner, 
yaitu  variabel  respon  yang  terdiri  dari  dua  kategori  yaitu 
bernilai  1  jika  kejadian  sukses  dan  bernilai  0  jika  kejadian 
gagal. Sedangkan apabila variabel respon terdiri dari lebih dari 
dua kategori dan kategori tersebut merupakan tingkatan disebut 
regresi logistik ordinal (Hosmer & Lemeshow, 2000). 

II.  TUJUAN PENELITIAN 

ini 

secara 

Penelitian 

untuk 
mengklasifikasikan  dan  memprediksi  kelangsungan  hidup 
penderita kanker hati. Tujuan khusus dari penelitian ini antara 
lain: 

bertujuan 

umum 

1.  Menguji performa algoritma klasifikasi yang diterapkan 

pada data rekam medis penderita kanker hati, 

2.  Membandingkan  performa  algoritma  klasifikasi  yang 
diterapkan pada data rekam media penderita kanker hati, 
3.  Menemukan variabel-variabel yang berpengaruh secara 
terhadap  kelangsungan  hidup  penderita 

signifikan 
kanker hati. 

III. PENELITIAN TERKAIT 

Keles  dalam  penelitiannya  tahun  2019  memprediksi  dan 
mendeteksi kanker payudara menggunakan beberapa algoritma 
data mining dan membandingkannya. Algoritma random forest 
memiliki akurasi tertinggi yaitu sebesar 92.2%.  

lain 

lain 

Rabby  dan 

(2018)  dalam  penelitiannya 
mengevaluasi  kinerja  teknik  klasifikasi  data  mining  untuk 
prediksi  penyakit 
tertinggi 
menggunakan SVM yaitu sebesar 85.28%. 

jantung.  Diperoleh  akurasi 

Penelitian  Fiarni  dan  lain-lain  (2018)  memiliki  tujuan 
membangun  model  prediksi  untuk  tiga  penyakit  komplikasi 

  Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

diabetes  utama  dan  mengetahui 
fitur  signifikan  yang 
berkorelasi.  Algoritma  yang  digunakan  antara  lain  k-means, 
naïve  bayes,  dan  C4.5  decision  tree.  Algoritma  naïve  bayes 
memiliki performa yang lebih baik. 

Rady  dan  Anwar  (2019)  memperkirakan  stadium  penyakit 
ginjal.  Akurasi  tertinggi  diperoleh  menggunakan  algoritma 
Probabilistic Neural Network (PNN), yaitu sebesar 96.7%.  

Penelitian Verma dan lain-lain bertujuan mengklasifikasikan 
penyakit  kulit  dengan  menggunakan  metode  ensemble  yaitu 
menggabungan  beberapa  algoritma.  Akurasi  yang  didapat 
mencapai  98.64%.  Penelitian  yang  ada  belum  banyak 
membahas  tentang  seberapa  besar  suatu  variabel  independen 
berdampak pada variabel dependen. 

IV. METODE PENELITIAN  

Pada bagian ini akan dijelaskan bagaimana metode dan apa 
saja yang dilakukan untuk mencapai tujuan dari penelitian yang 
akan dilakukan. 

A.  Desain Penelitian 

Model  proses  yang  digunakan dalam  penelitian ini adalah 
CRISP-DM  (Cross-Industry  Standard  Process 
for  Data 
Mining).  CRISP-DM  memberikan  gambaran  tentang  siklus 
hidup  proyek  data  mining.  Terdapat  6  tahapan  dalam  model 
proses ini yaitu Business Understanding, Data Understanding, 
Data Preparation, Modelling, dan Evaluation. 

B.  Tahapan Business Understanding (Pemahaman Bisnis) 

Data yang digunakan untuk penelitian diekstraksi dari UCI 
Machine  Learning  Repository  (https://archive.ics.uci.edu/), 
yang  berisi  data  rekam  medis  asli  di  suatu  rumah  sakit 
tersebut,  peneliti 
universitas  di  Portugis.  Dari  dataset 
memutuskan  untuk  melakukan  klasifikasi  dan  memprediksi 
tingkat  kelangsungan  hidup  penderita  penyakit  kanker  hati 
menggunakan  tiga  metode  yaitu  random  forest,  gradient 
boosting,  dan  regresi  logistik.  Kemudian  ketiga  metode 
tersebut akan dibandingkan performanya. 

C.  Tahapan Data Understanding (Pemahaman Data) 

Pada  tahap  kedua,  peneliti  mencari  pemahaman  tentang 
dataset.  Dataset  ini  berisi  data  165  pasien  yang  didiagnosis 
menderita  kanker  hati.  Secara  keseluruhan,  data  yang  hilang 
sebesar  10,22%  dari  keseluruhan  dataset  dan  hanya  delapan 
pasien  yang  memiliki  data  yang  lengkap  (4,85%).  Variabel 
target adalah kelangsungan hidup penderita kanker hati dalam 
1  tahun  dan  dikodekan  sebagai  variabel  biner:  0  (die)  dan  1 
(live). Data yang digunakan memiliki 165 baris dan 50 kolom. 
Kolom  ini  terdiri  dari  49  atribut  independen  dan  1  atribut 
dependen yaitu class. 

D.  Tahapan  Data  Preparation  (Persiapan  atau  Pengolahan 

Data) 
Pada  tahapan  ini,  peneliti  melakukan  penanganan  missing 
values  dan  pembersihan  data,  dimana  data  yang  tidak  dapat 
digunakan  akan  dibuang.  Metode  penanganan  missing  value 
yang  digunakan  dalam  penelitian  ini  antara  lain  mean  dan 

 2 / 6 

 
 
 
 
 
 
 
 
 
mode,  median  dan  mode,  serta  KNN  Imputation.  Peneliti 
melakukan  persiapan  data  mencakup  semua  kegiatan  untuk 
menyusun  dataset  akhir  dari  data  mentah  awal  guna 
menyiapkan  data  untuk  diproses  lebih  lanjut.  Dataset  akhir 
kemudian  dibagi  ke  dalam  dua  bagian  yaitu  training  sebesar 
80% dan testing sebesar 20%. 

Gambar 1. Tahapan CRISP-DM 

E.  Tahapan Modelling (Pemodelan) 

Peneliti  membuat  model  berdasarkan  beberapa  teknik 
pemodelan  yang  berbeda.  Di  sini  peneliti  telah  memilih 
beberapa  algoritma,  di  antaranya  random  forest,  gradient 
boosting, dan regresi logistik. Setelah itu peneliti membagi data 
menjadi  dataset  pelatihan,  pengujian,  dan  validasi.  Hasil 
pengolahan  data  yang  didapatkan  langsung  dibandingkan 
dengan  algoritma  lain  agar  peneliti  dapat  menafsirkan  hasil 
model berdasarkan pengetahuan umum. 

F.  Iterative Random Forest 

forest 

Algoritma 

iterative  random 

(iRF)  merupakan 
pengembangan  dari Random  Forest  (RF).  Gagasan  mengenai 
RF bermula dengan menyusun pengklasifikasi berbasis pohon 
(Ho, 1995). Kemudian Leo Breiman mengembangkan gagasan 
tersebut  dan  menemukan  algoritma  yang  efektif  dan  tidak 
overfit, yaitu Random Forest (Breiman, 2001). RF merupakan 
alternatif yang digunakan untuk mengatasi keterbatasan dalam 
algoritma klasifikasi berbasis pohon (Basu, et.al., 2018). 

Algoritma  iRF  adalah  pendekatan  komputasi  yang  efisien 
untuk  mencari  interaksi  yang  tidak  diketahui  dalam  data 
berdimensi  tinggi  dengan  tiga  langkah.  Pertama,  melakukan 
pembobotan ulang secara adaptif dan berulang untuk mengatur 
RF  yang  tepat.  Kedua,  mengubah  aturan  keputusan  peta  RF 
berbobot  fitur  yang  berupa  kontinu  atau  kategorikal  menjadi 
fitur  biner.  Terakhir,  langkah  bagging  akan  menilai  stabilitas 
interaksi. (Basu, et.al., 2018). 

G.  Gradient Boosting 

Gradient  boosting  merupakan  algoritma  machine  learning 
yang  dikembangkan  dari  algoritma  boosting.  AdaBoost 

  Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

merupakan  algoritma  boosting  pertama  yang  efektif  dengan 
dasar mengambil sampel dan menggunakannya secara adaptif 
(Freund  &  Schapire,  1996).  Algoritma  ini  memiliki  sifat 
tertentu  yang  membuat  algoritma  ini  lebih  praktis  dan  lebih 
mudah diimplementasikan dibanding algoritma perdahulunya. 
(Freund & Schapire, 1996).  

Meskipun  begitu  AdaBoost  bukan  merupakan  metode 
terbaik jika dibandingkan dengan algoritma LK_TreeBoost dan 
LogitBoost. Kemudian AdaBoost digeneralisasikan ke gradient 
boosting  untuk  menangani  kekurangan  algoritma  tersebut 
(Friedman,  2001).  Gradient  boosting  merupakan  salah  satu 
teknik  yang  mampu  menyesuaikan  weak  learner  terhadap 
residual  secara  berulang-ulang  sehingga  dapat  meningkatkan 
performa model (Zhang, et.al., 2019). 

H.  Regresi Logistik 

Metode  regresi  logistik  yang  digunakan  adalah  regresi 
logistik biner karena variabel target dataset memiliki dua nilai 
yaitu 0 (die) dan 1 (live). Persamaan dari regresi logistik biner 
adalah sebagai berikut: 

𝑔(𝑥𝑖) = 𝛽0 + ∑ 𝛽𝑗𝑋𝑗𝑖

𝑝
𝑗=1

            (1) 

Menurut  Hosmer  dan  Lemeshow  (2000),  model  regresi 
logistik  juga  sensitif  dengan  adanya  kolinieritas  seperti  pada 
regresi linier. Kolinieritas yang tinggi mengindikasikan adanya 
ketergantungan  yang  tinggi  antara  dua  atau  lebih  variabel 
prediktor.  Multikolinieritas  merupakan  adanya  korelasi  pada 
beberapa  atau  semua  variabel  prediktor.  Gujarati  (2004), 
menjelaskan  bahwa  multikolinieritas  dapat  diketahui  dengan 
melihat nilai Variance Inflation Factor (VIF). Nilai VIF dapat 
dihitung dengan formula sebagai berikut: 

𝑉𝐼𝐹𝑗 =

1
1−𝑅𝑗

2  

(2) 

Dimana 𝑅𝑗

2 merupakan koefisien determinasi dari auxiliary 
2  berbanding  lurus  dengan  VIF,  semakin 
regression.  Nilai 𝑅𝑗
2 maka  semakin  besar  nilai  VIF.  Jika  nilai  VIF 
besar  nilai 𝑅𝑗
bernilai lebih dari 10, maka sudah dipastikan bahwa pada data 
tersebut terdapat multikolinearitas. 

Sebelum  dilakukan  perumusan  model,  perlu  dilakukan 
beberapa pengujian diantaranya uji simultan, uji parsial, dan uji 
kesesuaian model. Uji simultan dan uji parsial dilakukan untuk 
mengetahui variabel prediktor yang berpengaruh secara nyata 
terhadap variabel respon. 

I.  Tahapan Evaluation (Evaluasi) 

Setelah dilakukan pengolahan dengan melakukan pelatihan 
dan pengujian terhadap data, hasilnya dari 49 atribut yang ada, 
beberapa  dari  variabel  tersebut  memiliki  pengaruh  terhadap 
variabel  target.  Fase  evaluasi  akan  menguji  model  dengan 
menggunakan  Performance  Evaluation  dan  10-fold  Cross 
Validation. 

Untuk mengetahui performa, ada beberapa hal yang diukur 
dalam  performance 
evaluation  diantaranya  accuracy, 
precission,  dan  recall.  Accuracy  atau  akurasi  digunakan 

 3 / 6 

 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

mengonsumsi alkohol lebih dari 100 gram alkohol maka tidak 
dapat bertahan hidup. 

mengukur rasio prediksi yang benar, baik itu positif dan negatif 
pada keseluruhan data. Precission atau presisi digunakan untuk 
mengukur  rasio  prediksi  benar  positif  dibandingkan  dengan 
keseluruhan  hasil  yang  diprediksi  positif.  Recall  atau 
sensitifitas  digunakan  untuk  mengukur  rasio  prediksi  benar 
positif  dibandingkan  dengan  keseluruhan  data  yang  benar 
positif. 

Gambar  3.  Visualisasi  konsumsi  alkohol  oleh  penderita 

kanker hati. 

Visualisasi penggunaan rokok per bungkus setiap tahun oleh 
penderita  kanker  hati  menunjukkan  bahwa  penderita  kanker 
hati  yang  mengonsumsi  kurang  dari  20  bungkus  rokok  per 
tahun  dapat  bertahan hidup.  Sedangkan penderita  kanker hati 
yang  mengonsumsi  rokok  lebih  dari  20  bungkus  rokok  per 
tahunnya tidak dapat bertahan hidup. 

Gambar 2. Alur penelitian 

Cross  validation  adalah  sebuah  teknik  yang  digunakan 
dalam pengevaluasian model dengan cara membagi sampel dari 
dataset  asli  ke  dalam  training  set  untuk  melatih  model  dan 
testing set untuk melakukan evaluasi terhadap model tersebut.  

J.  Tahapan Deployment (Penyebaran) 

Pada  tahapan  ini  akan  didapat  pengetahuan  dari  hasil 
evaluasi yang ada, dimana akan menjadi sebuah penjelasan dari 
tujuan yang disebutkan. 

Gambar  4.  Visualisasi  konsumsi  rokok  per  tahun  oleh 

penderita kanker hati. 

B.  Analisis Regresi Logistik 

V.  HASIL DAN PEMBAHASAN 

Pengujian  signifikansi  parameter  menggunakan  hipotesis 

Pada  bab  ini,  akan  menjelaskan  hasil  dari  pengujian 
beberapa  metode  yang  digunakan  dalam  pengklasifikasian 
dataset. 

A.  Explanatory Data Analysis 

Pada  bagian  ini  peneliti  ingin  menampilkan  bagaimana 
penggunaan  alkohol  setiap  hari  pada  pasien  penderita  kanker 
hati  yang  bertahan  hidup.  Visualisasi  plot  memperlihatkan 
berapa  banyak  konsumsi  alkohol  penderita  kanker  hati 
sehingga dapat bertahan hidup. Dari visualisasi pada gambar 3 
dapat disimpulkan bahwa sekitar kurang dari 100 gram alkohol 
dapat  bertahan  hidup  sedangkan  penderita  kanker  hati  yang 

sebagai berikut: 

H0:  tidak  ada  variabel  independen  yang  mempunyai 

pengaruh terhadap variabel dependen. 

H1:  paling  sedikit  ada  1  variabel 

independen  yang 

mempunyai pengaruh terhadap variabel dependen.  
Keputusan yang didapat adalah tolak H0, artinya paling sedikit 
ada  1  variabel  independen  yang  memberikan  pengaruh 
terhadap variabel dependen. 

Pengujian  signifikansi  parameter  parsial  menggunakan 

hipotesis sebagai berikut: 

H0:  variabel  independen  ke-j  tidak  mempunyai  pengaruh 

terhadap variabel dependen. 

 4 / 6 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
  Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

H1: variabel independen ke-j mempunyai pengaruh terhadap 

H1:  tidak  ada  kesesuaian  antara  model  dengan  nilai 

variabel dependen. 

Kesimpulan dari pengujian ini yaitu sebagian besar variabel 
independen memiliki p-value lebih besar dari alfa 5%, artinya 
sebagian  besar  variabel  tidak  mempunyai  pengaruh  secara 
signifikan terhadap variabel dependen.  

Adapun variabel independen yang tidak berpengaruh secara 
signifikan  antara  lain:  Symptoms,  Diabetes,  HIV,  Age  (usia 
saat didiagnosis), INR, ALT, AST, dan ALP. Karena sebagian 
besar  parameter  tidak  signifikan  maka  parameter  dengan  p-
value  tertinggi  dikeluarkan dan  dilakukan  pengujian  kembali. 
Sebanyak 39 model dibangun hingga semua parameter dalam 
model  signifikan.  Kemudian  dipilih  model  terbaik  dimana 
model  tersebut  memiliki  nilai  AIC  terendah  dibanding  yang 
lain. 

Persamaan dari model tersebut adalah sebagai berikut: 

𝑔(𝑥𝑖) = 13,02 − 1,92𝑋1 − 1,40𝑋2 − 2,42𝑋3 + 3,98𝑋4

observasinya. 
Keputusan  yang  didapat  adalah  gagal  tolak  H0,  artinya  ada 
kesesuaian antara model dengan nilai observasinya. 

TABEL I. 

CONFUSION MATRIX METODE REGRESI LOGISTIK 

Predicted 

0 
1 

0 
53 
10 

Actual 
1 
9 
91 

Dari  tabel  1  dapat  dihitung  akurasinya,  yaitu  sebesar 

88,34%. 

C.  Perbandingan Random Forest dan Gradient Boosting 

+ 2,32𝑋5 − 2,56𝑋6 + 1,88𝑋7 − 4,20𝑋8
+ 1,28𝑋9 − 1,78𝑋10 − 0,09𝑋11 − 0,03𝑋12
− 0,90𝑋13 − 2,33𝑋14 + 0,01𝑋15 − 0,13𝑋16
+ 0,03𝑋17 − 0,02𝑋18 − 0,01𝑋19 − 0,10𝑋20
+ 0,03𝑋21 − 0,002𝑋22 

Dimana 
X1 = Symtoms 
X2 = HBcAb 
X3 = HCVAb 
X4 = Endemic 
X5 = Smoking 
X6 = Diabetes 
X7 = AHT 
X8 = HIV 
X9 = PHT 
X10 = PVT 
X11 = Age 
X12 = Packs/year 
X13 = Ascites 
X14 = INR 
X15 = Platelets 
X16 = TotalBil 
X17 = ALT 
X18 = AST 
X19 = ALP 
X20 = MajorDim 
X21 = Iron 
X22 = Ferritin 

Model  yang  sudah  dibuat  memiliki  koefisien  determinasi 
sebesar  0,56  atau  56,34%  artinya  variabel  independen  dapat 
menjelaskan  variabilitas  variabel  dependen  sebesar  56,34% 
sedangkan  sisanya  dijelaskan  oleh  variabel  lain  di  luar  data 
pengamatan yang ada. 

Setelah  membuat  model  kemudian  dilakukan  pengujian 
kelayakan model regresi menggunakan uji Hosmer-Lemeshow 
Goodness  of  Fit  Test.  Dalam  pengujian  ini  menggunakan 
hipotesis sebagai berikut: 

H0: ada kesesuaian antara model dengan nilai observasinya. 

Sebelum 

dilakukan 

pengklasifikasian  menggunakan 
algoritma  random  forest  dan  gradient  boosting,  dilakukan 
imputasi  atau 
penanganan  missing  value  dengan  cara 
mengganti  data  yang  hilang.  Metode  yang  digunakan  dalam 
penelitian  ini  adalah  mean  dan  mode,  median  dan  mode,  dan 
KNN  Imputation.  Setelah  dilakukan  imputasi  data  kemudian 
dilakukan  pemilihan  fitur  yang  berpengaruh  terhadap  model. 
Dari hasil yang didapatkan ternyata metode imputasi data yang 
digunakan tidak berpengaruh terhadap akurasi algoritma.  

Algoritma  random forest memiliki  akurasi  sebesar  72,16% 
sedangkan  akurasi  algoritma  gradient  boosting  sebesar 
70,32%. Kedua algoritma tersebut memiliki akurasi yang tidak 
berbeda jauh. 

VI. KESIMPULAN 

Berdasarkan  hasil  dan  pembahasan  dari  penelitian  ini, 

diperoleh kesimpulan sebegai berikut: 

1.  Hasil  prediksi  menggunakan  metode  CRISP-DM  dan 
untuk  modelling  menggunakan  metode  random  forest 
dan gradient boosting masih belum memiliki performa 
yang  sangat  baik.  Sebaliknya  metode  regresi  logistik 
memiliki akurasi yang lebih baik yaitu sebesar 88,34%. 
2.  Variabel yang tidak digunakan dalam algoritma random 
forest  dan  gradient  boosting  antara  lain:  Grams/day, 
Packs/year, ALT, DirBil, Iron, Sat, Ferritin. 

3.  Variabel yang digunakan dalam metode regresi logistik 
antarai  lain:  Symptoms,  HBcAb,  HCVAb,  Endemic, 
Smoking,  Diabetes,  AHT,  HIV,  PHT,  PVT,  Age, 
Packs/year,  Ascites,  INR,  Platelets,  TotalBil,  ALT, 
AST, ALP, MajorDim, Iron, dan Ferritin. 

4.  Performa yang belum cukup baik bisa jadi terjadi karena 
metode imputasi data yang belum cocok dengan dataset, 
mengingat  persentase  data  yang  hilang  cukup  tinggi. 
Kedepannya  mungkin  dapat  dilakukan  imputasi  data 
dengan  mempertimbangkan  masing-masing  variabel 
independen. 

DAFTAR PUSTAKA 
[1]  Basu,  S.,  Kumbier,  K., Brown, J.  B.,  &  Yu, B. (2018). Iterative random 
high-order 
predictive 

discover 

forests 

stable 

and 

to 

 5 / 6 

 
 
 
 
 
 
 
 
 
interactions. Proceedings  of  the  National  Academy  of  Sciences, 115(8), 
1943-1948. 

[2]  Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32. 
[3]  Centers for Disease Control and Prevention. Diakses pada 5 Oktober 2022 

dari https://www.cdc.gov/cancer/liver/  

[4]  Chen, I. Y., Pierson, E., Rose, S., Joshi, S., Ferryman, K., & Ghassemi, M. 
(2021).  Ethical  machine  learning  in  healthcare. Annual  review  of 
biomedical data science, 4, 123-144. 

[5]  Denisko, D., & Hoffman, M. M. (2018). Classification and interaction in 
random forests. Proceedings of the National Academy of Sciences, 115(8), 
1690-1692. 

[6]  Fiarni,  C.,  Sipayung,  E.  M.,  &  Maemunah,  S.  (2019).  Analysis  and 
prediction  of  diabetes  complication  disease  using  data  mining 
algorithm. Procedia computer science, 161, 449-457. 

[7]  Freund, Y., & Schapire, R. E. (1997). A decision-theoretic generalization 
of on-line learning and an application to boosting. Journal of computer and 
system sciences, 55(1), 119-139. 

[8]  Friedman,  J.  H.  (2001).  Greedy  function  approximation:  a  gradient 

boosting machine. Annals of statistics, 1189-1232. 

[9]  Global Cancer Observatory: Cancer today. (2020). Diakses pada 5 Oktober 

2022 dari https://gco.iarc.fr/today/home  

[10] Ho, T. K. (1995, August). Random decision forests. In Proceedings of 3rd 
international conference on document analysis and recognition (Vol. 1, pp. 
278-282). IEEE. 

[11] Keleş,  M.  K.  (2019).  Breast  cancer  prediction  and  detection  using  data 
study. Tehnički 

mining  classification  algorithms:  a  comparative 
vjesnik, 26(1), 149-155. 

[12] Rabbi, M. F., Uddin, M. P., Ali, M. A., Kibria, M. F., Afjal, M. I., Islam, 
M.  S.,  &  Nitu,  A.  M.  (2018).  Performance  evaluation  of  data  mining 
classification techniques for heart disease prediction. American Journal of 
Engineering Research, 7(2), 278-283. 

[13] Rady, E. H. A., & Anwar, A. S. (2019). Prediction of kidney disease stages 
using  data  mining  algorithms. Informatics  in  Medicine  Unlocked, 15, 
100178. 

[14] Sannabe,  A.  (2022).  How  to  improve  SME  performance  using  iterative 
institutional 
empirical 
random 
complementaritty. Humanities and Social Sciences Communications, 9(1), 
1-9. 

analysis 

forest 

the 

of 

in 

[15] Verma, A. K., Pal, S., & Kumar, S. (2019). Classification of skin disease 
using  ensemble  data  mining  techniques. Asian  Pacific  journal  of  cancer 
prevention: APJCP, 20(6), 1887. 

[16] Yamashita,  T.,  &  Kaneko,  S.  (2016).  Liver  cancer. Rinsho  byori.  The 

Japanese journal of clinical pathology, 64(7), 787-796. 

  Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

[17] Zhang, Z., Zhao, Y., Canes, A., Steinberg, D., & Lyashevska, O. (2019). 
Predictive analytics with gradient boosting in clinical medicine. Annals of 
translational medicine, 7(7). 

[18] Abdurashidovna,  R.  K.  (2022).  The  Main  Clinical  Signs,  Symptoms, 
Treatment  Methods  of  Liver  Cancer. Eurasian  Medical  Research 
Periodical, 6, 231-234. 

[19] Kamil,  K.  (2021).  Pemeriksaan  Alpha-Fetoprotein  (AFP)  Metode  ELFA 
Menggunakan Alat Vidas Biomerieux Di Laboratorium Immuno Serologi 
Samarinda. Jurnal  Teknologi 
RSUD  Abdul  Wahab 
Laboratorium Medik Borneo, 1(1), 51-60. 
18 

[20] Halodoc. 

Sjahranie 

Diakses 

Januari 

2023 

pada 

dari  

https://www.halodoc.com/artikel/deteksi-hepatitis-b-dengan-tes-hbsag 

[21] Alomedika. 

Diakses 

pada 

18 

Januari 

2023 

dari 

https://www.alomedika.com/memahami-hasil-pemeriksaan-serologi-
hepatitis-b 

[22] Hepatitis  B  Foundation.  Diakses  pada  18  Januari  2023  dari 
https://www.hepb.org/prevention-and-diagnosis/diagnosis/hbv-blood-
tests/ 

[23] Veterans  Affairs.  Diakses 

pada 

18 

Januari 

2023 

dari 

https://www.hepatitis.va.gov/hcv/patient/diagnosis/labtests-hepatitisC-
antibody.asp#:~:text=Hepatitis%20C%20antibody%20(HCV%20Ab,as%
20either%20positive%20or%20negative 

[24] Saitta,  C.,  Pollicino,  T.,  &  Raimondo,  G.  (2019).  Obesity  and  liver 

cancer. Annals of hepatology, 18(6), 810-815. 

[25] Asian  American  Medical  Group.  Diakses  pada  18  Januari  2023  dari 

https://www.aamg.co/liver/health-information-resources/liver/non-
alcoholic-fatty-liver-disease/ 

[26] Zhang, W. S., Li, X. O., Zhang, H., Gao, C., Fang, L., & Yang, H. Y. (2020). 
Increased Level of Systolic Blood Pressure in Hepatocellular Carcinoma 
Patients  with  Diabetes  Mellitus. Diabetes,  Metabolic  Syndrome  and 
Obesity: Targets and Therapy, 13, 1979. 

[27] KEPUTUSAN  MENTERI  KESEHATAN  REPUBLIK 

NOMOR  HK.01.07/MENKES/1355/2022 
NASIONAL 
PELAYANAN 
KARSINOMA SEL HATI PADA DEWASA 
18 

Diakses 

pada 

[28] Halodoc. 

KEDOKTERAN 

INDONESIA 
TENTANG  PEDOMAN 
LAKSANA 

TATA 

Januari 

2023 

dari  

https://www.halodoc.com/artikel/ketahui-4-fakta-seputar-penyakit-liver 
[29] Cleveland  Clinic  –  Diseases.  Diakses  pada  18  Januari  2023  dari  

https://my.clevelandclinic.org/health/diseases/15429-esophageal-varices 

[30] Medline Plus  Medical Encyclopedia. Diakses  pada 18 Januari 2023 dari  

https://medlineplus.gov/ency/article/003573.htm

 6 / 6 

 
 
","2023-12-19T07:58:56.434760Z",221910715,"[{""start"":605,""end"":682,""text"":""melakukan klasifikasi dan prediksi kelangsungan hidup penderita\\nkanker hati"",""labels"":[""Tujuan""]},{""start"":615,""end"":639,""text"":""klasifikasi dan prediksi"",""labels"":[""Metode""]},{""start"":8188,""end"":8268,""text"":""mengklasifikasikan dan memprediksi kelangsungan hidup\\npenderita kanker hati"",""labels"":[""Tujuan""]},{""start"":23521,""end"":23616,""text"":""metode random forest\\ndan gradient boosting masih belum memiliki performa\\nyang sangat baik"",""labels"":[""Temuan""]},{""start"":23631,""end"":23711,""text"":""metode regresi logistik\\nmemiliki akurasi yang lebih baik yaitu sebesar 88,34%"",""labels"":[""Temuan""]}]",511.068,"2023-12-19T07:58:56.434760Z"
4,"1","Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Analisis Tingkat Depresi Mahasiswa pada Media 
Sosial Twitter menggunakan Deep Learning dan 
Latent Dirichlet Allocation 
(Studi Kasus: Akun Twitter @collegemenfess) 

Azahra Dwi Putri (221910697, 4SD2) 
Dosen Pembimbing: Budi Yuniarto, SST., M.Si. 

pada 

135%. 

depresi 

depresi 

sebesar 

Penderita 

Ringkasan— Depresi merupakan gangguan suasana hati yang 
ditandai dengan perasaan sedih yang mendalam dan kehilangan 
minat dalam kegiatan sehari-hari. Depresi dapat terjadi kepada 
siapapun,  tidak  terkecuali  kepada  mahasiswa.  Dari  tahun  2013 
hingga  2021,  ditemukan  adanya  peningkatan  depresi  pada 
dapat 
mahasiswa 
mengungkapkan pikirannya melalui media sosial Twitter. Twitter 
dinilai  mampu  menggambarkan  perasaan  penggunanya  dengan 
lebih  kuat.  Penelitian  ini  bertujuan  untuk  mendeteksi  dan 
mengelompokkan 
tweet  @collegemenfess, 
melakukan  klasifikasi  tingkat  depresi  mahasiswa  pada  media 
sosial  Twitter  menggunakan  LSTM  dan  BiLSTM  serta 
membandingkan 
topik 
berdasarkan kelas depresi menggunakan LDA. Didapatkan hasil 
sebanyak  48.98%  tweet  yang  mengindikasikan  depresi.  Hasil 
cluster tweet depresif menunjukkan bahwa sebesar 73.42% tweet 
mengindikasikan 
tweet 
mengindikasikan  depresi  berat.  Kemudian,  metode  BiLSTM 
memberikan  hasil  akurasi  sebesar  82.72%  dan  LSTM  sebesar 
82.25%.  Secara  keseluruhan,  metode  BiLSTM  memberikan 
performa  lebih  baik  dibandingkan  LSTM.  Sedangkan  hasil 
pemodelan  topik  menggambarkan  tiga  masalah  umum  untuk 
setiap  kelas  depresi,  yaitu  masalah  akademik,  sosial,  dan  hal 
lainnya. 

dan  mengetahui 

performanya, 

26.58% 

depresi 

ringan 

dan 

Kata Kunci— depresi, mahasiswa, Twitter, deep learning, LDA. 

I.  LATAR BELAKANG 

telah 

Kesehatan mental merupakan hal penting yang harus selalu 
dijaga.  Apabila  kesehatan  mental  terganggu,  maka  gangguan 
timbul.  Menurut  World  Health 
kesehatan  mental  akan 
Organization  (WHO), 
terjadi  peningkatan  pasien 
penyakit mental di dunia sekitar 13% dalam dekade terakhir [1]. 
Salah satu penyakit mental yang paling umum adalah depresi. 
Depresi  merupakan  gangguan  suasana  hati  yang  ditandai 
dengan  perasaan  sedih  yang  mendalam  serta  kehilangan 
kesenangan  dan  minat  dalam  kegiatan  sehari-hari.  Depresi 
dapat  membuat  emosi  seseorang  menjadi  tidak  stabil,  seperti 
menjadi  lebih  mudah  tersinggung  dan  marah.  Hal  ini  dapat 
memengaruhi produktivitas dan mengganggu kehidupan sosial 
yang  penting  untuk  kehidupan  sehari-hari,  bahkan  dapat 
membuat  penderitanya  menyakiti  diri  sendiri  [2].  Menurut 
Riset  Kesehatan  Dasar  (Riskedas)  tahun  2018,  prevalensi 
penderita  depresi  pada  penduduk  berusia  15  tahun  ke  atas  di 
Indonesia mencapai sebesar 6,1% [3].  

Depresi dapat terjadi kepada siapapun, tak terkecuali kepada 
mahasiswa. Penelitian dari Boston University mengungkapkan 
bahwa  kesehatan  mental  mahasiswa  semakin  memburuk. 
Dalam penelitian tersebut ditemukan peningkatan depresi pada 
mahasiswa  sebesar  135%  dari  tahun  2013  hingga  2021. 
Meskipun  COVID-19  berperan  dalam  peningkatan  tersebut, 
angkanya  cenderung  meningkat  selama  bertahun-tahun 
sebelum  pandemi  [4].  Penelitian  lain  yang  dilakukan  pada 
tahun 2020 mengungkapkan bahwa sebesar 21,1% mahasiswa 
mengalami depresi ringan, 17% mengalami depresi sedang, dan 
3,4% mengalami depresi berat [5].  

Menurut  penelitian  [6],  beberapa  penyebab  depresi  pada 
mahasiswa adalah karena diri yang tidak kompeten, kurangnya 
interaksi dengan teman sebaya dan dosen, rasa takut yang besar 
dalam menghadapi ujian, fasilitas kampus yang tidak memadai, 
serta harapan orang tua yang tidak realistis. Sedangkan menurut 
[7],  mahasiswa  seringkali  merasa  tertekan  dengan  tuntutan 
pendidikan,  banyaknya 
tugas  pembelajaran  yang  harus 
diselesaikan,  pelaksanaan  ujian,  penyelesaian  tugas  ilmiah  di 
akhir pendidikan, permasalahan dalam pertemanan dan dalam 
keluarga.  Faktor-faktor  ini  seringkali  menjadi  pemicu  utama 
timbulnya depresi pada mahasiswa. 

Para ahli telah berusaha untuk menjelaskan hubungan yang 
akurat  antara  depresi  dengan  bahasa  menggunakan  bantuan 
Natural  Language  Processing  [8].  Mayoritas  orang  dengan 
gangguan  jiwa  lebih  suka  menyendiri.  Oleh  karena  itu, 
penderita  gangguan  jiwa  akan  mencari  tempat  yang  dapat 
menampung  luapan  pikirannya,  salah  satunya  melalui  media 
sosial  Twitter.  Twitter  dinilai  mampu  menggambarkan 
perasaan  penggunanya  dengan 
lebih  kuat.  Berdasarkan 
penelitian  [9],  Twitter  merupakan  media  sosial  yang  paling 
sering  digunakan  oleh  seseorang  dengan  gejala  depresi 
dibandingkan  media  sosial  lainnya,  yaitu  Instagram  dan 
Facebook.  

Salah satu akun khusus dalam Twitter adalah autobase, yaitu 
akun bot yang digunakan untuk mengirim pesan secara anonim 
dengan  tujuan  untuk  berdiskusi  dan  berbagi  informasi  [10], 
seperti akun @collegemenfess yang menjadi wadah diskusi dan 
sharing  bagi  mahasiswa,  khususnya  mahasiswa  Indonesia. 
Indonesia  menduduki  urutan  kelima  sebagai  negara  dengan 
pengguna  Twitter  terbanyak  di  dunia  yang  mencapai  sebesar 
18,45 juta pengguna menurut data Statista pada Januari 2022 
[11]. 

 1 / 8 

 
 
 
 
 
Pernyataan  pada  data  tweet  dapat  memberikan  informasi 
yang berguna. Namun, data yang diperoleh pada media sosial 
cenderung bersifat tidak terstruktur dan memiliki jumlah yang 
besar.  Metode  text  mining  dapat  digunakan  untuk  mengatasi 
masalah  tersebut.  Text  mining  merupakan  suatu  proses 
ekstraksi  informasi  secara  otomatis  dari  data  teks  yang  tidak 
terstruktur [12]. 

akan 

digunakan 

untuk  mendeteksi 

Berdasarkan  hal  di  atas,  terdapat  potensi  dilakukannya 
analisis  tingkat  depresi  mahasiswa  pada  media  sosial  Twitter 
menggunakan  text  mining.  Pada  penelitian  ini,  beberapa 
metode 
dan 
mengelompokkan  tweet  @collegemenfess  yang  mengandung 
indikasi depresi. Akun ini dipilih karena merupakan salah satu 
wadah  diskusi  bagi  mahasiswa,  khususnya  mahasiswa 
Indonesia,  sehingga  diasumsikan  dapat  merepresentasikan 
mahasiswa. Setelah mengetahui tingkat  depresi pada masing-
masing tweet, penelitian ini juga melakukan klasifikasi tingkat 
depresi  mahasiswa  menggunakan  dua  metode  deep  learning, 
yaitu  Long  Short-Term  Memory  (LSTM)  dan  Bidirectional 
Long Short-Term Memory (BiLSTM).  

LSTM  adalah  metode  yang  telah  banyak  digunakan  untuk 
klasifikasi  dan  prediksi  [13].  Model  LSTM  efektif  dalam 
menangkap 
informasi  penting  karena  dapat  menyimpan 
informasi lama dan menghubungkannya dengan informasi baru 
[14].  Sehingga,  dalam  mengklasifikasikan  teks,  output  yang 
dihasilkan akan menjadi lebih bermakna karena kata-kata yang 
diinput  memiliki  arti  sebenarnya  sebagai  kalimat.  Namun, 
LSTM memiliki kelemahan yaitu memproses informasi dalam 
satu arah saja. BiLSTM merupakan pengembangan dari LSTM 
yang  dapat  mengatasi  kelemahan  ini.  Model  ini  dapat 
mengekstrak informasi lebih cepat melalui pendekatan dua arah 
[15].  

Kemudian,  penelitian  ini  juga  bertujuan  untuk  mengetahui 
topik berdasarkan tingkat depresi mahasiswa pada media sosial 
Twitter  menggunakan  metode  Latent  Dirichlet  Allocation 
(LDA). Metode ini digunakan karena dapat membuat ringkasan, 
klasterisasi,  serta  mengolah  data  berskala  besar  dengan  cara 
menghasilkan  daftar  topik  yang  diberi  bobot  pada  dokumen 
terkait [16]. 

II.  TUJUAN PENELITIAN 

Berdasarkan  latar  belakang  di  atas,  tujuan  penelitian  ini 

adalah sebagai berikut: 
1.  Mendeteksi dan mengelompokkan tweet @collegemenfess 

yang mengandung indikasi depresi. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

menggunakan  lima  kriteria  sebagai  ukuran  kesehatan  mental 
dalam  suatu  ulasan,  yaitu  sentimen,  basic  emotion,  kata-kata 
negatif, kata-kata absolut, dan kata ganti orang pertama tunggal. 
Basic  emotion  diperoleh  dari  lexicon  WordNet,  sedangkan 
analisis  sentimen  memanfaatkan  lexicon  VADER.  Pelabelan 
data  dilakukan  menggunakan  bantuan  hierarchical  clustering 
dan  menghasilkan  tiga  level  depresi.  Selanjutnya,  data  yang 
sudah  diberi  label  diklasifikasikan  menggunakan  LSTM 
dengan beberapa optimasi (Adam, RMSProp, Adagrad). Hasil 
dari  semua  optimasi  memperoleh  tingkat  akurasi  yang  sama, 
yaitu sebesar 70,89% [17]. 

Penelitian  selanjutnya  dari  Hayatin  untuk  memprediksi 
gejala  depresi  pada  media  sosial  Twitter.  Penelitian  ini 
memanfaatkan  data  Sentiment140  yang  telah  diberi  label 
positif, negatif, dan netral. Label positif adalah label yang tidak 
mengandung  indikasi  depresi,  label  negatif  artinya  tweet 
mengandung gejala depresi dan kecemasan, sedangkan netral 
artinya tidak mengandung indikasi depresi, tetapi dapat lebih 
rentan  mengalami  depresi.  Selanjutnya  dilakukan  klasifikasi 
dengan Multinomial Naïve Bayes yang menghasilkan akurasi 
sebesar 70% dan f1-score sebesar 68% [18]. 

Penelitian  lainnya  oleh  Nugroho  dkk.  dilakukan  dengan 
tujuan untuk mendeteksi depresi dan kecemasan pada data teks 
Twitter  menggunakan  BiLSTM.  Peneliti  juga  menggunakan 
baseline  model seperti  K-Nearest Neighbor (KNN),  Decision 
Tree (DT), Support Vector Machine (SVM), Naïve Bayes (NB), 
Multi Layer Perceptron (MLP), maupun LSTM standar. Hasil 
akurasi yang diperoleh pada model BiLSTM sebesar 94.12% 
dan performa model tersebut lebih baik dibandingkan seluruh 
model lainnya [19]. 

Selanjutnya  adalah  penelitian  Ridhwanulah  dan  Fudholi 
terkait  pemodelan  topik.  Penelitian  ini  menggunakan  metode 
topik  perbincangan  masyarakat 
LDA  untuk  mengetahui 
Indonesia  terkait  penyakit  tropis,  khususnya  penyakit  kusta, 
malaria, dan demam berdarah. Hasil studi menunjukkan bahwa 
LDA  berhasil  memodelkan 
topik  pembicaraan 
masyarakat Indonesia terkait penyakit tropis. Didapatkan hasil 
topik  dengan  nilai  koherensi  0,576453. 
sebanyak  5 
Berdasarkan hasil pemodelan topik, dapat disimpulkan bahwa 
topik-topik tersebut membahas hal seperti dana yang digunakan 
untuk pemberantasan malaria dan demam berdarah, COVID-19, 
kebutaan dan kusta, serta pengobatan dan pencegahannya [20]. 

trend 

IV. METODE PENELITIAN  
Berikut  ditunjukkan  gambaran  terkait  tahapan  penelitian 

2.  Melakukan  klasifikasi  tingkat  depresi  mahasiswa  pada 

pada Gambar 1. 

media sosial Twitter menggunakan deep learning. 

3.  Membandingkan  performa  metode  deep  learning  dalam 
klasifikasi  data  tingkat  depresi  mahasiswa  pada  media 
sosial Twitter. 

4.  Mengetahui topik berdasarkan tingkat depresi mahasiswa 

pada media sosial Twitter. 

III. PENELITIAN TERKAIT 

Terdapat  beberapa  penelitian  yang  berkaitan  dengan 
penelitian  ini.  Salah  satunya  yaitu  penelitian  yang  dilakukan 
oleh  Kholifah  dkk.  dengan  tujuan  untuk  mendeteksi  tingkat 
keparahan  depresi  pada  media  sosial  Twitter.  Penelitian  ini 

Gambar 1. Tahapan penelitian  

 2 / 8 

 
 
 
 
A. Pengumpulan Data 

Pengumpulan data dilakukan menggunakan library snscrape 
pada  Python.  Data  yang  digunakan  dalam  penelitian  ini 
bersumber  dari  akun  Twitter  @collegemenfess.  Akun 
@collegemenfess  digunakan  karena  merupakan  salah  satu 
wadah diskusi bagi mahasiswa. Data tweet berbahasa Indonesia 
diambil dalam rentang waktu bulan Januari hingga Desember 
2022  dengan  menggunakan  kata  kunci  yang  mengandung 
makna  depresi.  Beberapa  kata  kunci  yang  digunakan  dalam 
penelitian ini diambil dari dua penelitian sebelumnya, yaitu [21] 
dan [22]. Daftar kata kunci tersebut dapat dilihat pada Tabel I. 

TABEL I 
DAFTAR KATA KUNCI 

Referensi 
Jurnal 

Kata Kunci 
Depresi, stres OR stress, capek OR lelah OR lemah, cemas 
OR gelisah OR khawatir OR resah OR anxiety, pusing OR 
penat, mual OR muntah, marah, gugup OR nervous, sedih 
OR galau OR nangis OR sad, panik 

Lainnya 

Tertekan, kesal OR kesel, benci OR hate, malas OR males, 
hancur, hampa, bersalah 

B. Preprocessing Data 

Tahap ini dilakukan agar data dapat digunakan untuk proses 
pengolahan  data  selanjutnya.  Tahap  ini  dibagi  menjadi  tiga 
bagian, yaitu sebagai berikut: 
a.  Preprocessing Data Bahasa Indonesia 

Langkah-langkah yang dilakukan dalam bagian ini yaitu: 
1.  Case  folding,  merupakan  tahap  mengubah  semua 

huruf kapital menjadi lower case. 

2.  Data  cleaning,  merupakan  proses  membersihkan 
noise  pada  data,  seperti  penghapusan  link,  hashtag, 
tanda  baca,  angka,  karakter  kosong, 
username, 
emoticon, serta data duplikat. 

3.  Normalization,  merupakan  proses  mengubah  kata 
gaul (slang) menjadi kata baku. Tahap ini diperlukan 
agar hasil terjemahan data menjadi lebih optimal. 

b.  Translate Data 

Selanjutnya,  dilakukan  proses  penerjemahan  data 
berbahasa Indonesia ke bahasa Inggris. Hal ini dilakukan 
karena  lexicon  VADER  yang  digunakan  dalam  ekstraksi 
fitur  sentimen  pada  tahap  pelabelan  data  hanya  tersedia 
dalam  bahasa  Inggris.  Penerjemahan  data  dilakukan 
menggunakan library googletrans pada Python. 

c.  Preprocessing Data Bahasa Inggris 

Tahapan yang dilakukan adalah sebagai berikut: 
1.  Case  folding,  merupakan  tahap  mengubah  semua 

huruf kapital menjadi lower case. 

2.  Data  cleaning,  merupakan  proses  membersihkan 
noise  pada  data,  seperti  penghapusan  tanda  baca, 
angka, karakter kosong, serta data duplikat. 

3.  Stopword removal, merupakan tahap menghapus kata 

yang tidak memiliki makna. 

4.  Tokenization, merupakan proses membuat daftar kata 
dengan  memisahkan  kalimat  menjadi  potongan-
potongan kata. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

5.  Lemmatization, merupakan proses mengubah kata ke 

dalam bentuk dasar. 

C. Pelabelan Data 
Ekstraksi Fitur Kesehatan Mental 

Ekstraksi fitur merupakan tahap memperoleh informasi dari 
fitur  yang  dimiliki  oleh  data  yang  dikumpulkan.  Fitur  yang 
digunakan dalam tahap ini merupakan fitur yang menjadi tolak 
ukur  kesehatan  mental  subjek  penelitian.  Pada  tahap  ini 
terdapat dua fitur kesehatan mental yang akan diekstraksi pada 
data tweet, yaitu sentimen dan basic emotion. 

Analisis sentimen digunakan untuk mengetahui sikap, opini, 
dan emosi yang terkandung dalam sebuah dokumen. Penelitian 
ini  menggunakan  sentimen  berbasis  lexicon,  yaitu  VADER 
melalui 
library  vaderSentiment  pada  Python.  VADER 
menghasilkan  skor  positif,  negatif,  netral,  dan  compound 
(gabungan). Ketentuan klasifikasi sentimen menggunakan nilai 
compound yakni positif untuk compound ≥ 0.05, netral untuk -
0.05 < compound < 0.05, dan negatif untuk compound ≤ -0.05 
[23].  Penderita  depresi  lebih  sering  menggunakan  kata-kata 
negatif  yang  menunjukkan  keputusasaan  dirinya,  kesedihan 
yang  berkepanjangan,  bahkan  pikiran  untuk  bunuh  diri  [17], 
sehingga data dengan hasil sentimen negatif ditetapkan sebagai 
tweet yang mengindikasikan depresi. 

Basic  emotion  sangat  berkaitan  dengan  kondisi  mental 
seseorang. Penelitian ini menggunakan NRC Emotion Lexicon 
untuk  mengeksplorasi  basic  emotion  yang  terkandung  pada 
data tweet dengan indikasi depresi. Jenis emosi dasar yang akan 
digunakan  ada  delapan,  yaitu  surprise,  anger,  fear,  sadness, 
anticipation, disgust, joy, dan trust [24].  
Pengelompokkan Tweet Depresif 

Hasil  dari  ekstraksi  fitur  adalah  data  yang  tidak  memiliki 
ini  menggunakan  bantuan  algoritma 
label.  Penelitian 
hierarchical clustering untuk mengelompokkan tweet menjadi 
beberapa  kelompok  yang  dapat  menggambarkan  tingkat 
depresi  pada 
tweet.  Tipe  hierarchical  clustering  yang 
digunakan  adalah  agglomerative  clustering  dengan  teknik 
pengelompokkan  yang  akan  digunakan  adalah  complete 
linkage. Hasil clustering akan dijadikan sebagai label pada data. 

D Klasifikasi Data 
Data  yang 

telah  diberi 

label  akan  diklasifikasikan 
menggunakan  deep  learning.  Algoritma  deep  learning  yang 
digunakan  dalam  penelitian  ini  adalah  LSTM  dan  BiLSTM. 
Word  embedding  GloVe  diterapkan  untuk  mengekstrak  fitur 
teks ke bentuk numerik dalam klasifikasi data. Data akan diuji 
dengan k-fold cross validation pada Python. Setelah dilakukan 
klasifikasi,  performa  kedua  model  akan  dievaluasi  dan 
dibandingkan untuk dilihat mana model yang bekerja lebih baik. 
Ukuran  metrik  yang  digunakan  untuk  mengevaluasi  model 
yaitu akurasi, presisi,  recall, dan  f1-score per masing-masing 
fold dan akan dirata-ratakan. 

E. Pemodelan Topik 

Pada tahap ini dilakukan pemodelan topik untuk mengetahui 
topik perbincangan mahasiswa berdasarkan tingkat depresinya. 
Metode  yang  digunakan  adalah  Latent  Dirichlet  Allocation 
(LDA) menggunakan library gensim pada Python. Data yang 

 3 / 8 

 
 
 
digunakan  adalah  data  tweet  berbahasa  Indonesia  yang  telah 
melalui tahap preprocessing dan filtering data.  

Penentuan  jumlah  topik  optimal  dilakukan  berdasarkan 
coherence score. Semakin tinggi nilai coherence score, maka 
semakin  baik  model  topik  yang  dihasilkan  [25].  Hasil 
pemodelan  topik  akan  divisualisasikan  menggunakan  library 
pyLDAvis dan juga diinterpretasikan oleh peneliti. 

V.  KERANGKA PIKIR 

Gambar 2. Kerangka penelitian 

ini  didasari  dari 

Gambar  2  menjelaskan  kerangka  pikir  dalam  penelitian. 
Penelitian 
suatu  penelitian  yang 
mengungkapkan bahwa kesehatan mental mahasiswa semakin 
memburuk  dari  tahun  ke  tahun  [4].  Salah  satu  gangguan 
kesehatan  mental  adalah  depresi.  Depresi  pada  mahasiswa 
umumnya disebabkan karena masalah akademik dan sosial [7]. 
Di era digital ini, penderita depresi dapat mencurahkan suasana 
hatinya  pada  media  sosial,  salah  satunya  Twitter.  Twitter 
merupakan  media  sosial  yang  paling  sering  digunakan  oleh 
orang dengan gejala depresi dibandingkan media sosial lainnya 
[9]. Para ahli telah berusaha untuk menjelaskan hubungan yang 
akurat  antara  depresi  dengan  bahasa  menggunakan  bantuan 
Natural  Language  Processing  [8].  Oleh  karena  itu,  NLP 
memiliki  potensi  untuk  menjadi  metode  pelengkap  dalam 
mendeteksi  tingkat  depresi.  Solusi  yang  diusulkan  dalam 
penelitian 
ini  yaitu  dengan  melakukan  deteksi  dan 
pengelompokkan tweet depresi, klasifikasi data tingkat depresi, 
dan 
depresi 
menggunakan metode yang telah ditentukan. Data diambil dari 
akun  Twitter  @collegemenfess  pada  tahun  2022.  Beberapa 
metode yang digunakan dinilai dengan indikator evaluasi agar 
hasil yang didapatkan teruji dengan baik. 

berdasarkan 

pemodelan 

tingkat 

topik 

VI. HASIL DAN PEMBAHASAN 

A. Pengumpulan Data 

Data tweet berbahasa Indonesia dari akun @collegemenfess 
pada tahun 2022 dikumpulkan menggunakan library snscrape. 
Data dikumpulkan berdasarkan berbagai keyword depresi yang 
telah  ditentukan  secara  terpisah.  Kemudian,  masing-masing 
data  tersebut  digabung  menjadi  satu  menggunakan  bahasa 
Python.  Jumlah  data  tweet  yang  berhasil  di-scraping  adalah 
tiga  kata  kunci  yang 
sebanyak  29.908  data.  Adapun 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

menghasilkan data terbanyak yaitu ‘sedih’ sebanyak 9.712 data, 
‘capek’ sebanyak 5.164 data, dan ‘pusing’ sebanyak 2.996 data. 
Data yang diperoleh memiliki  tiga atribut, yaitu  id,  datetime, 
dan tweet. Data ini kemudian disimpan dalam format ekstensi 
csv. 

B. Preprocessing Data 

Sebelum  masuk  ke  tahap  analisis  data,  data  yang  telah 
dikumpulkan  akan  dipraproses  terlebih  dahulu  agar  data 
menjadi bersih dan konsisten. Setelah preprocessing dilakukan, 
jumlah  data  yang  akan  digunakan  untuk  tahap  selanjutnya 
adalah sebanyak 27.332 data. Contoh perbandingan tweet dari 
data mentah hingga preprocessing ditunjukkan pada Tabel II. 

TABEL II 
HASIL PREPROCESSING DATA 
Hasil 

Kondisi 

Data mentah 

[cm] udah mulai stress sama skripsi belum? 

sudah mulai stres sama skripsi belum 

Have you started to stress with your thesis yet? 

started stress thesis yet 

Preprocessing bahasa 
Indonesia 
Translate data 

Preprocessing bahasa 
Inggris 

C. Pelabelan Data 

Langkah  pertama  adalah  melakukan  ekstraksi 

fitur 
kesehatan  mental  menggunakan  sentimen  dan  basic  emotion. 
Ekstraksi  fitur  sentimen  VADER  dilakukan  menggunakan 
library  vaderSentiment  pada  Python.  Beberapa  contoh  hasil 
dari sentimen VADER ditunjukkan pada Gambar 3.   

Gambar 3. Contoh hasil ekstraksi fitur sentimen VADER 

Adapun  perbandingan  hasil  sentimen  dapat  dilihat  pada 

Gambar 4.  

Gambar 4. Perbandingan hasil sentimen VADER 

 4 / 8 

 
 
 
 
 
 
 
 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Gambar 7. Rata-rata emosi negatif untuk tiap label 

Berdasarkan Gambar 7, dapat disimpulkan bahwa kelompok 
dengan  label  1  ditetapkan  sebagai  “depresi  berat”  dan 
kelompok dengan label 0 sebagai “depresi ringan” karena rata-
rata  emosi  negatif  label  1  secara  keseluruhan  lebih  besar 
daripada  label  0.  Perbandingan  jumlah  tweet  dari  masing-
masing label dapat dilihat pada Gambar 8. 

Dari  gambar  di  atas,  didapatkan  jumlah  sentimen  negatif, 
positif,  dan  netral  masing-masing  sebanyak  13.388  tweet, 
12.305 tweet, dan 1.639 tweet. Tweet dengan sentimen negatif 
merupakan 
tweet  yang  mengindikasikan  gejala  depresi. 
Sehingga,  sebanyak  13.338  data  sentimen  negatif  akan 
digunakan untuk proses selanjutnya. 

Fitur  kedua  yaitu  basic  emotion  menggunakan  NRC 
Emotion  Lexicon  versi  0.92.  Dari  tweet  sentimen  negatif, 
dilakukan  ekstraksi  terhadap  delapan  emosi  dasar  yang  telah 
ditentukan.  Beberapa  contoh  hasil  dari  basic  emotion  dapat 
dilihat pada Gambar 5. 

Gambar 5. Ekstraksi fitur basic emotion 

hierarchical 

depresif  menggunakan 

Langkah  berikutnya  adalah  melakukan  pengelompokkan 
tweet 
clustering 
berdasarkan fitur kesehatan mental yang telah diperoleh. Hasil 
pengelompokkan  ini  akan  dijadikan  sebagai  label  pada  data. 
Sebelum  melakukan  clustering,  data  dinormalisasi  terlebih 
dahulu menggunakan fungsi normalize() pada Python. Hal ini 
dilakukan karena beberapa fitur memiliki rentang yang berbeda, 
sehingga dilakukan normalisasi agar semua fitur memberikan 
kontribusi yang sama. Selanjutnya, dilakukan clustering untuk 
membentuk  2  cluster  dengan  menggunakan  metric  euclidean 
dan  complete  linkage.  Beberapa  contoh  hasil  data  yang  telah 
dinormalisasi  beserta  hasil  clustering  ditunjukkan  pada 
Gambar  6.  Adapun  contoh  tweet  beserta  hasil  cluster-nya 
ditampilkan pada Tabel III. 

Gambar 6. Pelabelan data dengan hierarchical clustering 

TABEL III 
CONTOH HASIL PENGELOMPOKKAN DATA 

Tweet 
sender  made  biggest  choice  life  yes chose  stop  eighth  semester 
hard cry every day get depressed schizo parent agreed decision 

started stress thesis yet 

Label 
1 

0 

Untuk menentukan profil pada masing-masing cluster yang 
telah terbentuk, peneliti perlu melakukan analisis lebih lanjut. 
Menurut  [8],  penderita  gangguan  mental  cenderung  memiliki 
emosi dan ekspresi yang lebih negatif. Sehingga dari 8 emosi 
yang  digunakan,  peneliti  akan  menganalisis  4  emosi  negatif 
(anger, fear, sadness, dan disgust) dengan melihat rata-rata per 
emosinya  yang  kemudian  akan  dirata-ratakan 
secara 
keseluruhan.  Hasil  analisis  lanjutan  untuk  tiap  label  terlihat 
pada Gambar 7. 

Gambar 8. Perbandingan jumlah label depresi ringan dan depresi berat 

Dari Gambar 8, terlihat bahwa jumlah tweet dengan kategori 
depresi ringan sebanyak 9.830 tweet dan kategori depresi berat 
sebanyak  3.558  tweet.  Hasil  pengelompokkan  tweet  depresif 
menunjukkan  bahwa  sebesar  73.42%  tweet  mengindikasikan 
depresi  ringan  dan  sebesar  26.58%  tweet  mengindikasikan 
depresi  berat.  Data  ini  tergolong  sebagai  imbalanced  data 
karena  rasio  di  kedua  kategori  tidak  proporsional.  Namun, 
penelitian  ini  tidak  melakukan  penanganan  imbalanced  data 
lebih lanjut. 

D. Klasifikasi Data 

Klasifikasi  dilakukan  menggunakan  LSTM  dan  BiLSTM. 
Dalam mengekstraksi fitur data teks untuk klasifikasi, peneliti 
menggunakan  GloVe  6B  word  embedding  dengan  dimensi 
word  vector  sebesar  300.  Pada  Tabel  IV  ditunjukkan  contoh 
dari GloVe 6B word embedding. Dalam contoh tersebut, setiap 
kata  dicirikan  dengan  300  angka  dari  hasil  pelatihan 
menggunakan algoritma deep learning. 

TABEL IV 
CONTOH GLOVE 6B WORD EMBEDDING 
Dimensi 
299 
-0.022394 
-0.61651 

Dimensi 
2 
0.21318 
0.45908 

… 
… 

Dimensi 
1 
0.04656 
-0.50148 

… 

Word 

the 
college 

Dimensi 
300 
0.13684 
0.22215 

Setelah data teks diekstraksi, peneliti menerapkan dua model 
klasifikasi pada data yang telah berbentuk numerik. Data akan 
diuji 
validation  menggunakan 
StratifiedKFold  pada  Python  karena  cocok  digunakan  untuk 
permasalahan imbalanced data [26].  

dengan  5-fold 

cross 

Parameter  yang  digunakan  dalam  LSTM  yaitu  unit  LSTM 
sebesar  16,  dropout  0.5,  dan  dense  layer  1  dengan  fungsi 

 5 / 8 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

TABEL VII 
PERBANDINGAN HASIL PERFORMA LSTM DAN BILSTM 
Presisi 
67.31% 
67.76% 

Akurasi 
82.25% 
82.72% 

Recall 
65.88% 
68.55% 

F1-score 
66.26% 
67.82% 

Model 
LSTM 
BiLSTM 

E. Pemodelan Topik 

Pemodelan  topik  dilakukan  untuk  mengetahui  gambaran 
umum perbincangan mahasiswa dengan indikasi depresi baik 
ringan  maupun  berat.  Pemodelan  dilakukan 
depresi 
menggunakan  algoritma  Latent  Dirichlet  Allocation  (LDA) 
dengan memanfaatkan library gensim pada Python. 

Data yang digunakan adalah data tweet berbahasa Indonesia 
yang telah dipraproses hingga tahap normalisasi. Data ini perlu 
dilakukan  praproses  lebih  lanjut  menggunakan  stopword 
removal  dan  filter  jumlah  data  menyesuaikan  jumlah  kelas 
depresinya.  Hasil  praproses  data  untuk  pemodelan  topik 
ditunjukkan pada Tabel VIII. 

TABEL VIII 
CONTOH HASIL PRAPROSES DATA PEMODELAN TOPIK 

Label 
Depresi 
berat (1) 

Sebelum Praproses 
sekarang aku tahu kenapa banyak yang 
stres  atau 
tertekan  karena  skripsi 
sampai  cuti  karena  capai  ternyata 
rasanya seperti begini 

Setelah Praproses 
tertekan 
stres 
skripsi cuti capai 

Depresi 
ringan (0) 

lagi  stres  sekali  sampai  tiap  detik 
makan melulu 

stres  detik  makan 
melulu 

jumlah 

Penentuan 

topik  yang  optimal  menggunakan 
pendekatan limit topik, di mana peneliti membatasi limit topik 
sebanyak 2-20 topik dengan iterasi sebanyak 100 kali. Adapun 
penentuan  topik  yang  optimal  akan  diuji  menggunakan 
coherence score. Jumlah topik dengan skor coherence terbesar 
akan  menjadi  banyaknya  topik  yang  akan  digunakan  dengan 
batasan bahwa jumlah topik tersebut tidak terlalu besar. Hasil 
grafik dan nilai coherence score untuk kedua kelas ditunjukkan 
pada Gambar 9 dan 10. 

aktivasi sigmoid. Kemudian, dalam proses fitting, epoch yang 
digunakan sebesar 20 dan  batch size sebesar 128. Parameter-
parameter ini merujuk pada sumber  [27] dalam penelitiannya 
untuk  mendeteksi  depresi  menggunakan  LSTM.  Adapun 
optimizer  yang  digunakan  ditentukan  langsung  oleh  peneliti, 
yaitu optimizer ‘Adam’.  

Hasil klasifikasi tweet depresi dengan LSTM menggunakan 
5-fold cross validation menunjukkan rata-rata akurasi sebesar 
82.25%, presisi sebesar 67.31%, recall sebesar 65.88%, dan f1-
score  sebesar  66.26%  yang  ditunjukkan  pada  Tabel  V.  Nilai 
presisi,  recall,  dan  f1-score  yang  rendah  dapat  disebabkan 
karena masalah data yang tidak seimbang. 

TABEL V 
HASIL PERFORMA MODEL LSTM 
Presisi 
67.03% 
61.32% 
67.42% 
70.96% 
69.81% 
67.31% 

Recall 
68.54% 
74.58% 
67.42% 
57.38% 
61.46% 
65.88% 

Akurasi 
82.67% 
80.73% 
82.67% 
82.44% 
82.70% 
82.25% 

Iterasi ke- 
1 
2 
3 
4 
5 
Rata-rata 

F1-score 
67.78% 
67.30% 
67.42% 
63.45% 
65.37% 
66.26% 

Parameter  yang  digunakan  dalam  BiLSTM  yaitu  unit 
BiLSTM sebesar 16, dropout 0.5, dense layer 10 dengan fungsi 
aktivasi relu, dan terakhir dense layer 1 dengan fungsi aktivasi 
sigmoid. Penentuan dense layer merujuk pada penelitian [21] 
yang  melakukan  deteksi  depresi  menggunakan  BiLSTM. 
Adapun  epoch,  batch  size,  maupun  optimizer  spesifikasinya 
sama seperti model LSTM. 

Hasil 

tweet 

depresi 

klasifikasi 

dengan  BiLSTM 
menggunakan  5-fold  cross  validation  menunjukkan  rata-rata 
akurasi sebesar 82.72%, presisi sebesar 67.76%, recall sebesar 
68.55%, dan  f1-score sebesar 67.82% yang ditunjukkan pada 
Tabel VI. Nilai presisi, recall, dan f1-score yang rendah dapat 
disebabkan karena masalah data yang tidak seimbang. 

TABEL VI 
HASIL PERFORMA MODEL BILSTM 
Presisi 
73.31% 
69.74% 
71.38% 
60.33% 
64.03% 
67.76% 

Recall 
65.59% 
67.98% 
60.96% 
71.87% 
76.37% 
68.55% 

Akurasi 
84.50% 
83.64% 
83.12% 
79.98% 
82.33% 
82.72% 

Iterasi ke- 
1 
2 
3 
4 
5 
Rata-rata 

F1-score 
69.24% 
68.85% 
65.76% 
65.60% 
69.66% 
67.82% 

Perbandingan  dari  kedua  model  deep 

learning  yang 
digunakan ditunjukkan pada Tabel VII. Tabel ini menunjukkan 
hasil  rata-rata  evaluasi  metrik  5-fold  cross  validation  pada 
seluruh  kelas.  Terlihat  bahwa  metode  yang  lebih  baik 
performanya  adalah  BiLSTM  karena  secara  keseluruhan 
memberikan  hasil  yang  lebih  baik  dibandingkan  LSTM 
meskipun tidak terlalu berbeda secara signifikan. Hal ini terjadi 
karena BiLSTM mempunyai kelebihan yang dapat mengatasi 
kelemahan  LSTM,  yakni  memproses  informasi  dari  dua  arah 
sebagaimana yang telah  dijelaskan oleh penelitian sebelumnya 
[15]. Namun, dalam prosesnya BiLSTM membutuhkan waktu 
komputasi yang lebih lama dibandingkan dengan LSTM. 

Gambar 9. Grafik coherence score pada kelas depresi ringan (kiri) dan depresi 
berat (kanan) 

 6 / 8 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Gambar 10. Nilai coherence score pada kelas depresi ringan (kiri) dan depresi 
berat (kanan) 

Berdasarkan grafik skor koherensi kelas depresi ringan dan 
berat yang ditunjukkan pada Gambar 9, terlihat bahwa jumlah 
19  topik  memiliki  nilai  yang  paling  tinggi.  Gambar  10 
memperjelas bahwa 19 topik memiliki nilai coherence tertinggi 
dengan nilai untuk kelas depresi ringan sebesar 0.400203 dan 
depresi  berat  sebesar  0.363278.  Namun,  jumlah  topik  yang 
terlalu  banyak  dapat  membentuk  model  yang  tumpang  tindih 
pada  setiap  topik  dan  sulit  untuk  diinterpretasikan  [28], 
sehingga  pada  kasus  ini  jumlah  topik  yang  dipilih  adalah 
sebanyak 5 topik karena dari rentang 2-5 topik terlihat bahwa 
jumlah 5 topik memiliki nilai yang paling tinggi dengan nilai 
coherence  pada  kelas  depresi  ringan  sebesar  0.263995  dan 
depresi berat sebesar 0.267982. 

Berikut  ditunjukkan  grafik  intertopic  distance  map  yang 
menunjukkan  sebaran  topik  menggunakan  pyLDAvis  untuk 
kedua  kelas  pada  Gambar  11.  Sebagian  besar  topik  telah 
menyebar di seluruh kuadran. Meskipun terdapat 2 topik yang 
beririsan  (topik  1  dengan  4  di  kelas  depresi  ringan  dan  juga 
depresi  berat),  tidak  ada  topik  yang  beririsan  penuh  atau 
tumpang  tindih.  Sehingga  kedua  model  ini  sudah  dapat 
dikategorikan cukup baik. 

4 

5 

Topik 
1 

2 

3 

4 

5 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

sedih,  menangis, 
tips_biar,  dosen, 
gugup, 

panik, 
skripsi, 
telepon_genggam, 
teman, sakit_hati 
sedih, 
pengin_menangis, 
kesel, 
sidang_skripsi, 
bingung, kkn 

menangis, 
pas, 
bayar_ukt, 
semester, 

Tekanan menghadapi skripsi dan 
komunikasi  dengan  dosen  atau 
teman 

Keluhan 
ukt 

tentang  pembayaran 

TABEL X 
INTERPRETASI PEMODELAN TOPIK KELAS DEPRESI BERAT 
Pembahasan 
Emosi  negatif  yang  dihadapi 
saat belajar 

Kata Kunci 
pas, semester, kuliah, sedih, 
marah,  orang_tua,  belajar, 
pakai, sakit, mohon 
ngerjain_skripsi, 
skripsi, 
matkul, tugas, besok, kelas, 
pas, sedih, sidang, marah 
tinggal_kos, 
ngerjain_tugas, 
kos, 
bimbang,  tugas,  uts,  sedih, 
kuliah, 
homesick, 
tugas_kelompok 
orang_tua, semester, orang, 
tua, 
sedih, 
pengin_menangis,  pengin, 
kangen_rumah, 
habis, 
melulu 
sedih, 
kampus, 
kuliah, 
laptop, kuliah_offline, tidur, 
skripsi, 
semester, 
rusak, 
kerja 

Tekanan 
terkait  penyelesaian 
skripsi  dan  proyek  akademik 
lainnya 
Tekanan  mahasiswa  perantau 
yang  menanggung 
beban 
akademik 

Perasaan 
perantau  kepada  orang 
(homesick) 

rindu  mahasiswa 
tua 

Tantangan kehidupan akademik, 
seperti 
dan 
tekanan untuk menyeimbangkan 
kuliah dan bekerja 

offline 

kuliah 

Gambar  11.  Sebaran topik  pada  kelas depresi  ringan (kiri) dan depresi  berat 
(kanan) 

Hasil  interpretasi  pemodelan  topik  untuk  kelas  depresi 
ringan ditunjukkan pada Tabel IX. Sedangkan hasil interpretasi 
pemodelan  topik  untuk  kelas  depresi  berat  ditunjukkan  pada 
Tabel X. 

Topik 
1 

2 

3 

TABEL IX 
INTERPRETASI PEMODELAN TOPIK KELAS DEPRESI RINGAN 

Kata Kunci 
sedih,  menangis,  semester, 
menambah_semester, 
dosen_pembimbing,  pakai, 
sks, takut, penelitian, data 
orang_tua, ngerjain_tugas, 
orang,  menangis, 
tua, 
tinggal_kos, 
sedih,  kos, 
tugas, kuliah 
sedih, 
tugas_kelompok, 
kuliah, 
tugas, 
kuliah_offline, uts, lulus 

menangis, 
pusing, 
semester, 

Pembahasan 
Ketakutan mahasiswa akan masa 
belajar yang berkepanjangan dan 
komunikasi 
dosen 
pembimbing 
Tekanan  mahasiswa  perantau 
yang  menanggung 
beban 
akademik 

dengan 

Tantangan  terkait  perkuliahan 
seperti  mengerjakan  tugas  dan 
tugas  kelompok,  ujian,  dan 
kuliah offline 

Berdasarkan kata kunci maupun interpretasi topik pada kelas 
depresi ringan maupun depresi berat, terdapat 3 masalah umum 
yang diperbincangkan. 
1.  Masalah akademik, seperti tugas, ujian, dan skripsi. 
2.  Masalah sosial, seperti hubungan dengan orang tua, teman, 

dan dosen. 

3.  Masalah lainnya, seperti merantau, pembayaran UKT, dan 

bekerja. 

tuntutan  pendidikan,  banyaknya 

Menurut  penelitian  [7],  mahasiswa  seringkali  merasa 
tertekan  dengan 
tugas 
pembelajaran  yang  harus  diselesaikan,  pelaksanaan  ujian, 
penyelesaian  tugas  ilmiah  di  akhir  pendidikan,  permasalahan 
dalam  pertemanan  dan  dalam  keluarga.  Faktor-faktor  ini 
seringkali  menjadi  pemicu  utama  timbulnya  depresi  pada 
mahasiswa.  Selain  itu,  faktor  lain  yang  memperkuat  depresi 
adalah  kondisi  mahasiswa  yang  jauh  dari  keluarga  seperti 
mahasiswa  rantau  yang  tinggal  di  kos  atau  kontrakan  karena 
perasaan kesepian tanpa adanya dukungan dari orang terdekat. 
Sehingga  dari  pemaparan  tersebut,  dapat  dikatakan  bahwa 
terdapat kesesuaian antara hasil pemodelan topik kelas depresi 
ringan  maupun  berat  dalam  penelitian  ini  dengan  teori  pada 
penelitian sebelumnya. 

VII. 

PENUTUP 

A. Kesimpulan  
1.  Dari  seluruh  tweet  akun  @collegemenfess  yang  telah 
tweet  yang 

terdapat  sebanyak  48.98% 

dibersihkan, 

 7 / 8 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
terdeteksi  mengindikasikan  depresi.  Adapun  hasil 
pengelompokkan  tweet  depresif  menunjukkan  bahwa 
sebesar 73.42% tweet mengindikasikan depresi ringan dan 
sebesar 26.58% tweet mengindikasikan depresi berat. 
2.  Model  LSTM  dan  BiLSTM  berhasil  digunakan  untuk 
klasifikasi  tingkat  depresi  mahasiswa  pada  akun  Twitter 
@collegemenfess  dengan  nilai  akurasi  masing-masing 
sebesar 82.25% dan 82.72%. 

3.  Secara  keseluruhan,  metode  klasifikasi  BiLSTM 
memberikan  performa  yang  lebih  baik  dibandingkan 
metode  LSTM  karena  BiLSTM  dapat  memproses 
informasi  dari  dua  arah,  sedangkan  LSTM  hanya 
memproses dari satu arah. 

4.  Hasil  pemodelan  topik  menggunakan  LDA  untuk  kelas 
depresi ringan maupun depresi berat dengan jumlah 5 topik 
sama-sama  menghasilkan  tiga  pembahasan  umum,  yaitu 
terkait akademik, sosial, dan hal lainnya. Hasil ini cukup 
berkaitan  dengan  penelitian  yang  menyatakan  bahwa 
penyebab  depresi  paling  umum  pada  mahasiswa  adalah 
masalah akademik dan masalah sosial. 

B. Saran 
1.  Menggunakan  fitur  sentimen  maupun  basic  emotion 
dengan  kamus  berbahasa  Indonesia  agar  dapat  menjaga 
keutuhan makna kata aslinya. 

2.  Meningkatkan  kualitas  aturan  pelabelan  data  dan 
memverifikasikan  hasilnya  kepada  pakar  yang  kompeten 
di bidang kesehatan mental, khususnya terkait depresi. 
3.  Menambahkan model lainnya untuk melakukan klasifikasi 
data, baik machine learning maupun deep learning. 
4.  Hasil dari pemodelan topik dalam penelitian ini diharapkan 
dapat  dijadikan  sebagai  bahan  untuk  meneliti  penyebab 
depresi mahasiswa secara rinci. 

DAFTAR PUSTAKA 
[1]  WHO,  “Depression,”  2021.  https://www.who.int/en/news-room/fact-

sheets/detail/depression (accessed Mar. 22, 2023). 

[2]  Kemenkes 

RI, 

“Pengertian 
https://promkes.kemkes.go.id/pengertian-kesehatan-mental 
Jan. 09, 2023). 

Kesehatan  Mental,” 

2018. 
(accessed 

[3]  Kemenkes  RI,  “Laporan  Riskesdas  2018  Nasional.”  Lembaga  Penerbit 
Badan Penelitian dan Pengembangan Kesehatan, Jakarta, p. 674, 2019, 
[Online]. Available: http://repository.bkpk.kemkes.go.id/3514/1/Laporan 
Riskesdas 2018 Nasional.pdf. 
J.  Colarossi,  “Mental  Health  of  College  Students  Is  Getting  Worse,” 
Boston 
2022. 
https://www.bu.edu/sph/news/articles/2022/mental-health-of-college-
students-is-getting-worse/ (accessed Mar. 21, 2023). 

University 

Health, 

School 

Public 

[4] 

of 

[5]  U.  Hasanah,  N.  L.  Fitri,  S.  Supardi,  and  L.  PH,  “Depression  Among 
College Students Due to the COVID-19 Pandemic,” J. Keperawatan Jiwa, 
vol. 8, no. 4, p. 421, 2020, doi: 10.26714/jkj.8.4.2020.421-424. 

[6]  R.  G.  Kamble,  “Academic  Stress  and  Depression  Among  College 

Students,” 2018, doi: 10.24941/ijcr.33132.12.2018. 

[7]  D. I. Angraini, “Hubungan Depresi dengan Status Gizi,” Medula Unila, 

[8] 

vol. 2, no. 2, pp. 39–46, 2014. 
I.  Syarif,  N.  Ningtias,  and  T.  Badriyah,  “Study  on  Mental  Disorder 
Detection  via  Social  Media  Mining,”  2019  4th  Int.  Conf.  Comput. 
Commun. 
doi: 
2019, 
ICCCS 
10.1109/CCCS.2019.8888096. 

Secur. 

2019, 

1–6, 

pp. 

[9]  A.  Jeri-Yabar  et  al.,  “Association  between  social  media  use  (Twitter, 
Instagram,  Facebook)  and  depressive  symptoms:  Are  Twitter  users  at 
higher risk?,” Int. J. Soc. Psychiatry, vol. 65, no. 1, pp. 14–19, 2019, doi: 
10.1177/0020764018814270. 

[10]  B. N. Sangaji, “Autobase, Fitur Twitter Yang Hanya Ada di Indonesia!,” 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Digstraksi,  2022.  https://digstraksi.com/autobase-fitur-twitter-yang-
hanya-ada-di-indonesia/ (accessed Jan. 12, 2023). 

[11]  S.  Dixon,  “Leading  countries  based  on  number  of  Twitter  users  as  of 
2022. 

January 
https://www.statista.com/statistics/242606/number-of-active-twitter-
users-in-selected-countries/ (accessed Mar. 31, 2023). 

Statista, 

2022,” 

[12]  C. C. Aggarwal and C. X. Zhai, Mining text data, vol. 9781461432. 2013. 
[13]  N. K. Manaswi, “RNN and LSTM BT  - Deep Learning with Applications 
Using Python : Chatbots and Face, Object, and Speech Recognition With 
TensorFlow and Keras,” N. K. Manaswi, Ed. Berkeley, CA: Apress, 2018, 
pp. 115–126. 

[14]  X.  Bai,  “Text  classification  based  on  LSTM  and  attention,”  in  2018 
Thirteenth International Conference on Digital Information Management 
(ICDIM), 2018, pp. 29–32, doi: 10.1109/ICDIM.2018.8847061. 

[15]  F.  A.  Gers,  J.  Schmidhuber,  and  F.  Cummins,  “Learning  to  forget: 
Continual prediction with LSTM,” IEE Conf. Publ., vol. 2, no. 470, pp. 
850–855, 1999, doi: 10.1049/cp:19991218. 

[16]  J. C. Campbell, A. Hindle, and E. Stroulia, “Latent Dirichlet Allocation: 
Extracting Topics from Software Engineering Data,” Art Sci. Anal. Softw. 
Data,  vol.  3,  pp.  139–159,  2015,  doi:  10.1016/B978-0-12-411519-
4.00006-9. 

[17]  B. Kholifah, I. Syarif, and T. Badriyah, “Mental Disorder Detection via 
Social Media Mining using Deep Learning,” Kinet. Game Technol. Inf. 
Syst. Comput. Network, Comput. Electron. Control, vol. 4, pp. 309–316, 
2020, doi: 10.22219/kinetik.v5i4.1120. 

[18]  N. Hayatin, “Implementasi Multinomial Naïve Bayes Untuk Klasifikasi 
Data  Tweets  Mengandung  Term  Depresi,”  Pros.  SENTRA  (Seminar 
Teknol.  dan  Rekayasa),  vol.  0,  no.  6,  pp.  344–349,  2021,  [Online]. 
Available: 
http://research-
report.umm.ac.id/index.php/sentra/article/view/3921. 

[19]  K.  S.  Nugroho,  I.  Akbar,  A.  N.  Suksmawati,  and  I.  Istiadi,  “Deteksi 
Depresi dan Kecemasan Pengguna Twitter,” 4th Conf. Innov. Appl. Sci. 
Technol. (CIASTECH 2021), no. Ciastech, pp. 287–296, 2021. 

[20]  D.  Ridhwanullah  and  D.  H.  Fudholi,  “Pemodelan  Topik  pada  Cuitan 
tentang  Penyakit  Tropis  di  Indonesia  dengan  Metode  Latent  Dirichlet 
Allocation,”  J.  Ilm.  SINUS,  vol.  20,  no.  1,  p.  11,  2022,  doi: 
10.30646/sinus.v20i1.589. 

[21]  J.  Cha,  S.  Kim,  and  E.  Park,  “A  lexicon-based  approach  to  examine 
depression detection in social media: the case of Twitter and university 
community,” Humanit. Soc. Sci. Commun., vol. 9, no. 1, pp. 1–10, 2022, 
doi: 10.1057/s41599-022-01313-2. 

[22]  M.  De  Choudhury,  M.  Gamon,  S.  Counts,  and  E.  Horvitz,  “Predicting 
Depression via Social Media,”  Proc. Int. AAAI Conf. Web Soc. Media, 
vol.  7,  no.  1  SE-Full  Papers,  pp.  128–137,  Aug.  2021,  doi: 
10.1609/icwsm.v7i1.14432. 

[23]  E. Hutto, C.J. and Gilbert, “VADER: A Parsimonious Rule-based Model 
for  Sentiment  Analysis  of  Social  Media  Text,”  Eighth  Int.  AAAI  Conf. 
Weblogs 
[Online].  Available: 
18, 
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPap
er/8109. 

Soc.  Media, 

2014, 

p. 

[24]  S.  M.  Mohammad  and  P.  D.  Turney,  “Emotions  evoked  by  common 
words and phrases: using mechanical turk to create an emotion lexicon,” 
CAAGET  ’10  Proc.  NAACL  HLT  2010  Work.  Comput.  Approaches  to 
Anal. Gener. Emot. Text, no. June, pp. 26–34, 2010, [Online]. Available: 
https://aclanthology.org/W10-0204. 

[25]  D. Mimno, H. M. Wallach, E. Talley, M. Leenders, and A. McCallum, 
“Optimizing semantic coherence in topic models,” EMNLP 2011 - Conf. 
Empir.  Methods  Nat.  Lang.  Process.  Proc.  Conf.,  no.  2,  pp.  262–272, 
2011. 

[26]  J.  Brownlee,  “How  to  Fix  k-Fold  Cross-Validation  for  Imbalanced 
2020. 

Classification,” 
https://machinelearningmastery.com/cross-validation-for-imbalanced-
classification/ (accessed Jun. 28, 2023). 

Learning 

Machine 

Mistery, 

[27]  A. Apoorva, “Depression Detection on Twitter using hybrid CNN-LSTM 
https://github.com/aapoorv-tf/Depression-Detection 

2021. 

Model,” 
(accessed Jan. 01, 2023). 

[28]  M.  Schweinberger,  “Topic  Modeling  with  R,”  LADAL,  2023. 

https://ladal.edu.au/topicmodels.html (accessed Jun. 25, 2023). 

 8 / 8 

 
 
 
","2023-12-19T08:13:10.992621Z",221910697,"[{""start"":880,""end"":1123,""text"":""\\nyang menanggung\\nbeban\\nakademik\\n\\nPerasaan\\nperantau kepada orang\\n(homesick)\\n\\nrindu mahasiswa\\ntua\\n\\nTantangan kehidupan akademik,\\nseperti\\ndan\\ntekanan untuk menyeimbangkan\\nkuliah dan bekerja\\n\\noffline\\n\\nkuliah\\n\\nGambar 11. Sebaran topik pa"",""labels"":[""Tujuan""]},{""start"":1151,""end"":1198,""text"":""e"",""labels"":[""Temuan""]},{""start"":1201,""end"":1327,""text"":""las depresi ringan (kiri) dan depresi berat\\n(kanan)\\n\\nHasil interpretasi pemodelan topik untuk kelas depresi\\nringan ditunjukkan pada Tabel IX. Sedangkan hasil interpretasi\\npemodelan topik untuk kelas depresi berat ditunjukkan pada\\nTabel X.\\n\\nTopik\\n1\\n\\n2\\n\\n3\\n\\nTABEL IX\\nINTERPRETASI PEMODELAN TOPIK KELAS DEPRESI RINGAN\\n\\nKata Kunci\\nsedih, menangis, semester,\\nmenambah_semester,\\ndosen_pembimbing, pakai,\\nsks, takut, penelitian, data\\norang_tua, ngerjain_tugas,\\norang, menangis,\\ntua,\\ntinggal_kos,\\nsedih, kos,\\ntugas, kuliah\\nsedih,\\ntugas_kelompok,\\nkuliah,\\ntugas,\\nkuliah_offline, uts, lulus\\n\\nmenangis,\\npusing,\\nsemester,\\n\\nPembahasan\\nKetakutan mahasiswa akan masa\\nbelajar yang berkepanjangan dan\\nkomunikasi\\ndosen\\npembimbing\\nTekanan mahasiswa perantau\\nyang menanggung\\nbeban\\nakademik\\n\\ndengan\\n\\nTantangan terkait perkuliahan\\nseperti mengerjakan tugas dan\\ntugas kelompok, ujian, dan\\nkuliah offline\\n\\nBerdasarkan kata kunci maupun interpretasi topik pada kelas\\ndepresi ringan maupun depresi berat, terdapat 3 masalah umum\\nyang diperbincangkan.\\n1. Masalah akademik, seperti tugas, ujian, dan skripsi.\\n2. Masalah sosial, seperti hubungan dengan orang tua, teman,\\n\\ndan dosen.\\n\\n3. Masalah lainnya, seperti merantau, pembayaran UKT, dan\\n\\nbekerja.\\n\\ntuntutan pendidikan, banyaknya\\n\\nMenurut penelitian [7], mahasiswa seringkali merasa\\ntertekan dengan\\ntugas\\npembelajaran yang harus diselesaikan, pelaksanaan ujian,\\npenyelesaian tugas ilmiah di akhir pendidikan, permasalahan\\ndalam pertemanan dan dalam keluarga. Faktor-faktor ini\\nseringkali menjadi pemicu utama timbulnya depresi pada\\nmahasiswa. Selain itu, faktor lain yang memperkuat depresi\\nadalah kondisi mahasiswa yang jauh dari keluarga seperti\\nmahasiswa rantau yang tinggal di kos atau kontrakan karena\\nperasaan kesepian tanpa adanya dukungan dari orang terdekat.\\nSehingga dari pemaparan tersebut, dapat dikatakan bahwa\\nterdapat kesesuaian antara hasil pemodelan topik kelas depresi\\nringan maupun berat dalam penelitian ini dengan teori pada\\npenelitian sebelumnya.\\n\\nVII.\\n\\nPENUTUP\\n\\nA. Kesimpulan\\n1. Dari seluruh tweet akun @collegemenfess yang telah\\ntweet yang\\n\\nterdapat sebanyak 48.98%\\n\\ndibersihkan,\\n\\n7 \/ 8\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\fterdeteksi mengindikasikan depresi. Adapun hasil\\npengelompokkan tweet depresi"",""labels"":[""Temuan""]},{""start"":1340,""end"":1399,""text"":"""",""labels"":[""Temuan""]},{""start"":1406,""end"":1427,""text"":"""",""labels"":[""Metode""]},{""start"":1542,""end"":1558,""text"":""men"",""labels"":[""Metode""]},{""start"":10549,""end"":10560,""text"":"""",""labels"":[""Metode""]},{""start"":10669,""end"":10692,""text"":"""",""labels"":[""Metode""]},{""start"":1535,""end"":1681,""text"":""menunjukkan bahwa\\nsebesar 73.42% tweet mengindikasikan depresi ringan dan\\nsebesar 26.58% tweet mengindikasikan depresi berat.\\n2. Model LSTM dan BiLSTM berhasil digunakan untuk\\nklasifikasi tingkat depresi mahasiswa pada akun Twitter\\n@collegemenfess dengan nilai akurasi masing-masing\\nsebesar 82.25% dan 82.72%.\\n\\n3. Secara keseluruhan, metode klasifikasi BiLSTM\\nmemberikan performa yang lebih baik dibandingkan\\nmetode LSTM karena BiLSTM dapat memproses\\ninformasi dari dua arah, sedangkan LSTM hanya\\nmemproses dari satu arah.\\n\\n4. Hasil pemodelan topik menggunakan LDA untuk kelas\\ndepresi ringan maupun depresi berat dengan jumlah 5 topik\\nsama-sama menghasilkan tiga pembahasan umum, yaitu\\nterkait akademik, sosial, dan hal lainnya"",""labels"":[""Temuan""]},{""start"":35396,""end"":35440,""text"":"""",""labels"":[""Temuan""]},{""start"":35454,""end"":35496,""text"":""8"",""labels"":[""Temuan""]},{""start"":35503,""end"":35635,""text"":"""",""labels"":[""Temuan""]},{""start"":35729,""end"":35828,""text"":"""",""labels"":[""Temuan""]},{""start"":35948,""end"":36062,""text"":"""",""labels"":[""Temuan""]},{""start"":36089,""end"":36162,""text"":"""",""labels"":[""Temuan""]}]",856.431,"2023-12-19T08:13:15.340296Z"
5,"1","Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

Deteksi Pergerakan dan Laju Pertumbuhan PDB 
Menggunakan Klasifikasi Berita Online 
Studi Kasus Portal Berita Detik.com 
Dinda Pusparahmi Sholawatunnisa (221910740, 4SD1) 

Dosen Pembimbing: Dr. Eng. Lya Hulliyyatus Suadaa, S.ST, M.T 

Ringkasan—Data  Produk  Domestik  Bruto  (PDB)  merupakan 
informasi  strategis  yang  dimanfaatkan  banyak  pihak.  Dari 
pergerakan  PDB    dapat  diketahui  pola  pertumbuhan  ekonomi 
nasional  serta  sektor  ekonomi  yang  mengalami  peningkatan  atau 
penurunan.  Perkembangan  teknologi  terkini  memungkinkan  berita 
dirilis  secara  real-time.  Berita  online  aktual  terkait  ekonomi  yang 
tersedia  secara  masif  dapat  dijadikan  sumber  data  alternatif  yang 
potensial untuk analisis dinamika ekonomi. Penelitian ini bertujuan 
untuk  mendeteksi  pergerakan  dan 
laju  pertumbuhan  PDB 
menggunakan  klasifikasi  berita  online.  Data  dikumpulkan  dengan 
teknik  scraping  berdasarkan  kata  kunci.  Model  klasifikasi  yang 
diusulkan  adalah 
learning  dari  pre-trained  model 
Transformers,  sedangkan  algoritma  machine  learning  digunakan 
sebagai  baseline  model.  Berdasarkan  hasil  klasifikasi  untuk  deteksi 
pergerakan PDB dan laju pertumbuhannya, pre-trained Transformers 
dengan  model  IndoBERT  berhasil  melampaui  performa  machine 
learning dengan akurasi terbaik 0.8880 dan 0.7899. SVM memberikan 
akurasi  terbaik  sebesar  0.8440  dan  0.7811,  diantara  model  machine 
learning.  Penelitian  ini  juga  mengekstraksi  fitur  penting  pada  data 
berita panjang dengan sentences selection menggunakan prinsip text 
summarization dan pencarian kata kunci yang berhasil meningkatkan 
performa klasifikasi dan mempercepat waktu pemrosesan. 

transfer 

Kata  Kunci—Pre-trained  Transformers,  Machine  Learning,  NLP, 

Transfer learning, Long Text handling 

I.  LATAR BELAKANG 
Dunia mengalami banyak krisis sejak tahun 2020, mulai dari 
krisis kesehatan dan pembatasan sosial akibat pandemi Covid-
19 hingga konflik militer dan perang dagang antar negara yang 
menghambat  rantai  pasok  internasional.  Krisis  yang  terjadi 
memberikan  tekanan  berat  terhadap  perekonomian  global, 
hingga beberapa negara termasuk Indonesia resmi dinyatakan 
mengalami  resesi.  Berdasarkan  konvensi  yang  diikuti  secara 
luas, resesi didefinisikan terjadi ketika Produk Domestik Bruto 
(PDB)  berkontraksi  selama  dua  kuartal  berturut-turut  [1]. 
Resesi  yang  dialami  Indonesia  berlangsung  selama  empat 
kuartal  terhitung  dari  kuartal  II-2020  pertumbuhan  ekonomi 
Indonesia  berkontraksi  sebesar  5,32%  dan  melanjutkan 
pergerakan negatif untuk dua kuartal berikutnya yakni kuartal 
III-2020  sebesar  3,49%  dan  kuartal  IV  sebesar  2,17%. 
Pertumbuhan  ekonomi  Indonesia  kian  membaik,   dengan 
pergerakan  PDB  positif  sebesar  7,07%  pada  kuartal-II  2021. 
Ekonomi Indonesia baru bangkit pada kuartal II-2021 dengan 
pergerakan PDB sebesar 7,07% [2]. 

Tidak  hanya  digunakan  untuk  mengetahui  indikasi  resesi 
ekonomi  suatu  negara.  Pertumbuhan  ekonomi  nasional  yang 
dapat diperoleh dari data  PDB merupakan informasi strategis 
yang  dimanfaatkan  banyak  pihak.  PDB  merupakan  statistik 
perekonomian  yang  paling  diperhatikan  karena  dianggap 
sebagai  ukuran  tunggal  terbaik  yang  mampu  menunjukkan 
total 
kesejahteraan  masyarakat 

serta  dapat  mengukur 

pendapatan  semua  individu  dalam  perekonomian  dan  total 
pembelanjaan  negara  untuk  barang-jasa  hasil  perekonomian 
secara  bersamaan  [3].  Berdasarkan  hal  ini,  PDB  banyak 
digunakan  pula  sebagai  instrumen  pembanding  pertumbuhan 
ekonomi  antarnegara.  Dengan  strategisnya  penggunaan  data 
PDB, Badan Pusat Statistik (BPS) menjadi instansi resmi yang 
ditugasi dalam penghitungan dan perilisan  data PDB.  

statistik 

Penghitungan  PDB  merupakan  perkerjaan  yang  kompleks. 
Hingga  saat  ini  penghitungan  PDB  dilakukan  menggunakan 
tiga  pendekatan,  yaitu  pendekatan  produksi,  pendekatan 
pendapatan,  dan  pendekatan  pengeluaran.  Nilai  PDB  yang 
diperoleh dengan tiga pendekatan penghitungan secara teroretis 
akan menghasilkan nilai yang sama. Tetapi, dalam praktiknya 
kerap  menghasilkan  nilai  yang  berbeda.  Perbedaan  hasil 
penghitungan  yang  diperoleh  dari  pendekatan  yang  berbeda 
dinamakan sebagai diskrepansi statistik. Penurunan persentase 
diskrepansi 
sebesar  5%  menjadi  2%  pada 
penghitungan PDB telah ditargetkan sebagai sasaran program 
Rencana  Strategis  BPS  Tahun  2020-2024  [4].  Deteksi 
pergerakan  PDB  menggunakan  berita  online  memang  tidak 
dapat menurunkan diskrepansi statistik PDB sebagaimana yang 
ditargetkan dalam Renstra BPS, namun dapat dijadikan sebagai 
data pendamping official statistics PDB yang dapat diperoleh 
lebih 
PDB 
untuk  mengamati 
antarperiode,   serta  sebagai  bentuk 
inisiasi  pemanfaatan 
sumber data alternatif dalam penelitian terkait official statistics. 
Selain kompleks, banyaknya sumber data yang perlu dianalisis 
dan digabungkan dalam penghitungan  official statistics PDB, 
membuat  proses  ini  memerlukan  banyak  waktu.  Saat  ini, 
periode waktu yang dibutuhkan oleh BPS untuk rilis data PDB 
triwulanan  sekitar  35  hari  setelah  triwulan  baru  dimulai. 
Sementara  itu,  seringkali  diperlukan  akses  real-time  akan 
informasi 
ketika 
mempertimbangkan seberapa cepat perekonomian berubah. 

pertumbuhan 

ekonomi, 

dinamika 

terutama 

cepat 

pelaku 

sebagai 

ekonomi 

Dengan mendeteksi pergerakan PDB, pemerintah, korporasi, 
dapat 
dan  masyarakat 
mengoptimalkan potensi keuntungan apabila pergerakan PDB 
terprediksi menuju ke arah positif. Sebaliknya, pendeteksian ini 
dapat  pula  dijadikan  sebagai  early  warning  system  dari 
perlambatan  ekonomi  bahkan  krisis  jika  pergerakan  PDB 
terdeteksi ke arah negatif. Dengan demikian, risiko resesi dapat 
terdeteksi  lebih  dini.  Akan  tetapi,  pergerakan  PDB  secara 
agregat  masih  terlalu  kompleks  untuk  dimanfaatkan.  PDB 
dihitung  dari  agregat  komponen  ekonomi  makro  yang  diolah 
sedemikian  sehingga  menghasilkan  angka  tunggal  sebagai 
kuantifikasi  perekonomian  domestik  negara.  Oleh  karena  itu, 
pergerakan PDB yang dideteksi perlu diklasifikasi sesuai sektor 

 1 / 8 

 
 
 
lapangan  usaha  agar  dapat  dimanfaatkan  oleh  pelaku  usaha 
secara  spesifik  dan  tepat  guna.  Tujuan  ini  menjadi  dasar 
digunakannya  PDB  pendekatan  produksi  yang  terdiri  dari  17 
sektor lapangan usaha yang berkontribusi dalam perekonomian 
domestik  sesuai  panduan  penghitungan  official  statistics 
PDB. Pemilihan  PDB  pendekatan  produksi  dilakukan  dengan 
pertimbangan kemudahan pengelompokkan dan pengumpulan 
berita  online  sebagai  input  penelitian.  Kata  kunci  yang 
berkaitan dengan 17 sektor lapangan usaha tersebut digunakan 
pada tahap pengumpulan berita online dengan teknik scraping.  
Berita  online  merupakan  produk  jurnalistik  yang  lebih 
mutakhir dibandingkan media cetak. Perkembangan teknologi 
terkini memungkinkan berita dirilis secara real-time, sehingga 
memberikan  keuntungan  sekaligus  tantangan  bagi  analisis 
statistik untuk memperoleh insights yang tepat dari data yang 
melimpah bahkan menuju ke arah information overload. Berita 
online  terkait  ekonomi  yang  dirilis  secara  masif  dan  aktual 
dapat  dijadikan  sumber  data  alternatif  yang  potensial  untuk 
mendeteksi  pergerakan  PDB.  Pemanfaatan  data  berita  dalam 
analisis  tren  maupun  dinamika  ekonomi  termasuk  kedalam 
pekerjaan natural language processing (NLP). Analisis bahasa 
natural memiliki tantangan untuk menangani  ambiguitas yang 
kerap  ditemui  dalam  konteks  kalimat  semantik  bahasa.  Kata 
yang sama bisa memiliki makna yang jauh berbeda tergantung 
dari konteks kalimat yang memuat kata tersebut. Permasalahan 
ini dapat diatasi dengan memanfaatkan language model (LM) 
berbasis  Transformers  dengan  mekanisme  “attention”  yang 
dapat  melihat  konteks  keseluruhan  kalimat  dan  memberikan 
konteks  berbeda  pada  kata  dan  frasa  yang  mirip  disesuaikan 
dengan  kalimat  dimana  kata  atau  frasa  muncul.  Language 
model  berbasis  Transformers  ini  telah  memberikan  banyak 
kemajuan  dalam  benchmark  pemrosesan  bahasa  natural  [5]. 
Penggunaan  language  model  berbasis  Transformers  dalam 
deteksi  pergerakan  PDB  menggunakan  berita  online 
diharapkan  dapat  memberikan  hasil  yang 
lebih  baik 
dibandingkan  penelitian  sebelumnya  [6]  yang  memperoleh 
hasil terbaik dari metode klasifikasi Random Forest. 

Berdasarkan 

II.  TUJUAN PENELITIAN 
latar  belakang  yang 
dirumuskan tujuan yang hendak dicapai dalam penelitian ini. 
1.  Membangun dataset untuk klasifikasi pergerakan dan laju 
pertumbuhan  PDB  pada  17  sektor  lapangan  usaha 
menggunakan data berita online. 

telah  diuraikan, 

2.  Mendeteksi  pergerakan  dan  laju  pertumbuhan  PDB 
menggunakan berita online dengan  transfer learning dari 
model  pre-trained  Transformers  dan  membandingkan 
performanya  dengan  machine  learning  sebagai  baseline 
model, 
terbaik  untuk 
direkomendasikan. 

sehingga  diperoleh  model 

3.  Mengekstraksi fitur penting pada data teks panjang untuk 
meningkatkan  performa  klasifikasi  laju  pertumbuhan 
PDB  dengan   transfer  learning  dari  model  pre-trained 
Transformers  dan  membandingkan performanya  dengan 
algoritma machine learning sebagai baseline model. 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

III. PENELITIAN TERKAIT 
Penelitian  terkait  deteksi  pergerakan  PDB  menggunakan 
berita  online  hingga  saat  ini  belum  banyak  dilakukan.  Pada 
penelitian  sebelumnya,  Khairani,  et.  al.  [6]  mendeteksi 
pergerakan  PDB  pada  14  sektor  lapangan  usaha  berdasarkan 
berita  online  yang  diambil  selama  periode  kuartal  pertama 
tahun  2021.  Scraping  data  berita  dilakukan  pada  lima  portal 
berita  online  dengan  jumlah  pengunjung  terbanyak.  Dari 
delapan algoritma klasifikasi yang diuji coba, diperoleh akurasi 
tertinggi sebesar 96.51% menggunakan Random Forest.  

Penelitian  terkait  klasifikasi  berita  online  dilakukan  oleh 
Wongso, et. al. [7] dengan mencari algoritma yang sesuai untuk 
klasifikasi  artikel  berita  berbahasa  Indonesia  ke  dalam  lima 
kelas  yaitu  ekonomi,  kesehatan,  teknologi,  olahraga,  dan 
politik. Penelitian ini melakukan beberapa perbandingan yaitu 
perbandingan  metode  feature  selection  dan  perbandingan 
classifiers. Metode feature selection yang dibandingkan adalah 
TF-IDF  dan  algoritma  SVD,  sedangkan  classifiers  yang 
dibandingkan  yaitu  Multinomial  Naïve  Bayes,  Multivariate 
Bernoulli  Naïve  Bayes,  dan  SVM.  Hasil  perbandingan 
menunjukkan  jika  TF-IDF  dan  Multinomial  Naïve  Bayes 
paling  unggul  dan  mampu  mengklasifikasikan  artikel 
berbahasa Indonesia dengan akurasi 85%.  

Penelitian  terkait  lainnya  memiliki  objek  penelitian  yang 
berbeda.  Walaupun  demikian,  memuat  tujuan  dan  metode 
penelitian  yang  relevan  untuk  topik  skripsi  yang  dikerjakan. 
Penelitian  Duarte,  et.  al.  [8]  memprediksi  penurunan  harga 
pada  bursa  saham  Brazil  menggunakan  sebelas  algoritma 
machine  learning.  Hasil  penelitian  menunjukkan  Gaussian 
Naïve Bayes (NB-G), SVM, dan ANN  adalah pilihan terbaik 
untuk  memprediksi  pergerakan  harga.  Dari  penelitiannya 
disimpulkan  jika NB-G, Logistic Regression (LR), dan SVM 
sangat  efektif,  cepat  dilatih,  serta  memiliki  pengaturan  yang 
mudah.  MLP  dan  XGB  juga  efektif  namun  menambah 
kompleksitas dalam penelitian untuk mencari parameter terbaik 
sehingga  memerlukan  waktu 
training  yang  lebih  lama. 
Berdasarkan hasil penelitian terkait metode klasifikasi, model 
yang menunjukkan hasil terbaik pada penelitian terkait deteksi 
pergerakan  ekonomi  yaitu  Random  Forest,  SVM,  dan  Naïve 
Bayes.  Oleh  karena  itu,  ketiga  model  tersebut  digunakan 
sebagai baseline model pada penelitian ini untuk dibandingkan 
performanya dengan hasil  dari pre-trained Transformers.  

harga 

prediksi 

Penelitian 

pergerakan 

dengan 
pengimplementasian  transfer  learning  dengan  pre-trained 
model  juga  telah  dilakukan  beberapa  peneliti,  diantaranya 
penelitian  Chen  [9]  yang  menggunakan  model  Fine-Tuned 
Contextualized-Embedding  Recurrent  Neural  Network  (FT-
CE-RNN) untuk memprediksi pergerakan harga saham jangka 
pendek  menggunakan  judul  berita  yang  direpresentasikan 
dengan contextualize vector yang dihasilkan dari BERT. Hasil 
penelitian  FT-CE-RNN  menunjukkan  performa  lebih  baik 
dibandingkan  seluruh  baseline  model  dengan  peningkatan 
akurasi  4.1%  dari  penggunaan  RNN.  Penelitian  Wei  dan 
Nguyen 
[10]  mengaplikasikan  model  BERT  untuk 
memanfaatkan  berita  pasar  modal  dan  finansial  untuk 
memprediksi  pergerakan harga  saham.  Penelitian  Sonkiya  et. 
al. [11] melakukan analisis sentimen menggunakan pre-trained 
Transformers  finBERT  pada  berita  dan  headlines  kemudian 

 2 / 8 

 
 
dilanjutkan  dengan  Generative  Adversarial  Network  (GAN) 
untuk memprediksi harga saham secara nominal. 

Berdasarkan  penelitian-penelitian  terkait  yang  dipaparkan 
dapat diketahui jika deteksi pergerakan PDB berdasarkan berita 
online  masih  terbatas.  Penelitian  terkait  deteksi  pergerakan 
harga banyak dilakukan untuk instrumen finansial yang dikenal 
volatil,  namun  tidak  banyak  penelitian  tekait  hal  ini  di 
Indonesia.  Metode  penelitian  machine  learning  konvensional 
juga masih banyak digunakan. Walaupun demikian, penelitian 
relevan 
terbaru  mulai  banyak  menggunakan  pre-trained 
language model Transformers. Hasil beberapa penelitian yang 
menerapkan transfer learning menunjukkan bahwa pre-trained 
Transformers  dapat  digunakan  untuk  mendeteksi  pergerakan 
teks  berita,  serta  hasil  evaluasi 
arah  harga  dari 
menunjukkan 
jika  pre-trained  Transformers  cenderung 
melampaui  hasil  dari  machine  learning  konvensional  [10]. 
Akan  tetapi,  penelitian-penelitian  ini  dikerjakan  untuk  objek 
penelitian instrumen saham yang dikenal memiliki pergerakan 
perubahan  harga  yang  cepat  (volatil),  sehingga  menjadi 
tantangan tersendiri karena memerlukan beberapa penyesuaian 
agar dapat diimplementasikan dalam deteksi pergerakan PDB 
yang  relatif  nonvolatil,  berbeda  signifikan  dengan  instrumen 
investasi yang dibahas pada penelitian sebelumnya 

input 

IV. METODE PENELITIAN  

A.  Batasan Penelitian 

Pada penelitian ini dilakukan pendeteksian pergerakan PDB 
untuk periode Q3 2022 dengan pendekatan pertumbuhan PDB 
riil. Untuk menghindari bias kenaikan harga, pelabelan berita 
online  difokuskan  pada  narasi  berita  yang  menjelaskan 
kenaikan  dan  penurunan  output  barang  dan 
jasa  yang 
diproduksi  dan  bukan  pergerakan  harga  berlaku  yang 
memerlukan standardisasi harga tahun dasar.  

B.  Tahapan Penelitian 

Tahapan penelitian yang akan dilakukan mengikuti alur 

pengerjaan seperti yang ditunjukkan pada Gambar 1.  

Gambar 1. Tahap Penelitian 

1.  Pengumpulan Data  
Dataset diperoleh dengan metode web scraping pada portal 
berita  online  Detik.com  dengan  kata  kunci  yang  telah 
diidentifikasi.  Detik.com  adalah  perusahaan  media  di  bawah 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

naungan  PT.  Trans  Corporation  yang  hanya  berbasis  online. 
Detik.com  memiliki  kanal  yang  secara  khusus  membahas 
juga  kanal  yang 
ekonomi,  yaitu  Detik  Finance  dan 
memfasilitasi  pemberitaan  lokal  dengan  cakupan  provinsi  di 
Indonesia seperti Detik Sumut dan Detik Jabar. Dengan adanya 
fitur  kanal,  kategori  dan  cakupan  pemberitaan  menjadi  lebih 
mudah  diidentifikasi.  Dilansir  dari  situs  SimilarWeb,  selama 
periode  yang  diteliti  yaitu  Juli  hingga  September  2022  situs 
Detik.com  telah  diakses  oleh  516.7  juta  pengunjung  dan 
menjadi peringkat pertama untuk kategori situs Penerbit Berita 
dan  Media  [12].  Kata  kunci yang  digunakan  merupakan  kata 
yang mendeskripsikan 17 sektor lapangan usaha, sehingga data 
yang  terkumpul  telah  teridentifikasi  untuk  setiap  sektornya 
untuk  memastikan  jika  semua  sektor  lapangan  usaha  telah 
terwakili  dalam  data.  Contoh  berita  online  yang  digunakan 
ditunjukkan  pada Gambar 2. 

Gambar 2. Berita dengan indikasi penurunan PDB pada kategori sektor H 

2.  Pelabelan Data 
Data berita online diseleksi untuk memperoleh berita yang 
relevan  dengan  tujuan  penelitian.  Berita  relevan  kemudian 
dilabeli  oleh  anotator  berjumlah  ganjil  mengikuti  pedoman 
yang  disusun  peneliti.  Label  akhir  ditentukan  dengan  prinsip 
majority  vote  dan  dinilai  reliabilitas  pelabelannya  dengan 
koefisien  Krippendorff’s  alpha.  Krippendorff’s  alpha 
merupakan  pengukuran  nonparametrik  untuk  anotator 
agreement,  yakni  mengukur  kekonsistenan  pemberian  skor 
antara dua atau lebih anotator terhadap unit analisis yang sama 
[13].  Prasyarat anotator dalam penelitian ini adalah memiliki 
pengetahuan  dasar  terkait  PDB.  Anotator  yang  berkontribusi 
pada penelitian ini adalah mahasiswa Politeknik Statistika STIS 
yang  telah  memperoleh  pembelajaran  mata  kuliah  official 
statistics PDB dan SNN.  

3.  Preprocessing Teks 
Tahap  preprocessing  yang  dilakukan  diantaranya  sebagai 

berikut. 

a.  Case folding dan cleaning 

Pada tahap ini dilakukan konversi huruf menjadi lower 
case, menghapus berita duplikat, tanda baca, dan spasi 
berlebih. 

b.  Stemming dan stopwords removal 

Tahap  ini  hanya  dilakukan  untuk  metode  machine 
learning,  yaitu  menghilangkan 
imbuhan  untuk 
memperoleh  kata  dasar  dan  menghapus  kata  yang 
tidak berarti signifikan seperti konjungsi dan preposisi 
[14].  Tahapan  ini  dilakukan  menggunakan  library 
PorterStemmer. 

 3 / 8 

 
 
 
 
 
 
 
c.  Tokenization  

Pada  tahap  ini  dilakukan  konversi  data  teks  menjadi 
unit  yang  lebih  kecil  yaitu  kata  pada  algoritma 
machine  learning [15].  Sedangkan, pada  pre-trained 
Transformers  menjadi  subkata.  Tahapan  tokenizing 
dilakukan menggunakan library NLTK. 

feature 

4.  Features Selection 
Data  berita  direpresentasikan  dalam  bentuk  vektor  untuk 
tahap 
selection.  Representasi  vektor  dihitung 
berdasarkan  bobot  Term  Frequency-Inverse  Document 
Frequency (TF-IDF)  yang  diperoleh  menggunakan  library 
Scikit  Learn  (Sklearn).  Formula  frekuensi  kata  (TF)  yang 
digunakan dalam Sklearn ditunjukkan  dengan formula (1) [16], 

𝑇𝐹(𝑡,𝑑) =

𝑓𝑡,𝑑

∑

𝑡′∈𝑑

𝑓𝑡′,𝑑

, 

       (1) 

dengan, 
𝑓𝑡′,𝑑 
∑ 𝑓𝑡′,𝑑
𝑡′∈𝑑

=  frekuensi kata t dalam dokumen ke-d, 
= total kata t pada setiap dokumen d. 

Formula Inverse Document Frequency (IDF) pada Sklearn 
terdapat  penambahan  konstanta  1  pada  numerator  dan 
denumerator untuk mencegah pembagi menjadi 0 seperti yang 
ditunjukkan pada formula  (2), 

𝐼𝐷𝐹(𝑡) =𝑙𝑜𝑔 𝑙𝑜𝑔 

1+𝑛

1+𝑑𝑓(𝑡)

+ 1  

         (2) 

dengan, 
n 
𝑑𝑓(𝑡)  = jumlah dokumen training yang memuat term t. 

= jumlah dokumen training yang digunakan, 

4) Pembangunan Model Klasifikasi 
Model yang dibangun untuk mendeteksi pergerakan dan laju 
pertumbuhan  PDB  menggunakan  berita  online  adalah  model 
klasifikasi  machine  learning dan  pre-trained  language model 
Transformers.  Language  model  berbasis  Transformers  yang 
memfasilitasi pemrosesan bahasa Indonesia adalah IndoBERT 
dan Multilingual BERT. Berikut penjelasan dari model-model 
yang digunakan. 

a. Random Forest 

Gagasan  dari  Random  Forest  adalah  pembentukan 
sekumpulan  decision  tree  untuk  mengklasifikasi  label  kelas 
berdasarkan  majority  vote  untuk  pekerjaan  klasifikasi  [17]. 
Random  Forest menggunakan gabungan prediksi dari banyak 
tree  yang  telah  melalui  training  secara  terpisah.  Banyaknya 
jumlah pohon akan meningkatkan akurasi dari hasil klasifikasi 
[18]. Random Forest dapat menangani input variabel berukuran 
besar  dan  mampu  menyeimbangkan  error pada  permasalahan 
imbalanced dataset [19]. 

b.  Support Vector Machine (SVM) 
Prinsip  SVM  yaitu  menentukan  hyperplane  yang  dapat 
memisahkan  kelas  yang  berbeda.  Keunggulan  SVM 
diantaranya  dapat  memeriksa  kombinasi  fitur  yang  sesuai, 
sehingga cukup robust untuk data berdimensi tinggi [20]. Input 
data  teks  cocok  untuk  diklasifikasikan  dengan  SVM  karena 
data  teks  bersifat  sparse  high-dimensionality,  yakni  kondisi 
beberapa fitur tidak relevan, tetapi cenderung berkorelasi satu 
sama lain dan umumnya diatur ke dalam kategori yang dapat 
dipisahkan  secara  linier  [21].  SVM  merupakan  classifier 
terbaik untuk klasifikasi teks karena mampu menangani dataset 
dengan fitur yang sangat banyak [22]. 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

c.  Naïve Bayes Classifier 
Naïve  Bayes  adalah  probabilistik  classifier  dengan 
independensi  yang  kuat  dalam  asumsi  feature  space.  Naïve 
Bayes  menggunakan  konsep  peluang  yang  parameternya 
belajar dari data training dengan aturan peluang Bayesian [23]. 
Dengan  aturan  Bayes,  classifier  mengasumsikan  kemunculan 
kata  dalam  dokumen  independen  terhadap  kata  lainnya, 
berlainan  dengan  kata  yang  saling  terhubung  dalam  konsep 
bahasa  manusia.  Walaupun  demikian,  Naïve  Bayes 
menunjukkan  performa  baik  dalam  pekerjaan  klasifikasi  teks 
[22]. Model Naïve Bayes yang digunakan dalam penelitian ini 
adalah Bernoulli Naïve Bayes dan Multinomial Naïve Bayes. 

d.  IndoBERT 
IndoBERT  adalah  versi  pre-trained  model  berbasis 
Transformers  BERT  yang  dilatih  dengan  kosakata  berbahasa 
Indonesia. IndoBERT  menggunakan masked language model 
dengan kerangka Huggingface [24].  

 e. Multilingual BERT 
Multilingual  BERT  (mBERT)  merupakan  versi  pre-
trained model BERT yang dilatih dalam 102 bahasa (uncased) 
dan  104  bahasa  (cased)  di  Wikipedia,  termasuk  Bahasa 
Indonesia [5]. Oleh karena itu, mBERT dapat digunakan untuk 
pekerjaan NLP dalam bahasa Indonesia. 

f.  Modifikasi Input Text dengan Sentences Selection 
Dalam pekerjaan klasifikasi teks dengan konteks masalah 
spesifik,  tidak  semua  informasi  dalam  teks  diperlukan.  Data 
berita  yang  panjang  justru  berpotensi  menjadi  kendala  untuk 
model  dalam  mempelajari  fitur  penting  dari  konteks  yang 
diklasifikasi secara optimal. Modifikasi input data  teks untuk 
meningkatkan  performa  klasifikasi  long  text  telah  banyak 
dikerjakan  peneliti  lainnya  seperti  metode  Text  Guide  [25]. 
Fitur penting dalam Text Guide diperoleh menggunakan bag-
of-words dengan pengurutan kepentingan tiap kata dalam teks 
sehingga  menghasilkan  sorted  important-token-feature-list 
(sITFL),  namun  mekanisme  ini  tidak  relevan  untuk  kasus 
klasifikasi  dengan  konteks  masalah  spesifik  seperti  laju 
pertumbuhan PDB dalam penelitian ini. Oleh karena itu, fitur 
penting  yang  digunakan  didefinisikan  oleh  peneliti  sebagai 
predefined 
terdiri  dari  kata-kata  yang  dicari 
keberadaannya pada setiap kalimat dalam teks. Jika kata dalam 
list tidak ditemukan maka tiga kalimat pertama akan diekstraksi 
atau  dikenal  sebagai  metode  3-lead  summary  [26].  Untuk 
melakukan  sentences  selection  maka  perlu  terlebih  dahulu 
melakukan  tokenisasi  kalimat,  pada  penelitian  ini  tokenisasi 
kalimat diperoleh dengan library NLTK. 

list  yang 

5. Evaluasi Model 
Evaluasi model pendeteksi pergerakan PDB dilakukan pada 
data  testing dengan menggunakan  cross validation 5-fold. K-
fold  cross  validation  adalah  metode  evaluasi  model  dengan 
pemisahan  data  menjadi  training  set  dan  test  set  kemudian 
didistribusikan sesuai jumlah fold yang digunakan [27]. Metrik 
yang  digunakan  untuk  mengukur  performa  model  dalam 
klasifikasi teks yaitu, akurasi, presisi, recall, dan f1 score. 

a.  Akurasi,  diperoleh  dengan  menghitung  proporsi 
klasifikasi benar dengan keseluruhan hasil klasifikasi. 

 4 / 8 

 
 
 
 
 
 
 
 
 
 
 
Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

b.  Presisi,  menunjukkan  besar  klasifikasi  positif  dengan 
menghitung  proporsi  klasifikasi  positif  benar  dengan 
total klasifikasi positif.  

c.  Recall,  proporsi  klasifikasi  positif  yang  benar  dengan 

seluruh klasifikasi yang seharusnya positif.  

d.  F1 score, rata-rata harmonik antara recall dan presisi.  

V.  KERANGKA PIKIR 
Fokus penelitian ini adalah pemanfaatan berita online untuk 
deteksi  pergerakan  dan  laju  pertumbuhan  PDB.  PDB  yang 
digunakan  dalam  penelitian  ini  adalah  PDB  pendekatan 
produksi dengan pendekatan pertumbuhan PDB riil. Kata kunci 
dalam 
scraping 
memanfaatkan kata yang berkaitan dengan 17 kategori sektor 
ekonomi.  Dengan  demikian,  peneliti  dapat  memastikan  jika 
lapangan  usaha  yang  berkontribusi  dalam  perekonomian 
domestik telah terwakili dalam data. Kerangka pikir penelitian 
ini ditunjukkan pada Gambar 3. 

pengumpulan 

dengan 

teknik 

data 

Gambar 4. Perbandingan jumlah label pada data 

B.  Deteksi Pergerakan PDB dengan Klasifikasi Berita 
Klasifikasi  dilakukan  menggunakan  tiga  model  machine 
learning dengan parameter terbaik hasil grid search pada lima 
fold data cross validation. Model yang menunjukkan performa 
terbaik  dalam  klasifikasi  data  pergerakan  PDB  adalah  SVM. 
Perbandingan  ketiga  model  ditunjukkan  pada  Tabel  I. 
Berdasarkan empat metrik evaluasi model SVM unggul pada 
metrik  recall,  f1-score,  akurasi,  namun  berdasarkan  presisi 
lebih  rendah  dari  Random  Forest  yang  memiliki  performa 
terendah dari tiga metrik evaluasi lainnya. 

TABEL I 
EVALUASI PERFORMA KLASIFIKASI MODEL MACHINE LEARNING  
PERGERAKAN PDB 
Precision 

F1-Score 

Akurasi 

Recall 

Model 

Label 

Gambar 3. Kerangka pikir penelitian 

VI. HASIL DAN PEMBAHASAN 

A.  Pembangunan Dataset Penelitian 

pelabelan 

Scraping pada portal berita Detik.com menghasilkan 13.286 
data. Setelah diseleksi, data berita yang diolah dalam penelitian 
sebanyak  1.586  data.  Penyeleksian  data  mempertimbangkan 
rendahnya  jumlah  berita  yang  relevan  yaitu  <25%  untuk 
masing-masing  sektor  lapangan  usaha.  Data  berita  yang 
dianalisis adalah pergerakan PDB dengan label up dan down. 
Sedangkan  laju  pertumbuhan  PDB  dengan  label  klasifikasi 
tidak tercantum, Year-on-year, Cumulative-to-cumulative, dan 
Quarter-to-quarter.  Hasil 
anotator 
menghasilkan data yang tidak seimbang, akan tetapi klasifikasi 
yang  dilakukan  tidak  menangani  permasalahan  tersebut. 
Krippendorf  alpha  untuk  data  pergerakan  dan 
laju 
pertumbuhan PDB sebesar 0,777 dan 0,490. Nilai alpha yang 
rendah  pada  data  laju  pertumbuhan  PDB  menunjukkan 
rendahnya tingkat reliabilitas pelabelan laju pertumbuhan PDB. 
Setelah  dilakukan  analisis  mendalam,  rendahnya  tingkat 
reliabilitas  pelabelan  ini  dapat  terjadi  karena  beberapa  berita 
memuat  lebih  dari  satu  jenis  periode  laju  pertumbuhan  PDB 
sedangkan  sebagian  berita  lainnya  tidak  memiliki  keterangan 
waktu  yang  memadai. 
label 
ditunjukkan pada Gambar 4. 

Jumlah  masing-masing 

oleh 

SVM 

Random 
Forest 

Bernoulli 
Naïve 
Bayes 

down 

up 

macro avg 

down 

up 

macro avg 

down 

up 

macro avg 

0,7257 

0,8802 

0,8030 

0,8389 

0,8101 

0,8245 

0,7169 

0,8675 

0,7922 

0,6484 

0,9134 

0,7809 

0,3439 

0,9760 

0,6599 

0,5970 

0,9162 

0,7566 

0,6811 

0,8960 

0,7886 

0,4859 

0,8848 

0,6854 

0,6498 

0,8910 

0,7704 

0,8440 

0,8126 

0,8352 

TABEL II 
PERFORMA KLASIFIKASI PERGERAKAN PDB PRE-TRAINED MODEL  

Model 

label 

precision 

recall 

f1-score 

Akurasi 

IndoBERT 
Base 

IndoBERT 
Large 

Multilingual 
BERT 
uncased 

down 

up 

macro avg 

down 

up 

macro avg 

down 

up 

macro avg 

0,7324 

0,9216 

0,8270 

0,7544 

0,9470 

0,8507 

0,6593 

0,8959 

0,7776 

0,7858 

0,9016 

0,8437 

0,8551 

0,9006 

0,8779 

0,7085 

0,8772 

0,7929 

0,7556 

0,9112 

0,8334 

0,7957 

0,9220 

0,8589 

0,6775 

0,8855 

0,7815 

0,8704 

0,8881 

0,8314 

Performa model klasifikasi pergerakan PDB dengan transfer 
learning dari pre-trained Transformers dirinci dalam Tabel II. 
Performa terbaik diperoleh dari hasil klasifikasi dengan model 
IndoBERT-Large  dengan  akurasi  0,8880.  Akurasi  yang 
diperoleh  dari  IndoBERT-Base  tidak  jauh  berbeda  yaitu 

 5 / 8 

 
 
 
 
 
 
 
 
0,8704.  Jika  mempertimbangkan  efisiensi  sumber  daya  dan 
waktu  komputasi,  IndoBERT-Base  dapat  dipilih.  Sedangkan 
pada  hasil  klasifikasi  dengan  MultilingualBERT  (mBERT) 
performanya  tidak  lebih  baik  dibandingkan  dengan  baseline 
machine  learning  model  dengan  hyperparameter  tuning. 
Akurasi pada mBERT sebesar 0,831 lebih rendah dibandingkan 
akurasi  pada  SVM  dan  Bernoulli  Naïve  Bayes.  Berdasarkan 
Tabel II hasil klasifikasi dengan transfer learning melampaui 
performa  klasifikasi  dengan  machine  learning  untuk  model 
IndoBERT.  Hasil  klasifikasi  pergerakan  PDB  menggunakan 
berita  online  ini  dapat  dianalisis  sebagai  deteksi  percepatan 
label  up  dan  perlambatan 
pertumbuhan  PDB  untuk 
pertumbuhan  PDB  untuk 
sesuai  dengan 
label  down 
rekomendasi  yang  diberikan  oleh  praktisi  dan  subject  matter 
expert  dari  BPS  untuk  interpretasi  yang  lebih  tepat.  Analisis 
tersebut  juga  mempertimbangkan  tren  pertumbuhan  PDB  riil 
selama  12  tahun  terakhir  secara  triwulanan.  Pola  pergerakan 
PDB menunjukkan adanya efek musiman karena penggunaan 
periode  triwulanan,  namun  apabila  efek  musiman  tersebut 
dihiraukan  pola  pergerakan  PDB  cenderung  tidak  fluktuatif 
seperti  yang  ditunjukkan  dengan  grafik  pada  Gambar  5. 
Pertumbuhan PDB negatif merupakan kasus yang jarang terjadi 
dalam  ekonomi  Indonesia,  dalam  periode  tahun  2010-2022 
pertumbuhan negatif yang terjadi sebanyak tiga triwulan yang 
dipengaruhi krisis akibat pandemi Covid-19. Oleh karena itu, 
deteksi  penurunan  pergerakan  PDB  yang  diperoleh 
menggunakan  berita  online  lebih  relevan  digunakan  sebagai 
early warning system dari potensi krisis ekonomi. 

Gambar 5. Tren Pertumbuhan PDB Riil Triwulanan Tahun 2010-2022 

C.  Deteksi  Laju  pertumbuhan  PDB  dengan  Klasifikasi 

Berita 

Hyperparameter tuning dengan grid search dilakukan pada 
seluruh model machine learning untuk meningkatkan performa 
model.  Hasil  evaluasi  klasifikasi  laju  pertumbuhan  PDB 
dengan machine learning ditunjukkan pada Tabel III.  Dari tiga 
model  yang  dibandingkan,  SVM  menunjukkan  performa 
terbaik  dengan  akurasi  0,7811.  Performa  klasifikasi  laju 
pertumbuhan  PDB  menunjukkan  hasil  yang  lebih  rendah 
dibandingkan  hasil  klasifikasi  pergerakan  PDB.  Salah  satu 
faktornya karena berita dengan periode laju pertumbuhan tidak 
dispesifikasi  sangat  banyak  dibandingkan 
lainnya, 
sehingga  data  tidak  seimbang.  Berdasarkan  hasil  diskusi 
dengan  subject  matter  dari  Subdirektorat  Konsolidasi  Neraca 

label 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

Produksi  Nasional  BPS  RI,  data  berita  dengan  periode  laju 
pertumbuhan  yang  tidak  dispesifikasi  dapat  diasumsikan 
sebagai laju pertumbuhan PDB tahunan. 

TABEL III 
EVALUASI PERFORMA KLASIFIKASI MODEL MACHINE LEARNING  
PERTUMBUHAN PDB 
Precision  Recall 

F1-Score 

Akurasi 

Label 

Model 

Tidak 
tercantum 

Cumulative 

Q-to-Q 

Y-o-Y 

macro avg 

Tidak 
tercantum 

Cumulative 

Q-to-Q 

Y-o-Y 

macro avg 

Tidak 
tercantum 

Cumulative 

Q-to-Q 

Y-o-Y 

macro avg 

SVM 

Random 
Forest 

Multinomial 
Naïve Bayes 

0,8182 

0,5000 

0,6600 

0,4911 

0,6173 

0,7899 

0,3667 

0,4667 

0,4442 

0,5169 

0,7959 

0,2400 

0,4600 

0,4680 

0,4910 

0,9777 

0,0719 

0,2733 

0,3076 

0,4076 

0,9896 

0,0530 

0,0983 

0,1727 

0,3284 

0,9687 

0,0515 

0,1217 

0,2633 

0,3513 

0,8907 

0,1183 

0,3585 

0,3752 

0,4357 

0,8783 

0,0901 

0,1612 

0,2438 

0,3434 

0,8737 

0,0821 

0,1774 

0,3325 

0,3665 

0,7811 

0,7610 

0,7597 

TABEL IV 
PERFORMA KLASIFIKASI LAJU PERTUMBUHAN PDB PRE-TRAINED 
MODEL 

Model 

Label 

precision 

recall 

f1-score 

akurasi 

Tidak 
tercantum 

Cumulative 

Q-to-Q 

Y-o-Y 

macro avg 

Tidak 
tercantum 

Cumulative 

Q-to-Q 

Y-o-Y 

macro avg 

Tidak 
tercantum 

Cumulative 

Q-to-Q 

Y-o-Y 

macro avg 

IndoBERT 
Base 

IndoBERT 
Large 

Multilingual 
BERT 
uncased 

0,8896 

0,3809 

0,6155 

0,4972 

0,5958 

0,7895 

0,1000 

0,2000 

0,1910 

0,3201 

0,8768 

0,4212 

0,5667 

0,4702 

0,5837 

0,9242 

0,4055 

0,6783 

0,3264 

0,5836 

0,9793 

0,0167 

0,1700 

0,2182 

0,3460 

0,9395 

0,3131 

0,3483 

0,4067 

0,5019 

0,9055 

0,3832 

0,6133 

0,3759 

0,5694 

0,8716 

0,0286 

0,1833 

0,2036 

0,3218 

0,9069 

0,3487 

0,4214 

0,4333 

0,5276 

0,7899 

0,7597 

0,7887 

Kemudian  dilakukan  klasifikasi  dengan  transfer  learning 
menggunakan  pre-trained  language  model  Tranformers.  Hasil 
evaluasi  klasifikasi  laju  pertumbuhan  PDB  dengan  pre-trained 
model  Transformers  ditunjukkan  pada  Tabel  IV.    Pre-trained 
Transformers  yang  memberikan  performa 
terbaik  adalah 
IndoBERT-Base  dengan  akurasi  0,7899.  Berdasarkan  recall,  f1-

 6 / 8 

 
 
 
 
 
 
 
IV  dapat  diketahui  bahwa 

score dan akurasi, IndoBERT-Base unggul dibandingkan dengan 
baseline  model  terbaik 
  yaitu  SVM.  Tetapi  untuk  presisi 
IndoBERT-Base  masih  lebih  rendah  dibandingkan  SVM.  Dari 
Tabel 
IndoBERT-Large  yang 
memberikan  performa  terbaik  pada  klasifikasi  pergerakan  PDB 
justru  memberikan  performa  yang  paling  rendah  diantara  pre-
trained Transformers yang diuji pada klasifikasi laju pertumbuhan 
PDB. Hal ini mengindikasikan jika IndoBERT-Large kurang tepat 
digunakan untuk menangani klasifikasi data yang tidak seimbang. 
Walaupun demikian masih diperlukan analisis lebih lanjut dengan 
pengaturan  parameter  model  dan  data  yang  berbeda  untuk 
memvalidasi temuan ini secara umum. 

D.  Penerapan  Sentences  Selection  pada  Deteksi  Laju 

Pertumbuhan PDB 

input  data 

Mencermati  performa  hasil  yang  diperoleh  pada  eksperimen 
pertama  untuk  klasifikasi  laju  pertumbuhan  PDB  yang  tidak 
memberikan  peningkatan  metrik  evaluasi  signifikan,  peneliti 
melihat masih ada ruang untuk melakukan pengembangan metode 
agar performa yang diperoleh dapat lebih optimal. Oleh karena itu, 
penelitian dilanjutkan pada eksperimen kedua dengan melakukan 
modifikasi  pada 
teks  yang  digunakan  dengan 
mekanisme sentence selection. Modifikasi input teks berita dengan 
sentences  selection  menghasilkan  data  teks  yang  lebih  pendek 
namun  memuat  fitur  penting  terkait  konteks  masalah  yang 
diklasifikasikan model. Dari total data 1.586 berita, terdapat  159 
berita yang tidak  memuat kata yang diidentifikasi, hal ini terjadi 
karena beberapa kemungkinan yaitu laju pertumbuhan PDB yang 
dimuat  dalam  berita  merupakan  berita  perekonomian  terkini, 
informasi laju pertumbuhan PDB secara tersirat, atau data berita 
terklasifikasi sebagai label tidak tercantum. Kalimat yang terpilih 
secara  rata-rata  sebanyak  empat  kalimat  untuk  masing-masing 
berita,  sedangkan  panjang  berita  secara  rata-rata  sebanyak  25 
kalimat.  Kalimat  minimal  yang  diekstraksi  dengan  sentence 
selection sebanyak satu kalimat.  Kalimat maksimal yang diseleksi 
dengan  sentences  selection  tidak  dibatasi,  kemudian  diperoleh 
kalimat maksimal yang terseleksi sebanyak 31 kalimat. Performa 
hasil  klasifikasi  menggunakan  model  machine  learning  SVM 
dengan input data berita yang telah dimodifikasi dengan sentence 
selection  (Eksperimen  I.a)  dibandingkan  dengan  performa  hasil 
klasifikasi  dari  model  yang  sama  dengan  input  data  teks  berita 
tanpa modifikasi sentence selection (Eksperimen II.a) ditunjukkan 
pada Tabel V. Pada observasi untuk membandingkan waktu yang 
(Eksperimen  a)  dan 
diperlukan  dalam  pemrosesan  SVM 
IndoBERT  (Eksperimen  b),  platform  yang  digunakan  adalah 
Google Colaboratory dengan spesifikasi Intel Xeon CPU @2.30 
GHz,  13  GB  RAM,  Tesla  K80  accelerator,  dan  12  GB  GDDR5 
VRAM. 

Berdasarkan  metrik  evaluasi  yang  dirinci  pada  Tabel  V, 
penerapan  sentences  selection  pada  data  berita  menghasilkan 
peningkatan pada hampir seluruh metrik evaluasi. Hanya ada satu 
metrik evaluasi yang menunjukkan penurunan dengan nilai relatif 
kecil yaitu recall sebesar 0,0002. Kenaikan akurasi secara rata-rata 
sebesar  0,0226  poin  diperoleh  setelah  menerapkan  sentences 
selection  pada  input  model  SVM.  Akurasi  model  SVM  dengan 
input  data  hasil  sentences  selection  sebesar  0,8038.  Penerapan 
sentences  selection    juga  berhasil  mempersingkat  waktu  yang 
diperlukan  pada  tahap  hyperparameter  tuning  yang  sebelumnya 
selama  4900,8  detik,  menjadi  1172,6  detik  setelah  penerapan 
sentences selection dikerjakan pada perangkat yang sama. 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

TABEL V 
PERFORMA HASIL SENTENCES SELECTION SVM PADA 
KLASIFIKASI LAJU PERTUMBUHAN PDB  

Eksp 

Label 

Precision  Recall 

F1-
Score 

Support  Akurasi 

Hyperp
aramete
r tuning 
(s) 

I.a 

Tidak 
tercantum 

0,8410  0,9774  0,9040 

117 

0,8038  1172,6 

Cumulative 

0,6595  0,2002  0,2828 

Q-to-Q 

0,7400  0,3950  0,4979 

Y-o-Y 

0,5238  0,3649  0,4251 

macro avg 

0,6911  0,4844  0,5275 

weighted 
avg 

II.a  Tidak 

0,7835  0,8038  0,7706 

12 

9 

22 

159 

159 

117 

0,7811  4900,8 

tercantum 

0,8182  0,9777  0,8907 

Cumulative 

0,5000  0,0719  0,1183 

Q-to-Q 

0,6600  0,2733  0,3585 

Y-o-Y 

0,4911  0,3076  0,3752 

macro avg 

0,6173  0,4076  0,4357 

weighted 
avg 

0,7457  0,7811  0,7352 

12 

9 

22 

159 

159 

Eksperimen (b) membandingkan performa hasil klasifikasi laju 
pertumbuhan  PDB  dengan  penerapan  sentences  selection  pada 
metode transfer learning dari pre-trained Transformers. Performa 
hasil  klasifikasi  menggunakan  transfer  learning  dari  model 
IndoBERT-Base dengan input data berita yang telah dimodifikasi 
dengan sentence selection (Eksperimen I.b) dibandingkan dengan 
performa hasil klasifikasi dari model yang sama dengan input data 
teks berita tanpa modifikasi sentence selection (Eksperimen II.b) 
ditunjukkan  pada  Tabel  VI.  Berdasarkan  metrik  evaluasi  yang 
dirinci  pada  Tabel  VI,  penerapan  sentences  selection  pada  input 
data berita menghasilkan peningkatan pada hampir seluruh metrik 
evaluasi, namun ada beberapa metrik evaluasi yang menunjukkan 
penurunan  metrik  recall  dan  f1-score  pada  label  Q-to-Q  yang 
menunjukkan  penurunan  sebesar  0,0916  dan  0,0196.  Kenaikan 
akurasi  secara  rata-rata  sebesar  0,0164  poin  setelah  menerapkan 
sentences  selection  pada  input  model  IndoBERT-Base.  Akurasi 
pada  model  IndoBERT-Base  dengan  input  data  hasil  sentences 
selection  sebesar  0,8063.  Besarnya  peningkatan  akurasi  pada 
model  IndoBERT-Base  tidak  sebesar  peningkatan  akurasi  pada 
model  SVM.  Namun,  berdasarkan  nilai  akurasi  yang  diperoleh 
laju 
setelah 
pertumbuhan  PDB  menggunakan  metode  transfer  learning  dari 
pre-trained  language  model  Transformers  teruji  lebih  baik 
dibandingkan  baseline  model  dengan  metode  machine  learning. 
Penerapan sentences selection berhasil mempersingkat waktu yang 
diperlukan  pada  tahap  fine  tuning  dari  yang  sebelumnya  selama 
1411,4  detik,  menjadi  783  detik  setelah  penerapan  sentences 
selection dikerjakan pada perangkat yang sama. 

penerapan 

klasifikasi 

selection, 

sentences 

 7 / 8 

 
 
 
 
 
TABEL VI 
PERFORMA HASIL SENTENCES SELECTION  INDOBERT PADA 
KLASIFIKASI LAJU PERTUMBUHAN PDB  

Eksp 

Label 

Precision  Recall 

F1-
Score 

Support  Akurasi 

Fine 
tuning 
(s) 

Tidak 
tercantum 

0,8938  0,9472  0,9187 

117 

Cumulative 

0,4165  0,4318  0,4054 

Q-to-Q 

Y-o-Y 

0,6443  0,5867  0,5937 

0,5392  0,3464  0,4126 

12 

9 

22 

macro avg 

0,6234 

0,578  0,5826 

159 

I.b 

weighted 
avg 

Tidak 
tercantum 

0,8010  0,8063  0,7951 

159 

0,8063 

783 

0,8896  0,9242  0,9055 

117 

Cumulative 

0,3809  0,4055  0,3832 

Q-to-Q 

Y-o-Y 

0,6155  0,6783  0,6133 

0,4972  0,3264  0,3759 

12 

9 

22 

macro avg 

0,5958  0,5836  0,5694 

159 

weighted 
avg 

II.b 

0,7877  0,7899  0,7804 

159 

0,7899  1411,4 

VII. 

PENUTUP 

Berdasarkan hasil penelitian yang telah dipaparkan dapat dibuat 
beberapa  kesimpulan  terkait  tujuan  penelitian  yang  diajukan, 
diantaranya sebagai berikut. 

1)  Dari penelitian telah dibangun dataset berita online untuk 
klasifikasi pergerakan dan laju pertumbuhan PDB. Dataset 
yang  dibangun  menghasilkan  label  yang  tidak  seimbang, 
namun penelitian ini tidak mengatasi masalah tersebut dan 
hanya melakukan klasifikasi untuk mendeteksi pergerakan 
dan laju pertumbuhan PDB 

2)  Klasifikasi berita online telah dilakukan untuk mendeteksi 
pergerakan  dan  laju  pertumbuhan  PDB.  Hasil  klasifikasi 
yang  diperoleh  dari  transfer  learning  menggunakan  pre-
trained  Transformers 
IndoBERT-Large  memberikan 
performa yang lebih unggul untuk deteksi pergerakan PDB 
dan  IndoBERT-Base  untuk 
laju  pertumbuhan  PDB 
dibandingkan machine learning model berdasarkan metrik 
akurasi,  presisi,  recall,  dan  f1-score.  Akurasi  model 
klasifikasi terbaik untuk pergerakan dan laju pertumbuhan 
PDB masing-masing sebesar 0,8881 dan 0,7899. 
3)  Sentences  selection  diterapkan  pada  klasifikasi 

laju 
pertumbuhan  PDB  dalam  tahap  ekstraksi  fitur  penting 
berita  untuk  meningkatkan  performa  pada 
long-text 
classification dengan konteks klasifikasi spesifik, sehingga 
tidak  semua  informasi  berita  diperlukan.  Hasil  pengujian 
menunjukkan  jika  klasifikasi  laju  pertumbuhan  PDB 
berhasil  menunjukkan  peningkatan  performa  dan 
mempersingkat  waktu  pemrosesan  baik  untuk  machine 
learning  dan  transfer  learning.  Perbaikan  akurasi  secara 
rata-rata masing-masing sebesar 0,0226 dan 0,0164. 

DAFTAR PUSTAKA 
[1]  Eggers,  A.  C.,  Ellison,  M.,  dan  Lee,  S.  S.  (2021).  The  economic  impact  of 
recession announcements. Journal of Monetary Economics, 120, 40-52. 
[2]  BPS. (2021). PDB Indonesia Triwulanan 2017-2021. Badan Pusat Statistik. 
[3]  Gregory, M., Quah, E., dan Wilson, P. (2006). Pengantar Ekonomi Makro. Edisi 

Ketiga, Salemba Empat Jakarta. ISBN: 9789790613560 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

[4]  BPS.(2020).  PERKA  BPS  No.  36  Rencana  Strategis  BPS  Tahun  2020-

2024.Jakarta.https://ppid.bps.go.id/upload/doc/Renstra_BPS_2020-
2024_1646895774.pdf 

[5]  J. Devlin, M. W. Chang, K. Lee, and K. Toutanova, “BERT: Pretraining of deep 
bidirectional Transformers for language understanding,” NAACL HLT 2019 - 
2019  Conference  of  the  North  American  Chapter  of  the  Association  for 
Computational  Linguistics:  Human  Language  Technologies  -  Proceedings  of 
the  Conference,  vol.  1,  no.  Mlm,  pp.  4171–4186,  2019.  Available  : 
https://doi.org/10.48550/arXiv.1810.04805  

[6]  Khairani, F., Kurnia, A., Aidi, M. N., dan Pramana, S. (2022). Predictions of 
Indonesia economic phenomena based on online news using Random Forest. 
Sinkron: jurnal dan penelitian teknik informatika, 7(2), 532-540. 

[7]  Wongso,  R.,  Luwinda,  F.  A.,  Trisnajaya,  B.  C.,  dan  Rusli,  O.  (2017).  News 
article text classification in Indonesian language. Procedia Computer Science, 
116, 137-143. Available : https://doi.org/10.1016/j.procs.2017.10.039 

[8]  Duarte, J. J., Montenegro González, S., dan Cruz, J. C. (2021). Predicting stock 
price falls using news data: Evidence from the Brazilian market. Computational 
Economics, 57(1), 311-340. https://doi.org/10.1007/s10614-020-10060-y 
[9]  Chen,  Q.  (2021).  Stock  movement  prediction  with  financial  news  using 
contextualized  embedding  from  bert. arXiv  preprint  arXiv:2107.08721. 
Available : https://doi.org/10.48550/arXiv.2107.08721  

[10] Wei,  F.,  dan  Nguyen,  U.  T.  (2018).  Stock  Trend  Prediction  using  Financial 
Market News and BERT. Wall Street Journal. KDIR, ISBN 978-989-758-474-
9; ISSN 2184-3228, pages 325-332. DOI: 10.5220/0010172103250332 

[11] Sonkiya,  P.,  Bajpai,  V.,  dan  Bansal,  A.  (2021).  Stock  price  prediction  using 
: 

and  GAN.  arXiv  preprint 

arXiv:2107.09055.  Available 

BERT 
https://doi.org/10.48550/arXiv.2107.09055 

[12] SimilarWeb. Detik.com Website Traffic Rank Juli-September 2022. 
https://www.similarweb.com/website/cnbcindonesia.com/#overview  

[13] Gwet, K. L. (2014). Handbook of Inter-Rater Reliability: The Definitive Guide 
to Measuring the Extent of Agreement Among Raters. Advanced Analytics, LLC, 
Gaithersburg, MD, 4th edition. 

[14] Vijayarani, S., Ilamathi, M. J., dan Nithya, M. (2015). Preprocessing techniques 
for  text  mining-an  overview.  International  Journal  of  Computer  Science  dan 
Communication Networks, 5(1), 7-16. 

[15] Vijayarani, S., dan Janani, R. (2016). Text mining: open source tokenization 
tools-an  analysis.  Advanced  Computational  Intelligence:  An  International 
Journal (ACII), 3(1), 37-47. 

[16] T. Joachims. A Probabilistic Analysis of the Rocchio Algorithm with TFIDF 

for Text Categorization. ICML Conference, 1997 

[17] Liparas,  D.,  HaCohen-Kerner,  Y.,  Moumtzidou,  A.,  Vrochidis,  S.,  dan 
Kompatsiaris, I. (2014, November). News articles classification using random 
forests  and  weighted  multimodal  features.  In  Information  Retrieval  Facility 
Conference (pp. 63-75). Springer, Cham. DOI: 10.1007/978-3-319-12979-2_6 
[18] Al-Ash, H. S., Putri, M. F., Mursanto, P., dan Bustamam, A. (2019, October). 
Ensemble learning  approach on indonesian  fake news  classification.  In  2019 
3rd  International  Conference  on  Informatics  and  Computational  Sciences 
(ICICoS) (pp. 1-6). IEEE. 

[19] Panda, M., dan Patra, M. R. (2009). Evaluating machine learning algorithms for 
detecting  network  intrusions.  International  Journal  of  recent  trends  in 
Engineering, 1(1), 472. 

[20] Brouwer & W. H. Haemers, Spectra of Graphs.New York: Springer, 2012. 
[21] Aggarwal, C. C., dan Zhai, C. (2012). A survey of text classification algorithms. 
In  Mining  text  data  (pp.  163-222).  Springer,  Boston,  MA.  Available  : 
https://doi.org/10.1007/978-1-4614-3223-4_6 

[22] Shahi, T. B., dan Pant, A. K. (2018, February). Nepali news classification using 
Naïve  Bayes,  support  vector  machines  and  neural  networks.  In  2018 
International  Conference  on  Communication  Information  and  Computing 
Technology (ICCICT) (pp. 1-5). IEEE 

[23] Suleymanov, U., Rustamov, S., Zulfugarov, M., Orujov, O., Musayev, N., dan 
Alizade, A. (2018). Empirical study of online news classification using machine 
learning  approaches.  In  2018  IEEE  12th  International  Conference  on 
Application of Information and Communication Technologies (AICT).IEEE. 

[24] B.  Wilie,  K.  Vincentio,  G.  I.  Winata,  S.  Cahyawijaya,  X.  Li,  Z.  Y.  Lim,  S. 
Soleman,  R.  Mahendra,  P.  Fung,  S.  Bahar,  and  A.  Purwarianti,  “IndoNLU: 
Benchmark  and  Resources  for  Evaluating  Indonesian  Natural  Language 
Understanding,” 2020. [Online]. Available: http://arxiv.org/abs/2009.05387  
[25] Fiok, K., Karwowski, W., Gutierrez-Franco, E., Davahli, M. R., Wilamowski, 
M., Ahram, T., ... dan Zurada, J. (2021). Text guide: improving the quality of 
long text classification by a text selection method based on feature importance. 
IEEE Access, 9, 105439-105450. 

[26] Nallapati, R., Zhai, F., dan Zhou, B. (2017). Summarunner: A recurrent neural 
network-based sequence model for extractive summarization of documents. In 
Proceedings of the AAAI conference on artificial intelligence (Vol. 31, No. 1). 
[27] Refaeilzadeh, P., Tang,  L., dan Liu, H. (2009). Cross-validation. Encyclopedia 

of database systems, 5, 532-538 

 8 / 8 

 
 
","2023-12-19T08:25:13.937062Z",221910740,"[{""start"":980,""end"":1014,""text"":""scraping berdasarkan kata kunci"",""labels"":[""Metode""]},{""start"":915,""end"":942,""text"":""klasifikasi berita online"",""labels"":[""Metode""]},{""start"":1315,""end"":1421,""text"":""model IndoBERT berhasil melampaui performa machine\\nlearning dengan akurasi terbaik 0.8880 dan 0.7899"",""labels"":[""Temuan""]},{""start"":1422,""end"":1522,""text"":"" SVM memberikan\\nakurasi terbaik sebesar 0.8440 dan 0.7811, diantara model machine\\nlearning"",""labels"":[""Temuan""]},{""start"":41202,""end"":41315,""text"":"""",""labels"":[""Metode""]},{""start"":847,""end"":900,""text"":"" mendeteksi pergerakan dan\\nlaju pertumbuhan PDB"",""labels"":[""Tujuan""]}]",842.3040000000001,"2023-12-19T09:59:31.506600Z"
6,"1","Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Perancangan Aplikasi Evaluasi Atas Implementasi 
SAKIP BPS 

Marya Zahra Aliffio Krisfianda (221910730, 4SI1) 
Dosen Pembimbing: Ibnu Santoso, SST., M.T. 

fungsional 

Ringkasan—  Inspektorat  Utama  Badan  Pusat  Statistik  (BPS) 
bertugas  melakukan 
terhadap 
pengawasan 
pelaksanaan  tugas  di  lingkungan  BPS.  Salah  satu  bentuk 
pelaksanaan  tugas  tersebut  adalah  dengan  melakukan  evaluasi 
atas 
implementasi  Sistem  Akuntabilitas  Kinerja  Instansi 
Pemerintah  (SAKIP)  atau  evaluasi  AKIP.  Evaluasi  AKIP 
dilakukan untuk meningkatan akuntabilitas dan kinerja instansi 
pemerintah.  Namun,  saat  ini  sistem  yang  digunakan  masih 
kurang efisien dalam mengevaluasi ratusan unit kerja BPS yang 
tersebar  di  seluruh  Indonesia.  Sehingga  diperlukan  sistem 
aplikasi yang lebih efisien.  Berdasarkan permasalahan tersebut, 
peneliti  melakukan  penelitian  untuk  merancang  dan  mendesain 
sistem  yang  lebih  efisien  dalam  mengevaluasi  implementasi atas 
SAKIP.  Perancangan  sistem  dilakukan  dengan  metode  System 
Development  Life  Cycle  (SDLC)  model  Waterfall.  Hasil  dari 
ini  berupa  rancangan  aplikasi  evaluasi  atas 
penelitian 
implemntasi  SAKIP  serta  Product  Requirement  Document 
(PRD) dan Functional Specification Document (FSD) yang telah 
disetujui oleh tim TI buntama dan disahkan oleh kepala bagian 
umum  inspektorat  utama  BPS.  Berdasarkan  hasil  evaluasi, 
rancangan  yang  dibuat  sudah  konsisten,  sesuai  kebutuhan 
pengguna  dan  memiliki  tingkat  kepuasan  7,6375  berdasarkan 
QUIS. 

Kata  Kunci—  Evaluasi  AKIP,  SAKIP,  SDLC  waterfall, 

consistency analysis. 

I.  LATAR BELAKANG 

yang 

(BPS)  merupakan 

Badan  Pusat  Statistik 

bertugas  melaksanakan 

lembaga 
tugas 
pemerintahan 
pemerintahan  di  bidang  statistik  [1].  BPS  dipimpin  oleh 
seorang  kepala  yang  dibantu  oleh  sekretaris  utama,  lima 
deputi,  dan  inspektorat  utama.  Inspektorat  utama  bertugas 
terhadap  pelaksanaan 
melakukan  pengawasan  fungsional 
tugas  di  lingkungan  BPS  [1].  Bentuk  pelaksanaan  tugas 
inspektorat  tersebut  antara  lain  berupa  jaminan,  konsultasi, 
dan  pengawasan 
jaminan, 
inspektorat  utama  melakukan  kegiatan  audit,  reviu,  evaluasi, 
dan  pemantauan.  Salah  satu  evaluasi  yang  dilakukannya 
adalah 
(Sistem 
Akuntabilitas  Kinerja  Instansi  Pemerintah)  atau  evaluasi 
AKIP. 

lainnya.  Dalam  pelaksanaan 

implementasi  SAKIP 

evaluasi 

atas 

Berdasarkan peraturan menteri PAN-RB RI no. 88 tentang 
evaluasi akuntabilitas kinerja instansi pemerintah [2], evaluasi 
AKIP  adalah  aktivitas  analisis  yang  sistematis,  pemberian 
nilai,  atribut,  apresiasi,  dan  pengenalan  permasalahan,  serta 
pemberian  solusi  atas  masalah  yang  ditemukan  guna 
peningkatan  akuntabilitas  dan  peningkatan  kinerja  instansi 
pemerintah.  Evaluasi  AKIP  merupakan  hal  yang  penting 
dalam  suatu  instansi  pemerintah.  Kegiatan  ini  adalah  salah 

satu  strategi  pemerintah  dalam  mewujudkan  pemerintahan 
yang  bersih,  akuntabel,  kapabel,  serta  meningkatkan  kualitas 
pelayanan publik terhadap masyarakat. Tujuan evaluasi AKIP 
secara  umum  adalah  untuk  mengetahui  seberapa 
jauh 
implementasi  SAKIP  dilaksanakan,  serta  untuk  mendorong 
peningkatan  pencapaian  kinerja  yang  tepat  sasaran  dan 
berorientasi  hasil,  sehingga  diharapkan  dapat  mendorong 
setiap  instansi  pemerintah  baik  pusat  maupun  daerah  untuk 
berkomitmen  dan  secara  konsisten  mewujudkan  capaian 
kinerja yang telah direncanakan melalui implementasi SAKIP 
[2].  Inspektorat  utama  harus  melakukan  evaluasi  atas 
implementasi SAKIP pada seluruh unit kerja BPS di Indonesia. 
Sehingga,  inspektorat  utama  perlu  mengevaluasi  ratusan  unit 
kerja  BPS  yang  tersebar  di  Indonesia.  Untuk  mengevaluasi 
ratusan  unit  kerja  diperlukan  sistem  informasi  yang  efisien, 
dapat menghemat waktu dan tenaga.  

google 

Terdapat  6  tahapan  dalam  melakukan  evaluasi  AKIP, 
antara  lain  tahap  permintaan  dokumen,  tahap  evaluasi  oleh 
anggota  tim,  tahap  reviu  oleh  ketua  tim,  tahap  reviu  oleh 
pengendali  teknis,  tahap  tindak  lanjut,  dan  tahap  panelisasi. 
Saat  ini,  sistem  yang  berjalan  masih  menggunakan  berbagai 
fitur  google.  Tahap  permintaan  dokumen  dilakukan 
untuk  mengumpulkan 
form 
menggunakan 
dokumennya kemudian koordinator akan menampilkan daftar 
data  yang  telah  dikumpulkan  tersebut  menggunakan  loker 
studio  google.  Tahap  evaluasi  dan 
reviu  dilakukan 
menggunakan  lembar  kerja  evaluasi  (LKE)  dalam  bentuk 
google  sheets.  LKE  berupa  google  sheets  tersebut  dibuat 
menggunakan  google 
tahunnya, 
koordinator  perlu  membuat  ratusan  LKE  baru  yang  kosong 
untuk  mengevaluasi  seluruh  unit  kerja  BPS.  Tahap  tindak 
lanjut  dan  panelisasi  juga  dilakukan  menggunakan  google 
sheets.  Selain  6  tahapan  tersebut,  terdapat  proses  memonitor 
evaluasi  AKIP  yang  telah  dilakukan  oleh  pengguna  untuk 
melihat  berapa  persen  progres  yang  telah  selesai.  Progres 
tersebut ditampilkan dalam bentuk loker studio google. Hasil 
dari evaluasi AKIP berupa laporan hasil evaluasi (LHE) yang 
kemudian dikirimkan ke masing-masing unit kerja BPS. Saat 
ini, dalam pengiriman LHE dilakukan melalui e-mail. 

script.  Setiap 

apps 

Proses  evaluasi  AKIP  yang  menggunakan  berbagai  fitur 
google tersebut tentu kurang efektif. BPS tidak menggunakan 
google  workspace.  Sehingga,  terdapat  banyak  keterbatasan 
dalam  menggunakan  fitur-fitur  google  tersebut.  Belum  ada 
aplikasi  yang  dapat  menampung  seluruh  tahapan  dalam  satu 
sistem.  Maka,  inspektorat  utama  perlu  membangun  aplikasi 
yang  dapat  digunakan  untuk  mengevaluasi  implementasi 
SAKIP secara efisien. 

 1 / 8 

 
 
 
 
 
beberapa 

penelitian 

Peneliti  menemukan 

terkait 
perancangan  aplikasi  SAKIP.  Namun,  aplikasi-aplikasi 
tersebut  hanya  digunakan  untuk  mengumpulkan  dokumen-
dokumen yang dibutuhkan untuk implementasi SAKIP. Tidak 
ditemukan  penelitian  terkait  aplikasi  yang  dapat  digunakan 
untuk mengevaluasi implementasi SAKIP tersebut. Sehingga, 
untuk  membuat  aplikasi  tersebut,  tidak  bisa  mengadopsi 
aplikasi  yang  sudah  ada.  Oleh  karena  itu,  penelitian  ini  akan 
membahas 
tentang  perancangan  aplikasi  evaluasi  atas 
implementasi SAKIP  

II.  TUJUAN PENELITIAN 

Berdasarkan  latar  belakang  yang  telah  dijelaskan  di  atas, 

tujuan penelitian ini adalah sebagai berikut. 

1.  Merancang  sistem  yang  dapat  mengumpulkan  dan 
menampilkan  seluruh  informasi,  data,  dan  dokumen 
terkait  evaluasi  atas  implementasi  SAKIP  dalam  satu 
aplikasi.  

2.  Merancang  aplikasi  yang  dapat  mempermudah  dalam 
penyusunan  LKE  dan  KKE  sehingga  dapat  lebih 
menghemat waktu dan tenaga. 

3.  Merancang  sistem  yang  dapat  membatasi  proses 
evaluasi dan reviu dengan fitur kunci penilaian LKE. 

III. PENELITIAN TERKAIT 

[3].  Penelitian 

Terdapat  beberapa  penelitian 

terkait  pengembangan 
aplikasi  SAKIP  yang  telah  dilakukan  sebelumnya.  Pertama, 
peneltian  yang  dilakukan  oleh  Handoyo  Saputra,  Fajar 
ini 
Pradana,  dan  Bayu  Priyambadha 
menggunakan  metode  waterfall.  Dari 
tahapan  analisis 
kebutuhan  menghasilkan  kebutuhan  bahwa  aplikasi  yang 
dibuat  harus  dapat  diakses  dari  berbagai  peramban  yang 
berbeda serta membutuhkan 33 fitur. Pada tahap perancangan, 
peneliti tersebut membuat  sequence diagram berdasarkan use 
case  diagram  yang  disusun,  merancang  diagram  kelas, 
algoritma,  basis  data,  serta  antarmuka  aplikasi.  Peneliti 
tersebut  menuturkan  bahwa  sequence  diagram  digunakan 
untuk  menjelaskan  alur  jalannya  program,  diagram  kelas 
digunakan  untuk  mengetahui  semua  kelas  yang  ada  pada 
aplikasi,  dan  perancangan  antarmuka  dilakukan  untuk 
mengetahui 
sebelum  memulai 
pengkodean. 

antarmuka 

gambaran 

Kedua,  penelitian  yang  dilakukan  oleh  Budi  Santoso, 
Satrianansyah, Armanto, dan Wendi Saputra [4]. Penelitian ini 
juga menggunakan metode waterfall. Pada tahap desain sistem, 
Budi Santoso, dkk membuat use case diagram dan merancang 
wireframe aplikasi. 

Ketiga, penelitian yang dilakukan oleh Nur Hayati, M. Rudi 
Fanani,  dan  Umi  Azizah  menggunakan  metode  Rapid 
Application Development (RAD) [5]. Penelitian ini bertujuan 
untuk  menganalisis  dan  merancang  basis  data  aplikasi  E-
SAKIP.  Sehingga,  pada  tahap  perancangan,  peneliti  tersebut 
merancang sistem menggunakan Entity Relationship Diagram 
(ERD),  Context  Diagram  (CD),  dan  Data  Flow  Diagram 
(DFD). 

IV. METODE PENELITIAN  

A.  Metode Pengumpulan Data 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

1.  Wawancara  :  Pengumpulan  data  melalui  wawancara 
dilakukan  pada  beberapa  pegawai  BPS  bagian 
informasi 
inspektorat  utama  untuk  mengetahui 
mengenai  proses  bisnis  evaluasi  atas  implementasi 
SAKIP  yang  sedang  berjalan.  Wawancara 
juga 
dilakukan  untuk  mengidentifikasi  masalah  dan 
kebutuhan apa saja yang diperlukan dalam membangun 
aplikasi  yang  lebih  efisien  dalam  menghemat  waktu 
dan  tenaga.  Peneliti  perlu  berkali-kali  melakukan 
wawancara  dan  berdiskusi  dengan  narasumber 
mengenai  perancangan  sistem  yang  akan  dibuat. 
dengan 
Wawancara 
mendatangi  kantor  BPS  pusat  dan  secara  online 
melalui zoom meeting atau whatsapp. 

dilakukan 

offline 

secara 

2.  Studi  literatur  :  Pengumpulan  data  melalui  studi 
literatur  dilakukan  dengan  mencari  sumber-sumber 
informasi  yang  dapat  membantu  dalam  perancangan 
sistem.  Sumber-sumber  yang  digunakan  antara  lain, 
situs-situs  web,  jurnal  mengenai  penelitian-penelitian 
tentang  pengembangan  sistem 
terkait,  buku-buku 
informasi 
atas 
implementasi  SAKIP,  serta  peraturan  perundang-
undangan  yang  melandasi  terselenggaranya  evaluasi 
AKIP. 

pedoman 

evaluasi 

buku 

dan 

B.  Metode Perancangan Sistem 

Perancangan  sistem  dilakukan  dengan  metode  System 
Development Life Cycle (SDLC) model waterfall. Metode 
ini memiliki kelebihan mengidentifikasi kebutuhan sistem 
jauh sebelum pemrograman dimulai [6]. Sehingga, analisis 
kebutuhan  sistemnya  dapat  lebih  matang  dan  ketika 
lebih  mudah  karena 
memulai  pemrograman  akan 
terperinci.  Berikut 
kebutuhan 
merupakan gambar tahapan metode waterfall [6]. 

jelas  dan 

sistemnya 

Gambar 1. Tahapan metode waterfall. Sumber : A. Dennis [6]. 

1.  Tahap 

(Planning). 

perencanaan 

Perencanaan 
merupakan  proses  dasar  untuk  memahami  mengapa 
sistem  informasi  yang  akan  diteliti  penting  untuk  
ini,  peneliti  melakukan 
dibangun.  Pada 
wawancara  dengan  narasumber  dan  studi  literatur 
untuk  mencari  tahu  latar  belakang  perlunya  dilakukan 
perancangan  sistem  yang  baru  daripada  menggunakan 

tahap 

 2 / 8 

 
 
 
 
  
 
sistem  yang  sudah  ada.  Peneliti  berdiskusi  dengan 
narasumber  mengenai  rencana  sistem  yang  ingin 
dibangun. 
2.  Tahap  analisis 

(Analysis).  Tahap  analisis  akan 
menjawab  berbagai  pertanyaan  mengenai  siapa  saja 
yang  akan  menggunakan  sistem,  apa  saja  yang  akan 
dilakukan  sistem,  serta  di  mana  dan  kapan  sistem 
tersebut  akan  digunakan.  Berdasarkan  informasi  yang 
telah  dikumpulkan  melalui  wawancara  dan  studi 
literatur, selanjutnya dilakukan analisis sistem berjalan, 
analisis masalah, dan analisis kebutuhan sistem. 

3.  Tahap  desain 

ini  menentukan 
(Design).  Tahap 
bagaimana  sistem  akan  beroperasi  pada  perangkat 
keras,  perangkat  lunak,    dan  infrastruktur  jaringan, 
bagaimana  desain  antarmuka  penggunanya  dan 
struktur basis data yang akan digunakan. Pada tahap ini 
peneliti  merancang  sistem  menggunakan  use  case 
diagram, activity diagram, serta merancang antarmuka 
aplikasi,  arsitektur  sistem,  dan  basis  data.  Use  case 
diagram  digunakan  untuk  mengilustrasikan  fungsi 
utama dari sistem dengan sederhana dan berbagai jenis 
pengguna  yang  berinteraksi  dengan  fitur  tersebut. 
Activity diagram digunakan untuk memodelkan proses 
bisnis sistem [6]. Antarmuka pengguna juga dirancang 
untuk  memberikan  gambaran  tampilan  sistem  yang 
dirancang  kepada  narasumber  atau  pengguna  yang 
akan menggunakan aplikasi tersebut nantinya. 

4.  Tahap 

implementasi  (Implementation).  Tahap 

ini 
mengimplementasikan  rancangan  yang  telah  dibuat. 
Kemudian menghasilkan suatu sistem. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

evaluasi  dengan  QUIS  berjumlah  5  orang  responden. 
Pengujian  dengan  5  orang  memungkinkan  peneliti 
menemukan  masalah  yang  hampir  sama  banyaknya 
dengan menggunakan pengujian lebih dari 5 orang [8]. 

V.  KERANGKA PIKIR 

Penelitian  diawali  dengan  adanya  masalah  berupa  sistem 
yang  saat  ini  berjalan  untuk  mengevaluasi  implementasi 
SAKIP masih belum efisien dan masih menggunakan berbagai 
fitur pada google yang terpisah-pisah. Selanjutnya diperlukan 
tersebut  dengan 
solusi  untuk  mengatasi  permasalahan 
merancang aplikasi evaluasi atas implementasi SAKIP dengan 
lebih  efisien  berbasis  situs  web.  Metode  yang  digunakan 
adalah  waterfall.  Tahap  perencanaan  dilakukan  melalui 
wawancara  dan  studi  literatur.  Tahap  analisis  dilakukan 
dengan analisis sistem berjalan, analisis masalah, dan analisis 
kebutuhan.  Dalam  merancang  aplikasi  digunakan  use  case 
diagram,  activity  diagram  rancangan  antarmuka,  rancangan 
basis  data,  serta  rancangan  arsitektur  sistem.  Hasil  dari 
ini  berupa  rancangan  aplikasi  evaluasi  atas 
penelitian 
implementasi SAKIP dengan Product Requirement Document 
(PRD)  dan  Functional  Specification  Document  (FSD)  yang 
telah  disetujui  oleh  tim  TI  dan  disahkan  oleh  kepala  bagian 
umum  inspektorat  utama  BPS.  PRD  mencakup  kebutuhan 
bisnis,  persyaratan  bisnis,  nilai  bisnis,  istilah-istilah  terkait 
sistem yang dirancang, serta daftar penjelasan fitur-fitur yang 
diperlukan  dalam  sistem.  Sedangkan  FSD  mencakup  daftar 
kebutuhan  fungsional,  user  access  matrix,  use  case  diagram, 
proses  bisnis  berupa  activity  diagram,  serta  rancangan 
antarmuka aplikasi. 

C.  Metode Evaluasi Rancangan Sistem 

untuk  mengevaluasi 

pengguna.  Peneliti 
analysis 

Evaluasi  sistem  dilakukan  dengan  mewawancarai 
narasumber mengenai desain diagram dan antarmuka yang 
telah  dibuat.  Wawancara  dilakukan  untuk  mengetahui 
apakah  rancangan  yang  telah  dibuat  sudah  sesuai  dengan 
kebutuhan 
juga  menggunakan 
apakah 
consistency 
rancangan yang dihasilkan konsisten, sesuai dengan tujuan 
perancangan  aplikasi.  Ada  3  tahap  dalam  melakukan 
consistency  analysis  [7].  Tahap  pertama  melakukan 
identifikasi  ke  dalam  4  komponen  layer  yang  telah 
dijelaskan sebelumnya. Tahap kedua melakukan pemetaan 
dan  merelasikan  komponen-komponen  yang 
telah 
diidentifikasi.  Tahap  terakhir  menghitung  requirement 
consistency  index  (RCI)  untuk  mengetahui  persentase 
konsistensi sistem dengan formula berikut ini. 

RCI = A/(B+C) (1) 

Keterangan : 
A : Jumlah elemen kebutuhan yang konsisten 
B : Jumlah total elemen kebutuhan 
C : Jumlah elemn kebutuhan yang tidak terdefinisi 

Selain itu, peneliti juga menggunakan QUIS 7.0 untuk 
mengetahui 
tingkat  kepuasan  pengguna  berdasarkan 
rancangan  antarmuka  yang  telah  dibuat.  Responden  pada 

Gambar 2. Kerangka pikir penelitian 

 3 / 8 

 
 
 
 
 
VI. HASIL DAN PEMBAHASAN 

A.  Proses Bisnis Sistem Berjalan 

Gambar  3  menunjukkan  proses  bisnis  sistem  yang 
berjalan saat ini. Koordinator mengumpulkan bahan materi 
evaluasi AKIP berupa materi pelatihan, pedoman evaluasi, 
undang-undang, peraturan dan buku laporan hasil evaluasi 
tahun-tahun  sebelumnya  pada  google  sites  sebagai  bahan 
anggota  tim,  ketua  tim,  dan  pengendali  teknis  untuk 
melakukan  evaluasi  AKIP.  Sebelum  memulai  mekanisme 
evaluasi,  koordinator  perlu  membuat  LKE  dan  KKE 
(Kertas  Kerja  Evaluasi).  LKE  dan  KKE  dibuat 
menggunakan  google  apps  script.  Koordinator  perlu 
menyusun  kode  untuk  membuat  LKE  dan  KKE  dalam 
bentuk  google  sheets  sebanyak  547  unit  kerja.  Selain  itu, 
koordinator  juga  perlu  membagi  pegawai  inspektorat 
utama  menjadi  beberapa  tim  untuk  menilai  unit  kerja 
melalui  kegiatan  evaluasi  AKIP.  Berdasarkan  wawancara 
dengan  narasumber,  diketahui  mekanisme  evaluasi  AKIP 
secara umum dilakukan melalui 6 tahapan sebagai berikut. 
1.  Tahap  permintaan  dokumen  evaluasi.  Pada  tahap  ini, 
tim  koordinator  melakukan  permintaan  dokumen 
evaluasi  pada  setiap  unit  kerja  BPS  di  seluruh 
Indonesia  dengan  tujuan  untuk  memperoleh  data  dan 
fakta  yang  tertuang  dalam  beberapa  dokumen  milik 
unit kerja yang relevan dengan lingkup evaluasi AKIP. 
Dari  permintaan  tersebut,  unit  kerja  mengirimkan  link 
dokumen  yang  dibutuhkan  beserta  identitas  PIC  unit 
kerjanya  melalui  google  form.  Koordinator  akan 
permintaan 
informasi  mengenai 
menampilkan 
dokumen  melalui 
looker  studio  google  sehingga 
anggota  tim,  ketua  tim,  dan  pengendali  teknis  dapat 
mengaksesnya sebagai bahan untuk mengevaluasi unit 
kerja. 

2.  Tahap  evaluasi  oleh  anggota  tim.  Pada  tahap  ini, 
anggota  tim  mengevaluasi  unit  kerja  lewat  KKE  dan 
LKE  dalam  bentuk  google 
sheets  berdasarkan 
dokumen  evaluasi  unit  kerja  pada  tahap  permintaan 
dokumen.  Hasil  penilaian  unit  kerja  oleh  anggota  tim 
akan  otomatis 
tim  dan 
pengendali teknis untuk direviu. 

tersalin  ke  LKE  ketua 

3.  Tahap  reviu  oleh  ketua  tim.  Pada  tahap  ini,  ketua  tim 
mereviu hasil penilaian anggota tim. Apabila penilaian 
anggota  tim  sudah  sesuai,  ketua  tim  dapat  menandai 
bahwa  LKE  tersebut  telah  direviu.  Sedangkan  jika 
penilaian  anggota  tim  belum  sesuai,  ketua  tim  dapat 
tersebut  kemudian  menandai 
mengubah  penilaian 
bahwa  LKE  tersebut  telah  direviu.  Hasil  penilaian 
ketua  tim  akan  otomatis  tersalin  ke  LKE  pengendali 
teknis untuk kembali direviu. 

4.  Tahap  reviu  oleh  pengendali  teknis.  Pada  tahap  ini, 
pengendali  teknis  mereviu  hasil  penilaian  ketua  tim. 
Apabila  penilaian  ketua  tim  sudah  sesuai,  pengendali 
teknis  dapat  menandai  bahwa  LKE  tersebut  telah 
direviu.  Sedangkan  jika  penilaian  ketua  tim  belum 
sesuai,  pengendali  teknis  dapat  mengubah  penilaian 
tersebut kemudian menandai bahwa LKE tersebut telah 
direviu. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

5.  Tahap tindak lanjut. Pada tahap ini, hasil penilaian unit 
kerja  akan  diperlihatkan  dalam  bentuk  google  sheets. 
PIC  unit  kerja  diharapkan  dapat  memperbaiki 
dokumen-dokumen  yang  dibutuhkan  supaya  hasil 
penilaian  dapat  diubah  menjadi 
lebih  baik.  Jika 
dokumen  yang  dibutuhkan  sudah  diperbaiki,  PIC  unit 
kerja  dapat  menandai  pada  google  sheets  tersebut 
bahwa dokumennya sudah diperbaiki. 

6.  Tahap  panelisasi.  Berdasarkan  pedoman  evaluasi  atas 
implementasi  SAKIP  [9],  “Mekanisme  panelisasi 
adalah  membandingkan  hasil  evaluasi  seluruh  satker 
guna  meminimalisir  adanya  perbedaan  persepsi  pada 
saat  melakukan  evaluasi”.  Tahap  ini  dilakukan  oleh 
ketua  tim  dan  pengendali  teknis.  Panelisasi  juga 
dilakukan  menggunakan  google 
sheets.  Apabila 
terdapat  perbedaan  persepsi  dengan  tim  lain  saat 
melakukan  evaluasi,  maka  ketua  tim  atau  pengendali 
teknis  dapat  mengubah  hasil  evaluasi  unit  kerjanya 
pada google sheets tersebut. 

Selama  proses  evaluasi,  reviu,  dan  tindak  lanjut 
berlangsung,  kegiatan  termonitor  melalui  looker  studio 
google. Setelah tahap panelisasi selesai, pengendali teknis 
perlu  mengirim  LHE  (laporan  hasil  evaluasi)  kepada  unit 
kerja yang dievaluasi. Sebelum itu, pengendali teknis atau 
ketua tim perlu mengunduh template LHE yang disediakan 
oleh  koordinator  dengan  nama  fitur  generate  LHE.  Pada 
template LHE tersebut sudah memuat nilai unit kerja yang 
dievaluasi,  tetapi  belum  terdapat  nomor  surat,  tanggal, 
tempat penerima, dan tanda tangan anggota tim, ketua tim, 
dan  pengendali  teknis.  Sehingga  anggota  tim,  ketua  tim, 
dan  pengendali  teknis  perlu  melengkapi  LHE  tersebut 
sebelum  mengirimkannya  pada  unit  kerja.  Pada  sistem 
yang berjalan, pengiriman LHE dilakukan melalui e-mail. 

Gambar 3. Proses bisnis sistem berjalan 

B.  Analisis Masalah 

Berdasarkan proses bisnis sistem yang berjalan saat ini, 

diperoleh beberapa masalah sebagai berikut. 
1.  Sistem  yang  berjalan  masih  menggunakan  berbagai 
fitur  google.  Belum  ada 
sistem  yang  dapat 
menampung  seluruh  proses  evaluasi  AKIP  dalam 
satu aplikasi. 

 4 / 8 

 
 
 
 
laman 

google  workspace 

2.  Koordinator  setiap  tahunnya  perlu  membuat  KKE 
dan  LKE  baru  yang  masih  kosong  untuk 
mengevaluasi  unit  kerja.  KKE  dan  LKE  berbentuk 
google sheet dibuat menggunakan google apps script. 
Berdasarkan 
[10], 
kelemahan  dari  google  apps  script  ini,  maksimal 
hanya dapat menjalankan hasil pengkodean selama 6 
menit, kemudian terputus dan pengguna tidak tahu di 
kode  mana  yang  terputus.  Padahal,  kode  yang 
dijalankan sangat banyak karena butuh membuat 547 
KKE  dan  LKE  untuk  mengevaluasi  547  unit  kerja. 
Sehingga,  pengguna  perlu  memecah  kode  tersebut 
menjadi  beberapa  bagian  dan  menjalankan  kodenya 
berkali-kali. Selain itu, BPS juga tidak menggunakan 
google workspace. Hal ini membatasi jumlah google 
sheet  yang  dapat  dibuat  dalam  sehari.  Google  apps 
script  hanya  bisa  membuat  sebanyak  250  google 
sheets per hari. 

3.  LKE  yang  dibuat  menggunakan  google  sheets  tidak 
bisa  membatasi  kapan  anggota  tim,  ketua  tim,  dan 
pengendali  teknis  dapat  mengubah  penilaian,  kapan 
mereka  sudah 
tidak  dapat  mengubah  penilaian. 
Apabila  anggota  tim  sudah  memberikan  nilai  A  dan 
ketua  tim  menyetujui  nilai  tersebut,  tetapi  kemudian 
anggota  tim  mengubah  nilainya  menjadi  B,  maka 
penilaian  yang  tersalin  di  ketua  tim  juga  akan 
berubah  menjadi  B.  Padahal  ketua 
tim  sudah 
menyetujui  nilai  A,  tetapi  nilai  dari  anggota  tim 
masih dapat berubah. Ketua tim bisa saja tidak sadar 
bahwa nilai yang disetujui telah diubah. 

C.  Analisis Kebutuhan 

Berdasarkan  analisis  masalah  yang  telah  dijelaskan, 
maka  dibutuhkan  sistem  yang  dapat  melakukan  hal-hal 
sebagai berikut. 
1.  Sistem  dapat  mengumpulkan  dan  menampilkan 
seluruh informasi, data, dan dokumen terkait evaluasi 
atas  implementasi  SAKIP  dalam  satu  aplikasi  sesuai 
dengan akses masing-masing peran; 

2.  Sistem  dapat  mempermudah  dan  conmempersingkat 

waktu dalam pembuatan KKE dan LKE baru; 

3.  Sistem  dapat  membatasi  proses  evaluasi  dan  reviu 

dengan fitur kunci penilaian LKE. 

D.  Desain 

1.  Proses Bisnis Sistem Usulan 

Setelah  mengetahui  kebutuhan-kebutuhan  yang 
diperlukan  narasumber,  peneliti  berdiskusi  dengan 
narasumber  mengenai  usulan proses  bisnis  sistem.  Secara 
umum, alur proses bisnis usulan dapat dilihat pada gambar 
4. 

Terdapat  perbedaan  pada  tahap  evaluasi  dan  reviu 
LKE.  Pada  proses  bisnis  berjalan,  ketika  tahap  reviu, 
anggota  tim  atau  ketua  tim  masih  dapat  mengubah 
penilaiannya  walaupun  sudah  melewati  reviu  ketua  tim 
atau  pengendali  teknis.  Sedangkan  pada  proses  bisnis 
usulan,  setelah  ketua  tim  atau  pengendali  teknis  mereviu 
penilaian,  mereka  diharuskan  untuk  mengunci  penilaian 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

tersebut.  Hal  ini  supaya  anggota  tim  atau  ketua  tim 
sebelumnya  tidak  dapat  mengubah  penilaiannya  lagi 
sehingga nilai pada LKE tidak dapat berubah lagi. 
Selain tahap evaluasi dan reviu, tahap lainnya memiliki alur 
yang  sama  secara  umum.  Perbedaanya  pada  proses  bisnis 
yang  berjalan  saat  ini,  sistem  menggunakan  berbagai  fitur 
pada  google.  Sedangkan  pada  proses  bisnis  usulan,  sistem 
menggunakan  satu  aplikasi  yang  dapat  menampung  semua 
tahapan  supaya  dapat  mengatasi  masalah  yang  ada  saat  ini. 
Sehingga, diperlukan perancangan yang lebih detail mengenai 
aplikasi evaluasi atas implementasi SAKIP. 

Gambar 4. Proses bisnis sistem usulan 

2.  Use Case Diagram 

Use  case  diagram  digunakan  untuk  menggambarkan 
interaksi  yang  dapat  dilakukan  oleh  aktor  pada  sistem. 
Berdasarkan hasil wawancara dengan narasumber, terdapat 
7  aktor  yang  terlibat  pada  sistem  evaluasi  AKIP,  antara 
lain  koordinator,  PIC  unit  kerja,  anggota  tim  (evaluator), 
ketua  tim,  pengendali  teknis,  kepala  unit  kerja,  dan 
inspektur. Gambar 5 menunjukkan use case diagram yang 
berhubungan  dengan  LKE.  Pada  use  case  terlihat  bahwa 
koordinator  dapat  mengelola  komponen  LKE,  sub 
komponen LKE, dan kriteria LKE. Sedangkan anggota tim, 
ketua tim, dan pengendali teknis hanya dapat mengisi LKE, 
melihat LKE tindak lanjut  (TL) dan melihat LKE per sub 
komponen. 

3.  Activity Diagram. 
utama 

Fitur 

pada 

aplikasi 

evaluasi 

atas 
implementasi SAKIP adalah fitur untuk mengisi LKE. 
Fitur  ini  merupakan  solusi  dari  masalah  LKE  untuk 
kegiatan evaluasi dan reviu yang tidak bisa membatasi 
kapan evaluator dapat mengubah penilaian dan kapan 
tidak  dapat  mengubah  penilaian.  Terdapat  tiga  aktor 
yang  berinteraksi  dengan  fitur  mengisi  LKE,  yaitu 
anggota 
teknis. 
Anggota  tim  mengisi  LKE  untuk  mengevaluasi  unit 
kerja  berdasarkan  kriteria  pada  LKE  dan  dokumen 
permintaan yang telah dikirimkan oleh unit kerja.  

tim,  dan  pengendali 

tim,  ketua 

Ketua  tim  menggunakan  fitur  mengisi  LKE  untuk 
mereviu apakah penilaian dari anggota tim sudah tepat 
atau belum. Jika sudah tepat, ketua tim dapat langsung 

 5 / 8 

 
 
 
 
 
mengunci penilaian yang sudah dilakukan anggota tim. 
Namun,  jika  belum  tepat,  ketua  tim  akan  mengubah 
penilaian tersebut kemudian mengunci penilaian yang 
telah  diubah.  Sehingga,  anggota  tim  sudah  tidak  bisa 
mengubah penilaiannya lagi. Apabila ketua tim hanya 
mengubah  penilaiannya  saja 
tanpa  menguncinya, 
tetap  dapat  mengubah  kembali 
anggota 
penilaiannya  dengan  membuka  kembali  LKE  dan 
menekan  tombol  simpan.  Sehingga,  penilaian  yang 
telah  diubah  oleh  ketua  tim  akan  berubah  seperti 
semula. 

tim 

tim 

tim  dan  anggota 

Begitu  pun  dengan  pengendali  teknis.  Pengendali 
teknis  menggunakan 
fitur  mengisi  LKE  untuk 
mereviu  penilaian  dari  ketua  tim  sudah  tepat  atau 
belum.  Jika  pengendali  teknis  mengunci  penilaian, 
tidak  dapat 
maka  ketua 
mengubah  penilaian  lagi.  Walaupun  ketua  tim  belum 
mengunci  penilai,  tetapi  jika pengendali  teknis  sudah 
mengunci  penilaian,  otomatis  anggota  tim  juga  tidak 
dapat mengubah penilaian lagi. Activity diagram fitur 
mengisi  LKE  dapat  dilihat  pada  gambar  6.  Tabel  I 
menjelaskan  aktivitas  yang  dilakukan  anggota  tim 
ketika  menggunakan  fitur  mengisi  LKE.  Penjelasan 
aktivitas  yang  dilakukan  ketua  tim  dan  pengendali 
teknis  ketika  menggunakan  fitur  mengisi  LKE  dapat 
dilihat pada tabel II dan III. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

komponen di halaman sub komponen 

2 

3 

4 

Kondisi : 
Kriteria 
sudah/belum 
terkunci? 

- 

Jika  kriteria  yang 
ingin  dinilai  belum 
terkunci,  maka  aktor  masih  bisa  menilai 
kriteria  tersebut.  Sedangkan  jika  kriteria 
yang  ingin  dinilai  sudah  terkunci,  maka 
aktor  sudah 
tidak  bisa  menilai  kriteria 
tersebut 

Aktor  menekan  tombol  simpan  jika  telah 
selesai menilai kriteria pada form LKE 

Belum : 
Menilai  kriteria 
pada  form  yang 
ditampilkan 

Sudah : 
Menekan 
tombol simpan 

Gambar 6. activity diagram yang berhubungan dengan LKE 

Penjelasan activity diagram fitur mengisi LKE oleh ketua tim 

TABEL II 

1 

2 

3 

4 

5 

6 

Gambar 5. Use case diagram yang berhubungan dengan LKE 

TABEL I 
Penjelasan activity diagram fitur mengisi LKE oleh anggota tim 

No 

Nama Proses 

Deskripsi 

1 

Membuka 
halaman 
LKE 

form 

Aktor membuka halaman form LKE dengan 
memilih  aksi  evaluasi  pada  salah  satu  sub 

No 

Nama Proses 

Membuka 
form LKE 

halaman 

Deskripsi 
Aktor  membuka  halaman  form 
LKE  dengan  memilih 
aksi 
evaluasi  pada  salah  satu  sub 
komponen  di  halaman 
sub 
komponen 

Kondisi : 
Kriteria  sudah/belum 
terkunci? 

- 

Belum : 
Kondisi 
mengubah penilaian? 

: 

Ingin 

tim 

Ya : 
Mengubah  penilaian 
anggota 
pada 
kriteria yang dipilih 
Tidak : 
Mengunci 
penilaian 
pada  kriteria  yang 
dipilih 

Jika  kriteria  yang  ingin  dinilai 
belum  terkunci,  apakah  aktor 
ingin  mengubah 
penilaian 
kriteria tersebut 

- 

Aktor  mengunci  penilaian  yang 
telah  diberikan  pada  kriteria 
yang dipilih 

Sudah : 
Menekan 
simpan 

tombol 

Aktor  menekan  tombol  simpan 
jika telah selesai menilai kriteria 
pada form LKE 

 6 / 8 

 
 
 
 
 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

8  menunjukkan  rancangan  hubungan  antar  entitas 
beserta atribut di dalamnya. 

TABEL III 

Penjelasan activity diagram fitur mengisi LKE oleh ketua tim 
No 

Nama Proses 

Deskripsi 
Aktor  membuka  halaman  form 
LKE  dengan  memilih 
aksi 
evaluasi  pada  salah  satu  sub 
komponen  di  halaman 
sub 
komponen 

1 

2 

3 

4 

5 

6 

Membuka 
halaman 
LKE 

form 

Kondisi : 
Kriteria 
sudah/belum 
terkunci? 

Belum : 
Kondisi  :  Ingin 
mengubah 
penilaian? 

Ya : 
Mengubah 
penilaian  ketua 
pada 
tim 
kriteria 
yang 
dipilih 
Tidak : 
Mengunci 
penilaian  pada 
kriteria 
yang 
dipilih 

Sudah : 
Menekan 
tombol simpan 

4.  Rancangan antarmuka 

- 

Jika  kriteria  yang  ingin  dinilai 
belum  terkunci,  apakah  aktor 
ingin  mengubah 
penilaian 
kriteria tersebut 

- 

Aktor  mengunci  penilaian  yang 
telah  diberikan  pada  kriteria 
yang dipilih 

Aktor  menekan  tombol  simpan 
jika telah selesai menilai kriteria 
pada form LKE 

Gambar 7. Rancangan antarmuka fitur mengisi LKE 

Antarmuka dirancang menggunakan aplikasi figma. 
Rancangan  antarmuka  dibuat  untuk  menggambarkan 
antarmuka  aplikasi  kepada  narasumber.  Perancangan 
antarmuka  dibuat  berdasarkan  kebutuhan  narasuber. 
Setiap  peneliti  membuat  rancangan  antarmuka  baru 
atau mengubah rancangan selalu didiskusikan dengan 
narasumber  supaya  dapat  menghasilkan  antarmuka 
yang 
dan  mudah 
sesuai 
dioperasikan. 

kebutuhan 

dengan 

Gambar 7. menampilkan rancangan antarmuka fitur 
untuk  mengisi  LKE.  Pada  gambar  tersebut  terdapat 
kriteria-kriteria  LKE  yang  akan  dievaluasi.  Setiap 
kriteria memiliki form nilai, nilai angka, dan catatan, 
serta panduan evaluator. Anggota tim, ketua tim, atau 
pengendali  teknis  menilai  unit  kerja  berdasarkan 
kriteria  yang  tertera  tersebut.  Mereka  akan  memilih 
kolom  nilai  dan  catatan.  Sedangkan  untuk  kolom 
nilai angka akan otomatis muncul ketika kolom nilai 
telah terisi. 

5.  Rancangan basis data 
basis 
Rancangan 

dilakukan 

dengan 
data 
mengidentifikasi  entitas-entitas  yang  diperlukan  pada 
basis  data.  Kemudian  menentukan  hubungan  antar 
entitas, atribut pada tiap entitas, dan definisi pada tiap 
atribut tersebut. Setelah mendefinisikan entitas-entitas 
tersebut,  langkah  selanjutnya  menentukan  hubungan 
antar  entitas  dan  atribut-atribut  di  dalamnya.  Gambar 

Gambar 8. Rancangan basis data 

6.  Rancangan arsitektur sistem 

Gambar  rancangan  arsitektur  sistem  dapat  dilihat 
pada  gambar  10.  Aplikasi  yang  akan  dirancang 

 7 / 8 

 
 
 
 
 
 
 
berbasis  web,  sehingga  pengguna  perlu  mengakses 
situs  web  evaluasi  AKIP  melalui  web  browser.  Situs 
web yang dirancang menggunakan framework laravel 
dan  bootstrap 
tampilannya.  Database 
Management  System  (DBMS)  yang  akan  digunakan 
adalah mysql. 

sebagai 

Gambar 10. Rancangan arsitektur sistem 

E.  Evaluasi Perancangan 
1.  Wawancara 

yang 

telah 

aplikasi 

Peneliti  melakukan  wawancara  dengan  pegawai 
akan 
inspektorat  utama  BPS  yang  nantinya 
menggunakan 
dirancang. 
Wawancara  dilakukan  untuk  mengetahui  apakah 
sesuai  dengan 
rancangan  yang  dibuat 
kebutuhan  pengguna  atau  belum.  Apabila  rancangan 
belum  sesuai,  maka  peneliti  akan  mengubah  atau 
memperbaiki rancangan tersebut hingga sesuai dengan 
kebutuhan  narasumber.  Setiap  pembuatan  rancangan 
fitur  baru  atau  perbaikan  rancangan  fitur,  peneliti 
selalu  memaparkan  hasilnya  pada  narasumber  untuk 
dievaluasi hingga hasil rancangannya disetujui. 

sudah 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

3.  Questionnaire of User Interface Satisfaction (QUIS) 

Peneliti  menggunakan  QUIS  7.0  untuk  mengetahui 
rancangan 
tingkat  kepuasan  pengguna  berdasarkan 
antarmuka  yang  telah  dibuat.  Responden  dalam  evaluasi 
ini  berjumlah  5  orang  pegawai  BPS  yang  nantinya  akan 
menggunakan aplikasi evaluasi atas implementasi SAKIP. 
Responden diberikan 32 pertanyaan  yang termasuk dalam 
6 kategori dengan interval nilai 0 hingga 9. 0 menyatakan 
bahwa  aplikasi  tersebut  buruk,  sedangkan  9  menyatakan 
bahwa aplikasi tersebut baik. Berdasarkan evaluasi dengan 
QUIS,  menghasilkan  nilai  7,6375  yang  menandakan 
bahwa  pengguna  sudah  cukup  puas  dengan  antarmuka 
aplikasi 

VII. 

PENUTUP 

Aplikasi evaluasi atas implementasi SAKIP telah dirancang 
untuk  dapat  mengumpulkan  dan  menampilkan  seluruh 
informasi,  data,  dan  dokumen 
terkait  evaluasi  atas 
implementasi  SAKIP  dalam  satu  aplikasi  serta  dapat 
mempermudah  dalam  penyusunan  LKE  dan  KKE  sehingga 
dapat  lebih  menghemat  waktu  dan  tenaga.  Aplikasi  juga 
dirancang  dengan  fitur  kunci  penilaian  LKE.  Rancangan 
aplikasi 
dengan 
menandatangi  Product  Requirement  Document  (PRD)  dan 
Functional Specification Document (FSD). Dokumen tersebut 
juga  telah  disahkan  oleh  kepala  bagian  umum  inspektorat 
utama BPS. Berdasarkan evaluasi dengan consistency analysis, 
rancangan yang dibuat sudah konsisten, sesuai dengan tujuan 
dibutuhkannya  aplikasi  evaluasi  atas  implementasi  SAKIP. 
Berdasarkan  QUIS,  didapatkan  bahwa  pengguna  telah  cukup 
puas dengan antarmuka aplikasi yang dirancang. 

narasumber 

dievaluasi 

telah 

oleh 

Setelah  mengevaluasi  dan  menyetujui  rancangan 
telah  disusun,  peneliti  menyusun  Product 
yang 
(PRD)  dan  Functional 
Requirement  Document 
Specification  Document 
Selanjutnya, 
narasumber  dan  tim  TI  buntama  inspektorat  utama 
BPS  menandatangi  dokumen  tersebut  sebagai  bukti 
bahwa  rancangan  aplikasi  evaluasi  atas  implementasi 
SAKIP  telah  dievaluasi  dan  disetujui.  Dokumen 
tersebut juga telah disahkan oleh kepala bagian umum 
inspektorat utama BPS. 

(FSD). 

2.  Consistency analysis 

yaitu 

layer, 

process 

business 

Selain  melalui  wawancara,  hasil  perancangan  juga 
dievaluasi menggunakan metode consistency analysis. 
Metode  ini  melakukan  identifikasi  pada  4  komponen 
layer, 
layer, 
requirements  layer,  dan  specification  layer.  Setelah 
mengidentifikasi  layer,  didapatkan  kebutuhan  yang 
konsisten  (A)  berjumlah  83,  total  elemen  kebutuhan 
(B) berjumlah 83, dengan rincian 3 business layer, 16 
process 
layer,  dan  32 
specification layer. Tidak ada elemen kebutuhan yang 
tidak  terdefinisi  (C).  Setiap  nilai  A,  B,  dan  C, 
dimasukkan dalam rumus RCI dan menghasilkan nilai 
100%.  Sehingga,  terbukti  bahwa  hasil  analisa  dan 
perancangan  sudah  sesuai  dan  konsisten  dengan 
kebutuhan sistem. 

layer,  32  requirements 

DAFTAR PUSTAKA 

[1]  Badan  Pusat  Statistik,  “Peraturan  Kepala  BPS  Nomor  7  Tentang 

Organisasi dan Tata Kerja BPS”. Jakarta, 2008. 

[2]  KemenPAN-RB, “Peraturan Menteri PAN-RB RI Nomor 88 Tentang 
Evaluasi Akuntabilitas Kinerja Instansi Pemrintah”. Jakarta,  2021. 
[3]  H.  Saputra,  F.  Pradana,  and  B.  Priyambadha,  “Pengembangan 
Elektronik-Sistem  Akuntabilitasi  Kinerja  Instansi  Pemerintah  untuk 
Dinas Perindustrian Kota Malang”, Jurnal Pengembangan Teknologi 
Informasi dan Ilmu Komputer, vol. 1, no.10, pp 1167-1175, Oktober 
2017. 

[4]  B.  Santoso,  Satrianansyah,  Armanto,  W.  Saputra,  “Sistem 
Akuntabilitasi  Kinerja  Instansi  Pemerintah  (SAKIP)  Berbasis  Web 
Mobile”, JUTIM (Jurnal Teknik Informatika Musirawas), vol. 6, no. 
1, pp 72-80, Juni 2021. 

[5]  N.  Hayati,  M.R.  Fanani,  U.  Azizah,  “Rancang  Bangun  Sistem 
Informasi  Akuntabilitas  Kinerja  Instansi  Pemerintah  Berbasis  E-
Government”, Kumpulan jurnaL Ilmu Komputer (KLIK), vol. 09, no. 
03, pp 479-490, 2022. 

[6]  A.  Dennis,  B.  H.  Wixon,  D.  Tegarden,  System  Analysis  &  Design 
An Object-Oriented Approach with UML. United States of America: 
Aptara, 2015. 

[7]  J.  Nielsen.  (2012,  6).  How  Many  Test  Users  in  a  Usability  Study? 
[Online].  Available:  https://www.nngroup.com/articles/how-many-
test-users/ 

[8]  A.  Subhan,  W.  H.  Haji,  “Analisa  Perancangan  Sistem  Informasi 
Manajemen  Validasi  Data  Pembangunan  Fiber  Optik”,  Jurnal 
Teknologi  Informasi  dan  Ilmu  Komputer  (JTIIK),  vol.  8  no.  5,  pp 
1107-1116, Desember, 2021. 

[9]  Inspektorat  Wilayah  I  BPS,  Pedoman  Evaluasi  Atas  Implementasi 
SAKIP. Jakarta : Inspektorat Utama Badan Pusat Statistik. 2022. 
[10] Google. (2022, 9). Kuota untuk Layanan Google [Online]. Available: 
https://developers.google.com/apps-script/guides/services/quotas. 

 8 / 8 

 
 
 
 
","2023-12-19T08:40:13.193174Z",221910730,"[{""start"":954,""end"":1058,""text"":"" merancang dan mendesain\\nsistem yang lebih efisien dalam mengevaluasi implementasi atas\\nSAKIP"",""labels"":[""Tujuan""]},{""start"":1109,""end"":1167,""text"":""System\\nDevelopment Life Cycle (SDLC) model Waterfall"",""labels"":[""Metode""]},{""start"":1194,""end"":1353,""text"":"" rancangan aplikasi evaluasi atas\\npenelitian\\nimplemntasi SAKIP serta Product Requirement Document\\n(PRD) dan Functional Specification Document (FSD)"",""labels"":[""Temuan""]},{""start"":1492,""end"":1624,""text"":""rancangan yang dibuat sudah konsisten, sesuai kebutuhan\\npengguna dan memiliki tingkat kepuasan 7,6375 berdasarkan\\nQUIS"",""labels"":[""Temuan""]}]",894.899,"2023-12-19T08:40:13.193174Z"
7,"1","Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Perbandingan Model Machine Learning dan Deep 
Learning dalam Memprediksi Curah Hujan Dasarian 
(Studi Kasus: Stasiun Meteorologi Kertajati) 

Hanivianisa Hamson (221910721, 4SD1) 
Dosen Pembimbing: Dr. Bony Parulian Josaphat, S.Si., M.Si. 

Ringkasan—  Indonesia  merupakan  salah  satu  negara  yang 
mengalami ancaman perubahan iklim yang berdampak pada pola 
dan distribusi curah hujan yang tidak menentu. Untuk itu, perlu 
adanya  penelitian  mengenai  prediksi  curah  hujan.  Oleh  karena 
itu,  penelitian  ini  berfokus  pada  penerapan  metode  machine 
learning  dan  deep  learning,  yaitu  Support  Vector  Regression 
(SVR),  Extreme  Gradient  Boosting  (XGBoost),  Multilayer 
Perceptron  (MLP),  dan  Long  Short-Term  Memory  (LSTM), 
dalam memprediksi curah hujan dasarian (sepuluh harian), serta 
menentukan model yang terbaik. Data penelitian ini dikumpulkan 
melalui  situs web Data Online BMKG dari Januari 1978 hingga 
Desember  2022.  Penelitian  ini  menggunakan  Grid  Search  CV 
untuk  melakukan  simulasi  hyperparameter  dan  memperoleh 
kombinasi  hyperparameter  terbaik.  Model  yang  telah  dibangun 
dievaluasi  menggunakan  ukuran  MAE,  RMSE,  dan  𝑹𝟐 .  Hasil 
kinerja  dari  keempat  model  tidak  berbeda  jauh.  Berdasarkan 
evaluasi kinerja pengujian dan visualisasi grafik, model prediksi 
LSTM  merupakan  model  terbaik  dalam  memprediksi  curah 
hujan  dasarian  di  Stasiun  Meteorologi  Kertajati,  dengan  nilai 
MAE sebesar 35,547, RMSE sebesar 54,590, dan 𝑹𝟐 sebesar 0,557. 
Kata  Kunci—  Curah  hujan  dasarian,  SVR,  XGBoost,  MLP, 

LSTM 

I.  LATAR BELAKANG 

Wilayah  Indonesia  terletak  di  garis  khatulistiwa  sehingga 
Indonesia  memiliki  iklim  muson  tropis  yang  menyebabkan 
Indonesia memiliki dua musim, yaitu musim hujan dan musim 
kemarau.  Kedua  musim  tersebut  ditandai  oleh  sering  atau 
jarangnya  curah  hujan.  Suatu  musim  dikatakan  musim  hujan 
jika curah hujan lebih dari 50 mm/dasarian (sepuluh harian) dan 
diikuti  oleh  dasarian  berikutnya,  sedangkan  musim  kemarau 
terjadi  ketika  curah  hujan  kurang  dari  50  mm/dasarian  dan 
diikuti  oleh  dasarian  berikutnya  [1].  Umumnya,  musim  di 
Indonesia berubah setiap setengah tahun. 

Indonesia  merupakan  salah  satu  negara  yang  mengalami 
ancaman perubahan iklim. Salah satu dampak dari perubahan 
iklim  adalah  pola  dan  distribusi  curah  hujan  yang  tidak 
menentu. Kejadian-kejadian ekstrem seperti curah hujan yang 
sangat  tinggi  dalam  waktu  singkat  dapat  mengakibatkan 
terjadinya banjir. Di sisi lain, curah hujan yang sangat rendah 
yang  berlangsung  secara  terus-menerus  dapat  menyebabkan 
musim  kemarau  berkepanjangan  sehingga  mengakibatkan 
terjadinya krisis air dan kekeringan. Selain itu, perubahan iklim 
dapat  membuat  musim  hujan  dan  kemarau  mengalami 
pergeseran. Hal ini tentu berdampak serius terhadap berbagai 
aspek kehidupan, salah satunya adalah sektor pertanian. 

Nuraisah  dan  Kusumo  [2]  melakukan  penelitian  dampak 
perubahan  iklim  terhadap  produksi  beras  di  Desa  Wanguk, 

Kecamatan Anjatan, Kabupaten Indramayu. Dari penelitian ini, 
disimpulkan  bahwa  petani  merasakan  perubahan-perubahan 
yang  terjadi  akibat  perubahan  iklim,  seperti  perubahan  masa 
tanam, perubahan suhu dan curah hujan, serta cuaca ekstrem. 
Selain itu dampak perubahan iklim yang dialami petani adalah 
penurunan pendapatan petani, penurunan hasil panen, semakin 
meningkatnya  serangan  organisme  pengganggu 
tanaman 
(OPT), dan terjadinya peningkatan risiko gagal panen 

Jawa Barat termasuk ke dalam tiga provinsi sentra produksi 
padi terbesar di Indonesia. Menurut data BPS, produksi padi di 
Provinsi  Jawa  Barat  mencapai  9,1  juta  ton  pada  tahun  2021. 
Meskipun begitu, Jawa Barat juga menjadi salah satu dari tiga 
provinsi  dengan  total  luas  potensi  gagal  panen  terbesar  di 
Indonesia  pada  tahun  2021.  Berdasarkan  hasil  pendataan 
Kerangka  Sampel  Area  (KSA)  oleh  BPS,  luas  potensi  gagal 
panen di Jawa Barat pada tahun 2021 mencapai 29,3 ribu hektar. 
Penyebab  gagal  panen  atau  rusak  umumnya  adalah  bencana 
alam,  seperti  banjir  dan  kekeringan,  serta  serangan  OPT  [3]. 
Wilayah  Jawa  Barat  memang  dikenal  sebagai  daerah  yang 
rawan akan bencana banjir. Berdasarkan data Badan Nasional 
Penanggulangan Bencana (BNPB), telah terjadi sebanyak 2011 
kejadian bencana alam di Jawa Barat pada tahun 2021, dengan 
303 di antaranya merupakan bencana banjir. 

Curah  hujan  merupakan  faktor  alam  yang  perlu  menjadi 
perhatian  khusus  karena  curah  hujan  yang  ekstrem  dapat 
berdampak  pada  bencana  alam.  Informasi  curah  hujan  yang 
akurat sangat bermanfaat bagi kehidupan masyarakat. Selain itu, 
informasi  curah  hujan  dasarian  dapat  digunakan  untuk 
mengetahui  awal  masuk  musim  hujan  dan  musim  kemarau 
sehingga dapat membantu masyarakat. Untuk itu, perlu adanya 
penelitian mengenai prediksi curah hujan dasarian.  

Menurut Swarinoto dan Sugiyono [4], curah hujan memiliki 
keterkaitan dengan unsur-unsur cuaca. Tidak hanya suhu udara 
dan  kelembaban  udara,  tetapi  banyak  unsur  cuaca  lain  yang 
berpengaruh 
terhadap  curah  hujan.  Salah  satu  stasiun 
meteorologi di Jawa Barat yang melakukan pengamatan unsur-
unsur cuaca adalah Stasiun Meteorologi Kertajati yang berada 
di wilayah Kabupaten Majalengka.  

Sudah  banyak  penelitian  sebelumnya  yang  membangun 
model  untuk  memprediksi  curah  hujan.  Salah  satu  metode 
klasik  yang  digunakan  adalah  Auto  Regressive  Integrated 
Moving Average with Exogenous Inputs (ARIMAX). Namun, 
metode  ini  memiliki  beberapa  asumsi  yang  harus  terpenuhi, 
seperti asumsi stationeritas serta asumsi bahwa residual model 
harus white noise dan berdistribusi normal. Sebagai alternatif, 
para  peneliti  menggunakan  berbagai  pendekatan  machine 

 1 / 8 

 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

learning  karena  mampu  bekerja  pada  data  yang  nonstationer 
dan nonlinier [5, 6]. Beberapa metode machine learning yang 
sering digunakan adalah Support Vector Regression (SVR), K-
Nearest  Neighbor  (KNN),  Decision  Tree,  Random  Forest 
Regression,  dan  Extreme  Gradient  Boosting  (XGBoost). 
Penelitian  yang  dilakukan  oleh  Liyew  dan  Melese  [7] 
menunjukkan  bahwa  performa  XGBoost  dalam  memprediksi 
curah  hujan  di  Ethiopia  lebih  baik  dibandingkan  dengan 
Multivariate  Linear  Regression  (MLR)  dan  Random  Forest 
Regression,  dengan  nilai  MAE  dan  RMSE  sebesar  3,58  dan 
7,85.  Sementara  itu,  Zhang,  dkk.  [8]  membandingkan  model 
SVR  dan  Multilayer  Perceptron  (MLP)  untuk  memprediksi 
curah hujan tahunan dan diperoleh bahwa model SVR memiliki 
performa yang lebih baik dibandingkan dengan model MLP. 

learning dibandingkan dengan machine learning adalah feature 
extraction  dapat  dilakukan  secara  otomatis.  Pada  machine 
learning, sebagian besar karakteristik harus ditentukan secara 
manual yang membutuhkan pengetahuan khusus dan performa 
dari  sebagian  besar  algoritma  machine  learning  bergantung 
pada keakuratan fitur yang diekstraksi. Akan tetapi, kelemahan 
deep  learning  adalah  deep  learning  membutuhkan  kumpulan 
data yang besar untuk memahami data dengan baik. Dalam hal 
ini,  pendekatan  machine  learning  dapat  memberikan  kinerja 
yang lebih baik dibandingkan deep learning [12]. Oleh karena 
itu,  penelitian  ini  berfokus  pada  penerapan  metode  machine 
learning  dan deep learning, yaitu SVR, XGBoost,  MLP, dan 
LSTM,  dalam  memprediksi  curah  hujan  dasarian,  serta 
menentukan model yang terbaik. 

Selain  machine 

learning,  beberapa  penelitian 

juga 
menerapkan deep learning untuk prediksi curah hujan, seperti 
MLP dan Long Short-Term Memory (LSTM). Pada penelitian 
yang  dilakukan  oleh  Gu,  dkk.  [9],  MLP  memiliki  performa 
yang baik dalam memprediksi curah hujan ekstrem bulanan di 
Taihu  Basin,  China,  mengungguli  model  stacking  ensemble 
learning dan model  machine learning. Sementara  itu, sebuah 
penelitian  curah  hujan  di  Ethiopia  oleh  Endalie,  Halie,  dan 
Taye  [10]  menunjukkan  bahwa  model  LSTM  memiliki 
performa  yang  lebih  baik  dalam  memprediksi  curah  hujan 
dibandingkan  dengan  model MLP,  KNN,  Decision  Tree,  dan 
SVR. 

Saat ini, pendekatan deep learning lebih banyak digunakan 
oleh para peneliti karena memiliki performa yang baik.  Deep 
learning sangat bagus dalam menemukan struktur yang rumit 
dalam  data  berdimensi  tinggi  sehingga  dapat  diterapkan  di 
banyak bidang sains dan bisnis [11]. Keunggulan lain dari deep 

II.  TUJUAN PENELITIAN 

Berdasarkan latar belakang di atas, tujuan dari penelitian ini 

adalah sebagai berikut: 

1.  Mengetahui  gambaran  umum  curah  hujan  dasarian  di 

Stasiun Meteorologi Kertajati. 

2.  Mengetahui  kinerja  model  SVR,  XGBoost,  MLP,  dan 
LSTM dalam memprediksi curah hujan dasarian. 
3.  Menentukan  model  yang  terbaik  untuk  memprediksi 

curah hujan dasarian. 

III. PENELITIAN TERKAIT 

Uraian beberapa penelitian sebelumnya yang terkait dengan 

penelitian ini disajikan dalam Tabel I. 

TABEL I 
PENELITIAN TERKAIT 

Penulis, Publikasi 
Liyew,  C.  M.,  &  Melese,  H.  A. 
Journal  of  Big  Data,  8(1),  1-11. 
2021. [7] 

Metode Penelitian 
MLR,  RFR,  dan 
XGBoost 

No 
1 

Judul 
Machine  learning  techniques  to 
predict daily rainfall amount 

2 

3 

4 

5 

6 

7. 

Rainfall prediction using Extreme 
Gradient Boosting 

and 

Annual 
Non-Monsoon 
Rainfall  Prediction  Modelling 
Using  SVR-MLP:  An  Empirical 
Study From Odisha 
A  Stacking  Ensemble  Learning 
for  Monthly  Rainfall 
Model 
Prediction  in  the  Taihu  Basin, 
China 
Deep  learning  model  for  daily 
rainfall  prediction:  case  study  of 
Jimma, Ethiopia 
Deep  Learning  Models  for  the 
Prediction of Rainfall 

Prediksi  Curah  Hujan  Dasarian 
dengan Metode Vanilla RNN dan 
LSTM  untuk  Menentukan  Awal 
Musim Hujan dan Kemarau 

Anwar,  M.  T.,  Winarno,  E., 
Hadikurniawati,  W.,  &  Novita,  M. 
In  Journal  of  Physics:  Conference 
Series (Vol. 1869, No. 1, p. 012078). 
2021. [13] 
Zhang,  X.,  Mohanty,  S.  N.,  Parida, 
A.  K.,  Pani,  S.  K.,  Dong,  B.,  & 
Cheng,  X.  IEEE  Access,  8,  30223-
30233. 2020. [8] 
Gu, J., Liu, S., Zhou, Z., Chalov, S. 
R., & Zhuang, Q. Water, 14(3), 492. 
2022. [9] 

In 

S.,  Geetha, 

Endalie,  D.,  Haile,  G., & Taye,  W. 
Water  Supply,  22(3),  3448-3461. 
2022. [10] 
Aswin, 
Vinayakumar, 
International 
Communication 
Processing (ICCSP). 2018. [14] 
Devi,  N.  M.  M.  C,  dkk.  JEPIN 
(Jurnal  Edukasi  dan  Penelitian 
Informatika), 8(3), Desember 2022. 
[15] 

R. 
Conference 
and 

P.,  & 
2018 
on 
Signal 

Tertulis 
Performa  XGBoost  menghasilkan  MAE  dan 
RMSE yang lebih kecil dibandingkan dengan MLR 
dan RFR sehingga lebih baik dalam memprediksi 
curah hujan. 
Model yang dibangun menghasilkan prediksi yang 
akurat  untuk  prediksi  curah  hujan  harian  dengan 
MAE  pengujian  sebesar  8,8.  Faktor  yang  paling 
mempengaruhi  curah  hujan  adalah  kelembaban 
rata-rata dan suhu minimum. 
Prediksi  curah  hujan 
tahunan  untuk  Odisha 
menggunakan  model  SVR  menunjukkan  kinerja 
yang lebih baik daripada MLP. 

Pada skala agregasi tahunan, model stacking, SVR 
dan  XGBoost  berkinerja  baik  dalam  menerapkan 
prediksi  curah  hujan  tahunan.  Dalam  hal  curah 
hujan ekstrem, MLP mengungguli model stacking. 
Model  LSTM  menghasilkan  RMSE  yang  lebih 
kecil  dibandingkan  dengan  metode  MLP,  KNN, 
DT, dan SVR. 

XGBoost 

SVR dan MLP 

KNN,  XGBoost, 
SVR,  MLP,  dan 
stacking ensemble 
learning 
LSTM, MLP, DT, 
KNN, dan SVR 

LSTM dan CNN  Metode LSTM menghasilkan RMSE sebesar 2,55 
dan  MAPE  sebesar  1.69.  Sementara  itu,  metode 
ConvNet  menghasilkan  RMSE  sebesar  2,44  dan 
MAPE sebesar 1,73. 

Vanila  RNN  dan 
LSTM 

Model  Vanilla  RNN  mem-peroleh  𝑅2  sebesar 
0.6139, sedangkan LSTM memperoleh 𝑅2 sebesar 
0.5364. Epoch yang optimal sebesar 75. 

 2 / 8 

 
 
 
 
 
 
IV. METODE PENELITIAN  
Tahapan penelitian  ini  secara  umum diilustrasikan  melalui 

diagram alir pada Gambar 1. 

Gambar 1. Diagram alir penelitian 

A.  Pengumpulan Data  

Penelitian 

ini  menggunakan  data 

sekunder  yang 
dikumpulkan  melalui  situs  web  Data  Online  BMKG  di 
https://dataonline.bmkg.go.id/.  Situs  ini  menyediakan  data 
cuaca harian yang terdiri dari 10 unsur cuaca dan dapat diunduh 
dengan  maksimal  rentang  waktu  selama  1  bulan,  yaitu  suhu 
minimum,  suhu  maksimum,  suhu  rata-rata,  kelembaban  rata-
rata, 
lamanya  penyinaran  matahari,  kecepatan  angin 
maksimum,  kecepatan  angin  rata-rata,  arah  angin  saat 
kecepatan maksimum, arah angin terbanyak, dan curah hujan. 
Data cuaca harian ini dikumpulkan dari satu stasiun BMKG di 
Jawa  Barat,  yaitu  Stasiun  Meteorologi  Kertajati,  dengan 
periode 1 Januari 1978 hingga 31 Desember 2022.   

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Sebelum dilakukan normalisasi, dataset dibagi menjadi dua 
bagian,  yaitu  80%  data  latih  dan  20%  data  uji.  Normalisasi 
dilakukan menggunakan data latih dan kemudian disesuaikan 
pada data uji menggunakan parameter yang telah diperoleh dari 
data latih. Untuk normalisasi data menggunakan metode Min-
Max dengan rumus pada Persamaan 1.  

𝑋𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑 =

𝑋𝑖 − 𝑋𝑚𝑖𝑛
𝑋𝑚𝑎𝑥 − 𝑋𝑚𝑖𝑛

(1) 

C.  Pemodelan Machine Learning dan Deep Learning 

Sebelum  proses  pelatihan  model,  peneliti  menentukan 
hyperparameter  untuk  masing-masing  metode.  Selanjutnya, 
dilakukan  simulasi  hyperparameter  menggunakan  algoritma 
grid  search  selama  pelatihan  untuk  mendapatkan  kombinasi 
hyperparameter terbaik dari model prediksi. Dalam melakukan 
simulasi, model pelatihan divalidasi menggunakan  expanding 
window  cross-validation,  seperti  yang  ditunjukkan  pada 
Gambar 2. Penelitian ini menggunakan jumlah k sebanyak 5. 
Setelah  diperoleh  kombinasi  hyperparameter  terbaik  untuk 
masing-masing  metode,  data  uji  digunakan  sebagai  masukan 
untuk melakukan prediksi curah hujan dasarian menggunakan 
model yang telah dibangun. 

Gambar 2. Expanding window 5-split cross-validation 

B.  Preprocessing Data  

Dataset  yang  telah  dikumpulkan  selanjutnya  dilakukan 
preprocessing data. Beberapa hal yang dilakukan pada tahapan 
ini antara lain imputasi missing values, cleaning data, agregasi 
data,  penambahan  lag,  dan  normalisasi  data.  Data  dengan 
missing  value  diimputasi  menggunakan  metode  Multiple 
Imputation  by  Chained  Equations  (MICE).  Semua  variabel 
pada dataset dimasukkan ke dalam model imputasi terlepas dari 
apakah  mengandung  missing  values  atau  tidak,  termasuk 
variabel dependen dalam model analisis dan variabel auxiliary 
yang  tidak  digunakan  dalam  model  analisis  karena  diduga 
mengandung informasi mengenai nilai yang hilang [16]. 

Pada  proses  cleaning  data,  variabel  yang  tidak  digunakan 
dibuang dari kumpulan data. Data yang sudah diimputasi dan 
dibersihkan  selanjutnya  diagregasi  menjadi  data  dasarian, 
dengan  variabel-variabel  suhu,  kelembaban  udara,  dan 
kecepatan  angin  dihitung  rata-rata  selama  sepuluh  hari,  serta 
variabel  curah  hujan  dan  lama  penyinaran  matahari  dihitung 
itu,  dilakukan 
totalnya  selama  sepuluh  hari.  Setelah 
penambahan 
sebagai  variabel 
independen untuk meningkatkan akurasi model menggunakan 
korelogram PACF, dengan maksimal sebanyak 2 atribut. 

lag  variabel  dependen 

1.  Support Vector Regression (SVR) 

Support Vector Regression (SVR) adalah metode supervised 
machine  learning  yang  digunakan  untuk  mengatasi  masalah 
regresi.  SVR  merumuskan  masalah  pengoptimalan  untuk 
mempelajari  fungsi  regresi  dengan memetakan  input  variabel 
prediktor ke nilai keluaran yang diamati [17]. Keuntungan dari 
SVR adalah memiliki kemampuan generalisasi yang baik serta 
menghasilkan  akurasi  yang  tinggi  [18].  Konsep  umum  dari 
SVR adalah menemukan sebuah fungsi yang dapat memetakan 
data  input  ke  dalam  ruang  fitur  berdimensi  tinggi  secara 
nonlinier  dengan  memanfaatkan  fungsi  kernel  [9].  Terdapat 
beberapa  fungsi  kernel  yang  dapat  digunakan,  salah  satunya 
adalah  fungsi  kernel  radial  basis  (RBF).  Fungsi  kernel  RBF 
adalah  kernel  umum  yang  sebagian  besar  diterapkan  tanpa 
adanya  pengetahuan  sebelumnya  [17].  SVR  kernel  RBF 
memiliki tiga parameter, yaitu parameter C (Cost), 𝛾 (gamma), 
dan 𝜀 (epsilon). 

2)  Extreme Gradient Boosting (XGBoost) 

Extreme Gradient Boosting atau XGBoost adalah salah satu 
algoritma pohon keputusan dan merupakan implementasi dari 
metode  gradient  boosting  yang  populer  dalam  machine 

 3 / 8 

 
 
 
 
   
 
 
learning untuk permasalahan klasifikasi dan regresi. Algoritma 
ini  didasarkan  pada  konsep  boosting,  yaitu  menggabungkan 
learner  untuk 
semua  prediksi  dari  sekumpulan  weak 
mengembangkan  strong  learner  melalui  strategi  pelatihan 
tambahan  [19].  Pada  dasarnya,  XGBoost  melakukan  iterasi 
dalam membangun model prediksi. XGBoost menggabungkan 
beberapa model prediksi yang relatif lemah menjadi satu model 
prediksi  baru  yang 
iterasi  untuk 
memperbaiki  kesalahan  prediksi  pada  iterasi  sebelumnya  dan 
meningkatkan  ketepatan  model  prediksi.  XGBoost  dapat 
menjalankan  kalkulasi  paralel  secara  otomatis  selama  fase 
pelatihan tetapi juga mengoptimalkan sumber daya komputasi. 
Sifat XGBoost berbasis pohon insensitif terhadap outlier, dan 
seperti  kebanyakan  metode  boosting,  dapat  menghindari 
overfitting [20].  

lebih  kuat  di  setiap 

3)  Multilayer Perceptron (MLP)  

Multilayer  Perceptron  (MLP)  adalah  model  yang  banyak 
digunakan  dalam  aplikasi  Neural  Network  menggunakan 
algoritma  pelatihan  backpropagation  [21].  MLP  merupakan 
sistem neuron atau node yang tersusun berlapis-lapis dan saling 
berhubungan,  yang  terdiri  dari  lapisan  input,  satu  atau  lebih 
lapisan  tersembunyi,  dan  lapisan  output.    Node  dihubungkan 
oleh  nilai  bobot.  Output  dari  setiap  node  dihitung  sebagai 
jumlah  tertimbang  dari  input  yang  diterima  dan  dimodifikasi 
melalui fungsi aktivasi yang kemudian diumpankan ke depan 
untuk  menjadi  input  ke  node  di  lapisan  jaringan  berikutnya 
[22].  Output  yang  dihasilkan  tergantung  pada  pilihan  fungsi 
aktivasi. Beberapa fungsi aktivasi yang dapat digunakan antara 
lain  fungsi  aktivasi  linier,  unit  step,  sigmoid,  dan  hyperbolic 
tangent  [23].  Tujuan  pelatihan  MLP  adalah  untuk  mencari 
kombinasi  bobot  yang  dapat  menghasilkan  nilai  kesalahan 
terkecil.  

4)  Long Short-Term Memory (LSTM)  

Long  Short-Term  Memory  (LSTM)  merupakan  salah  satu 
jenis  dari  Recurrent  Neural  Network 
(RNN)  yang 
diperkenalkan pertama kali oleh Hochreiter dan Schmidhuber 
[24].  Dengan  memperkenalkan  fungsi  gate  ke  dalam  struktur 
sel,  LSTM  dapat  menangani  msalah  ketergantungan  jangka 
panjang  dengan  baik  [25].  Selain  itu,  LSTM  juga  dapat 
menghindari masalah vanishing gradient selama fase pelatihan 
[26]. Arsitektur LSTM terdiri dari satu set blok memori yang 
terhubung secara berulang, dengan setiap blok berisi satu atau 
lebih memory cells dan tiga unit multiplikatif, yaitu forget gate, 
input  gate,  dan  output  gate  [27].  Gerbang  multiplikatif 
memungkinkan  sel  memori  LSTM  untuk  menyimpan  dan 
mengakses informasi dalam jangka waktu yang lama, sehingga 
mengurangi masalah vanishing gradient. Input gate digunakan 
untuk  mengontrol  informasi  yang  akan  ditambahkan  ke  cell 
state  dan  mencegah  informasi  yang  tidak  berguna  memasuki 
cell  state  [26].    Output  gate  digunakan  untuk  mengontrol 
informasi dan menentukan hidden state selanjutnya. Sementara 
itu,  forget  gate  dapat  memutuskan  informasi  apa  yang  akan 
dibuang dari cell state [25]. 

D.  Evaluasi dan Pemilihan Model Terbaik  

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Pada  tahap  ini,  dilakukan  evaluasi  kinerja  model  regresi 
yang telah dibangun menggunakan perhitungan Mean Absolute 
Error  (MAE),  Root  Mean  Squared  Error  (RMSE),  dan 𝑅2 . 
Dari keempat model, dipilih model terbaik dengan kriteria nilai 
MAE  dan  RMSE  yang  terkecil,  serta  nilai 𝑅2 yang  terbesar. 
Rumus MAE, RMSE, dan 𝑅2 tertulis pada Persamaan 2, 3, dan 
4 berikut: 

𝑀𝐴𝐸 =

1

𝑛

∑ |𝑦̂𝑖 − 𝑦𝑖|

𝑛
𝑖=1

𝑅𝑀𝑆𝐸 = √∑
𝑛
𝑖=1
𝑛
𝑖=1

𝑅2 = 1 −

∑

∑

(𝑦̂𝑖−𝑦𝑖)2
𝑛
𝑖=1
𝑛
(𝑦̂𝑖−𝑦𝑖)2
(𝑦̅−𝑦𝑖)

2       

(2) 

(3) 

(4) 

V.  KERANGKA PIKIR 

Penelitian  ini  diawali  dengan  permasalahan  mengenai 
pentingnya  prediksi  curah  hujan.  Untuk  itu,  penelitian  ini 
menerapkan metode machine learning dan deep learning, yaitu 
SVR, XGBoost, MLP, dan LSTM dengan memanfaatkan Grid 
search CV untuk melakukan simulasi hyperparameter sehingga 
diperoleh  model  prediksi  curah  hujan  dengan  kombinasi 
hyperparameter 
terbaik.  Selanjutnya,  dilakukan  evaluasi 
kinerja model menggunakan MAE, RMSE, dan 𝑅2. Dari hasil 
evaluasi,  dipilih  model  prediksi  yang  terbaik.  Kerangka  pikir 
penelitian ini disajikan pada Gambar 3. 

Gambar 3. Kerangka pikir penelitian 

VI. HASIL DAN PEMBAHASAN 

A.  Preprocessing Data 

Sebelum  pembangunan  model  prediksi,  data  harus  melalui 
tahapan  preprocessing  agar  data  siap  untuk  dianalisis  lebih 
lanjut. Data yang telah dikumpulkan terdiri atas 16.436 record 
dan 9 atribut data cuaca. Data cuaca harian Stasiun Meteorologi 
Kertajati  masih  memiliki  missing  value.  Selain  itu,  masih 
terdapat  beberapa  nilai  yang  tidak  masuk  akal  yang  tercatat 
dalam  data,  seperti  nilai  8888  dan  9999  pada  variabel  curah 
hujan  dan  lama  penyinaran  matahari.  Kedua  nilai  tersebut 
menunjukkan  bahwa  data  tidak  terukur  atau  tidak  dilakukan 
pengukuran. Oleh karena itu, nilai 8888 dan 9999 yang terdapat 
di  dalam  data  diubah  terlebih  dahulu  menjadi  null  atau  nilai 
kosong. Setelah itu, data yang hilang diimputasi menggunakan 
metode  MICE.  Menurut  Seu,  Kang,  dan  Lee  [28],  metode 
MICE  memiliki  kinerja  yang 
lebih  baik  dibandingkan 
KNNimputer  dalam  mengimputasi  missing  values.  Penelitian 

 4 / 8 

 
 
 
    
 
    
 
 
 
 
  
ini  memanfaatkan  package  miceforest  menggunakan  bahasa 
pemrograman python. 

Data yang telah diimputasi selanjutnya  dilakukan  cleaning 
atau pembersihan data. Pada penelitian ini, variabel independen 
yang digunakan untuk membangun model prediksi curah hujan 
sebanyak empat variabel, yaitu suhu rata, kelembaban rata-rata, 
lamanya  penyinaran  matahari,  dan  kecepatan  angin  rata-rata. 
Oleh karena itu, variabel lain yang tidak digunakan dihapus dari 
dataset.  

Setelah  itu,  data  harian  diagregasi  menjadi  data  dasarian 
(sepuluh  harian).  Terdapat  tiga  dasarian  dalam  satu  bulan, 
dengan  dasarian  ke-1  dimulai  dari  tanggal  1  sampai  10, 
dasarian ke-2 dimulai dari tanggal 11 sampai 20, dan dasarian 
ke-3 dimulai dari tanggal 21 sampai 31. Variabel suhu rata-rata 
dan  kelembaban  rata-rata,  dan  kecepatan  angin  rata-rata, 
diagregasi  dengan  menghitung  nilai  rata-ratanya  selama 
sepuluh  hari.  Sementara  untuk  variabel  lamanya  penyinaran 
matahari dan curah hujan dihitung nilai totalnya selama sepuluh 
hari. Setelah diagregasi, data berjumlah 1620 record. 

Penelitian 

ini  menggunakan  korelogram  PACF  untuk 
melakukan penambahan lag. Lag variabel curah hujan dasarian 
yang  signifikan  ditambahkan ke  dalam  data  menjadi  variabel 
independen dengan maksimal sebanyak 2 atribut. Berdasarkan 
korelogram PACF, lag yang ditambah adalah lag 1 dan lag 2. 
Dengan dilakukan penambahan lag, jumlah data menjadi 1618 
record.   

Sebelum data dinormalisasi, dataset dibagi menjadi 2, yaitu 
data  latih  dan  data  uji.  Hal  ini  dilakukan  karena  data  uji 
dianggap sebagai data baru yang tidak terlihat sehingga tidak 
seharusnya  informasi  dari  data  tersebut  bocor  dan  digunakan 
dalam pelatihan model. Pada penelitian ini, peneliti membagi 
dataset  menjadi  80%  data  latih  dan  20%  data  uji,  sehingga 
terdapat 1294 record sebagai data latih dan 324 record sebagai 
data uji. Selanjutnya, data dinormalisasi menggunakan metode 
Min-Max. 

B.  Gambaran Umum Curah Hujan Dasarian  

Pada Gambar 4, dapat dilihat bahwa curah hujan dasarian di 
Stasiun  Meteorologi  Kertajati  cenderung  berfluktuatif.  Curah 
hujan dasarian ini bersifat musiman. Dapat dilihat bahwa total 
curah hujan dasarian tinggi di akhir dan awal tahun, sedangkan 
curah  hujan  rendah  atau  sedang  terjadi  di  pertengahan  tahun. 
Hal  ini  menunjukkan  bahwa  pola  curah  hujan  di  Majalengka 
adalah bertipe monsunal, di mana memiliki satu puncak pada 
periode November – Maret dan satu palung pada periode Mei – 
September. Secara umum, curah hujan saat musim hujan lebih 
berfluktuatif  dibandingkan  saat  musim  kemarau.  Dari 
tangkapan Stasiun Meteorologi Kertajati, rata-rata curah hujan 
dasarian yang terjadi adalah 76,12 mm. Curah hujan dasarian 
terendah  pada  nilai  0  mm,  yang  berarti  tidak  terjadi  hujan 
selama  10  hari.  Sementara  itu,  total  curah  hujan  dasarian 
tertinggi terjadi pada dasarian pertama bulan April tahun 2011, 
yaitu  mencapai  432,7  mm  yang  menunjukkan  bahwa  pada 
periode dasarian tersebut, terjadi hujan yang ekstrem.  

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Gambar 4. Curah hujan dasarian di Stasiun Meteorologi Kertajati periode 
Januari 1978 hingga Desember 2022 

C.  Pembangunan Model untuk Memprediksi Curah Hujan 

Dasarian 
Pada metode SVR, peneliti telah menggunakan fungsi RBF 
sebagai fungsi kernel SVR untuk model prediksi curah hujan 
dasarian. Fungsi RBF dinilai memiliki kinerja yang lebih baik 
dibandingkan  fungsi  kernel  yang  lain  [9,  19].  Untuk  metode 
XGBoost,  beberapa  hyperparameter  yang  memiliki  efek 
signifikan  terhadap  performa  model  prediksi  adalah  learning 
rate,  subsample,  max  leaves,  max  depth,  gamma,  colsample 
bytree,  dan  min  child  weight  [29].  Sementara  untuk  model 
MLP, digunakan hidden layers sebanyak tiga lapisan. Jumlah 
hidden layers ini dipilih dari hasil trial and error oleh peneliti. 
Sementara  pada  pembangunan  arsitektur  model  LSTM, 
penelitian ini menggunakan beberapa layers, yaitu tiga hidden 
layers LSTM, layer dropout yang digunakan untuk mencegah 
terjadinya  overfitting,  dan  satu  layer  dense  yang  digunakan 
sebagai output dari model LSTM. Jumlah hidden layers LSTM 
tersebut  juga  dipilih  sebagai  hasil  dari  trial  and  error  yang 
dilakukan  oleh  peneliti.  Selain  itu,  beberapa  parameter  lain 
yang  ditentukan  di  awal  oleh  peneliti  untuk  model  LSTM 
antara lain fungsi ReLu sebagai fungsi aktivasi model LSTM 
dan ukuran  epoch yang  digunakan  adalah  sebanyak  75.  Nilai 
epoch ini dipilih karena performa model dapat menurun ketika 
menggunakan  epoch  yang  lebih  besar  [15].  Fungsi  aktivasi 
ReLu  digunakan  karena  dapat  mengungguli  fungsi  aktivasi 
tanh dan sigmoid [30]. Pada model LSTM, ditambahkan pula 
fungsi  Early Stopping untuk mencegah terjadinya  overfitting. 
Pada  penelitian  ini,  peneliti  menggunakan  jumlah  time  steps 
sebanyak 3. 

algoritma  grid 

Sebelum  melakukan  pemodelan,  peneliti  menentukan 
beberapa  hyperparameter  untuk  dilakukan  simulasi  dengan 
search  dan  divalidasi 
menggunakan 
menggunakan  expanding  window  cross-validation.  Grid 
search  bekerja  mencari  kombinasi  hyperparameter  terbaik 
secara  iteratif.  Adapun  hyperparameter  yang  ditentukan  oleh 
peneliti dapat dilihat pada Tabel II.  
TABEL II 
NILAI HYPERPARAMETER 

Model 
SVR 

Hyperparameter 

C: {1, 10, 100, 1000, 2000} 
Epsilon: {0,00001, 0,0001, 0,001, 0,01} 
Gamma: {0.00001, 0.0001, 0.001, 0,01} 

XGBoost  Max depth: {10, 20, 30} 

Max leaves: {50, 100} 
Min child weight: {5, 10, 15} 
Colsample bytree: {0,8, 1} 
Learning rate: {0,01, 0,1} 
Gamma: {0,1 , 0,2} 
Subsample: {0,6, 0,8} 

 5 / 8 

 
 
 
MLP 

LSTM 

Hidden layers: {(16,16,16), (32,32,32), (64,64,64), 
(128,128,128)} 
Batch size: {16, 32, 64} 
Alpha: {0,0001, 0,001, 0,01, 0,1} 
Learning rate init: {0,0001, 0,001, 0,01, 0,1} 
LSTM units: {16, 32, 64, 128} 
Dropout rate: {0,1, 0,2} 
Learning rate: {0,0001, 0,001, 0,01, 0,1} 
Batch size: {16, 32, 64} 

Setelah  penentuan  hyperparameter,  langkah  selanjutnya 
adalah  melakukan  pelatihan  model  menggunakan  data  latih. 
Dari  beberapa  hyperparameter  tersebut,  diperoleh  jumlah 
model  yang  terbentuk  dari  masing-masing  metode,  yaitu 400 
model SVR, 1440 model XGBoost, 960 model MLP, dan 480 
model LSTM. Jumlah model tersebut diperoleh dari banyaknya 
kombinasi  hyperparameter  masing-masing  metode  dikalikan 
dengan  5,  yaitu  banyaknya  k  dari  cross-validation  yang 
digunakan.    Dari  hasil  simulasi  hyperparameter,  diperoleh 
kombinasi terbaik untuk setiap metode yang ditunjukkan pada 
Tabel III.   

Model 
SVR 

XGBoost 

MLP 

LSTM 

TABEL III 
HASIL SIMULASI HYPERPARAMETER 

Kombinasi Hyperparameter Terbaik 

C: 2000 
Epsilon: 0,01 
Gamma: 0,01 
Max depth: 10 
Max leaves: 50 
Min child weight: 15 
Colsample bytree: 0,8 
Learning rate: 0,1 
Gamma: 0,2 
Subsample: 0,6 
Hidden layers: (128,128,128) 
Batch size: 64 
Alpha: 0,01 
Learning rate init: 0,001 
LSTM units: 64 
Dropout rate: 0,2 
Learning rate: 0,001 
Batch size: 32 

D.  Evaluasi Kinerja Model dan Pemilihan Model Terbaik 

Setelah  membangun  model  prediksi,  langkah  selanjutnya 
adalah  menguji  model  prediksi  yang  telah  dibangun.  Model 
tersebut  digunakan  untuk  memprediksi  curah  hujan  dasarian 
menggunakan data uji kemudian dievaluasi kinerjanya. Selain 
itu,  kinerja  model  pada  saat  menggunakan  data 
latih 
dibandingkan  dengan  kinerja  pengujian  untuk  memeriksa 
apakah model yang telah dibangun terjebak dalam overfitting. 
Evaluasi kinerja menggunakan tiga ukuran, yaitu MAE, RMSE 
dan 𝑅2.  

Pada  Tabel  IV,  ditunjukkan  hasil  evaluasi  masing-masing 
model  prediksi  menggunakan  data  latih  dan  data  uji.  Dapat 
dilihat bahwa hasil kinerja antara pelatihan dan pengujian dari 
masing-masing  model  tidak  jauh  berbeda  nilainya.  Hal  ini 
menandakan  bahwa  tidak  terdapat  indikasi  overfitting  pada 
model prediksi yang telah dibangun. 

Berdasarkan Tabel IV, kinerja dari keempat model prediksi 
terlihat tidak berbeda jauh. Jika dilihat dari kinerja pelatihan, 
model  XGBoost  memiliki  nilai  RMSE  terendah  dan  𝑅2 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

tertinggi,  yaitu  sebesar  51,906  dan  0,603,  sedangkan  MAE 
terkecil  dimiliki  oleh  model  LSTM,  yaitu  sebesar  36,01. 
Sementara  itu,  pada  kinerja  pengujian  terlihat  bahwa  LSTM 
memiliki  kinerja  yang  terbaik  dengan  nilai  MAE  dan  RMSE 
yang terkecil serta 𝑅2 yang terbesar, yaitu secara berturut-turut 
sebesar  35,547,  54,590,  dan  0,557.  Oleh  karena  itu,  model 
LSTM  dapat  dikatakan  sebagai  model  yang  terbaik.  Hal 
tersebut selaras dengan penelitian Endalie, Haile, dan Taye [10] 
yang  mengatakan  bahwa  kinerja  LSTM  dapat  mengungguli 
kinerja  model  regresi  machine  learning  dalam  memprediksi 
curah hujan.   

TABEL IV 
HASIL EVALUASI MODEL PREDIKSI 

Model 

SVR 
XGBoost 
MLP 
LSTM 

Model 

SVR 
XGBoost 
MLP 
LSTM 

MAE 
38,174 
36,399 
39,040 
36,010 

MAE 
38,409 
37,071 
36,990 
35,547 

Pelatihan 
RMSE 
57,893 
51,906 
55,342 
53,390 
Pengujian 
RMSE 
57,158 
55,465 
55,233 
54,590 

𝑅2 
0,506 
0,603 
0,549 
0,580 

𝑅2 
0,514 
0,543 
0,546 
0,557 

Meskipun untuk dataset yang kecil, machine learning lebih 
cocok  dibandingkan  dengan  deep  learning,  pada  studi  kasus 
penelitian  ini  model  deep  learning  menunjukkan  dapat 
memberikan  kinerja  yang  sama,  atau  bahkan  lebih  baik, 
daripada model machine learning. Pada Gambar 5, ditunjukkan 
grafik  garis  yang  membandingkan  data  aktual  dengan  hasil 
prediksi  model  SVR,  XGBoost,  MLP,  dan  LSTM.  Secara 
keseluruhan  dapat  dilihat  bahwa  keempat  model  sudah  dapat 
mengikuti pola curah hujan dasarian aktual, tetapi hasil prediksi 
LSTM  terlihat  lebih  baik  dan  sesuai  dibandingkan  dengan 
ketiga model lainnya. Model LSTM dapat memprediksi curah 
hujan dasarian yang bernilai 0 dengan baik, sedangkan model 
SVR  dan  MLP  masih  terdapat  hasil  prediksi  curah  hujan 
dasarian  yang  bernilai  negatif.  Model  XGBoost  juga  masih 
belum bisa memprediksi curah hujan dasarian yang bernilai 0 
dengan baik, terlihat dari grafik data prediksinya yang berada 
di atas data aktualnya. 

Gambar 5. Line chart hasil prediksi SVR, XGBoost, MLP, dan LSTM 

 6 / 8 

 
 
 
VII. 

PENUTUP 

Berdasarkan  hasil  penelitian  yang  telah  dilakukan,  maka 

diperoleh beberapa kesimpulan sebagai berikut. 

1.  Curah  hujan  dasarian  yang  ditangkap  oleh  Stasiun 
Meteorologi Kertajati bertipe monsunal, yang ditandai 
dengan  satu  puncak  pada  periode  November  –  Maret 
dan satu palung pada periode Mei – September sehingga 
terlihat  perbedaan  yang  jelas  antara  musim  hujan  dan 
musim kemarau di Majalengka. Curah hujan saat musim 
hujan  lebih  berfluktuatif  dibandingkan  saat  musim 
kemarau. 

curah 

2.  Penelitian ini telah menerapkan metode SVR, XGBoost, 
MLP,  dan  LSTM  dalam  membangun  model  untuk 
memprediksi 
dengan 
menggunakan algoritma grid search. Berdasakan hasil 
evaluasi kinerja model menggunakan data latih dan data 
uji, model prediksi yang telah dibangun dapat dikatakan 
fit.  Hasil  kinerja  dari  keempat  model  terlihat  tidak 
berbeda jauh. 

dasarian 

hujan 

3.  Dari hasil kinerja pengujian dan visualisasi grafik garis, 
model  prediksi  LSTM  dipilih  sebagai  model  terbaik 
dalam  memprediksi  curah  hujan  dasarian  di  Stasiun 
Meteorologi  Kertajati,  dengan  nilai  MAE  sebesar 
35,547, RMSE sebesar 54,590, dan 𝑅2 sebesar 0,557. 
Beberapa  saran  yang  dapat  diberikan  oleh  peneliti  adalah 

sebagai berikut. 

1.  Batasan  penelitian  ini  hanya  menggunakan  data  dari 
satu  stasiun  meteorologi  di  Jawa  Barat,  yaitu  Stasiun 
Meteorologi  Kertajati  sehingga  penelitian  selanjutnya 
dapat  memperluas  batasan  penelitian  prediksi  curah 
hujan dasarian untuk wilayah Provinsi Jawa Barat. 
2.  Penelitian ini hanya menggunakan empat variabel cuaca 
dalam  memprediksi  curah  hujan  dasarian,  yaitu  suhu 
rata-rata,  kelembaban  udara 
lamanya 
penyinaran  matahari,  dan  kecepatan  angin  rata-rata. 
Untuk  penelitian  selanjutnya,  dapat  menggunakan 
variabel  lain  sebagai  variabel  prediktor,  seperti  suhu 
permukaaan  laut,  jumlah  tutupan  awan,  dan  indeks 
iklim. 

rata-rata, 

3.  Penelitian  selanjutnya  dapat  menggunakan  metode 
simulasi  hyperparameter  yang  lain,  seperti  bayesian 
optimization  atau  random  search,  serta  menggunakan 
kombinasi hyperparameter yang lebih banyak. 

4.  Penelitian  selanjutnya  dapat  menggunakan  algoritma 
machine  learning  dan  deep  learning  yang  lain  untuk 
memprediksi curah hujan dasarian sehingga diharapkan 
dapat menemukan model prediksi yang lebih baik. 

DAFTAR PUSTAKA  

[1]   E. Aldrian, M. Karmini dan Budiman, Adaptasi dan Mitigasi Perubahan 
Iklim di Indonesia, Jakarta: Pusat Perubahan Iklim dan Kualitas Udara, 
Kedeputian Bidang Klimatologi, Badan Meteorologi, Klimatologi, dan 
Geofisika, 2011.  

[2]   G. Nuraisah dan R. A. B. Kusumo, “DAMPAK PERUBAHAN IKLIM 
PADI  DI  DESA  WANGUK 
TERHADAP  USAHATANI 
KECAMATAN  ANJATAN  KABUPATEN  INDRAMAYU,”  Mimbar 
Agribisnis:  Jurnal  Pemikiran  Masyarakat 
Ilmiah  Berwawasan 
Agribisnis, vol. 5, no. 1, pp. 60-71, 2019.  

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

[3]   Badan Pusat Statistik, Luas Panen dan Produksi Padi di Indonesia 2021, 

Jakarta: Badan Pusat Statistik, 2022.  

[4]   Y.  S.  Swarinoto  dan  Sugiyono,  “Pemanfaatan  Suhu  Udara  dan 
Kelembapan Udara dalam Persamaan Regresi untuk Simulasi Prediksi 
Total  Hujan  Bulanan  di  Bandar  Lampung,”  Jurnal  Meteorologi  dan 
Geofisika, vol. 12, no. 3, pp. 271-281, 2011.  

[5]   B.  Praveen,  S.  Talukdar,  S.  Mahato,  J.  Mondal,  P.  Sharma,  A.  R.  M. 
Islam  dan  A.  Rahman,  “Analyzing  trend  and  forecasting  of  rainfall 
changes  in  India  using  non-parametrical  and  machine  learning 
approaches,” Scientific Reports, vol. 10, no. 1, pp. 1-21, 2020.  

[6]   C. Hu, Q. Wu, H. Li, S. Jian, N. Li dan Z. Lou, “Deep Learning with a 
Long  Short-Term  Memory  Networks  Approach  for  Rainfall-Runoff 
Simulation,” Water, vol. 10, no. 11, p. 1543, 2018.  

[7]   C. M. Liyew dan H. A. Melese, “Machine learning techniques to predict 
daily rainfall amount,” Journal of Big Data, vol. 8, no. 1, pp. 1-11, 2021.  

[8]   X.  Zhang,  S.  N.  Mohanty,  A.  K.  Parida,  S.  K.  Pani,  B.  Dong  och  X. 
Cheng, ”Annual and Non-Monsoon Rainfall Prediction Modelling Using 
SVR-MLP: An Empirical Study From Odisha,” IEEE Access, vol. 8, pp. 
30223-30233, 2020.  

[9]   J.  Gu,  S.  Liu,  Z.  Zhou,  S.  R.  Chalov  dan  Q.  Zhuang,  “A  Stacking 
Ensemble Learning Model for Monthly Rainfall Prediction in the Taihu 
Basin, China,” Water, vol. 14, no. 3, p. 492, 2022.  

[10]  D.  Endalie,  G.  Haile  dan  W.  Taye,  “Deep  learning  model  for  daily 
rainfall prediction: case study of Jimma, Ethiopia,” Water Supply, vol. 
22, no. 3, pp. 3448-3461, 2022.  

[11]  Y. LeCun, Y. Bengio dan G. Hinton, “Deep learning,” Nature, vol. 521, 

no. 7553, pp. 436-444, 2015.  

[12]  Y. Xin, L. Kong, Z. Liu, Y. Chen, Y. Li, H. Zhu, M. Gao, H. Hou dan C. 
Wang,  “Machine  Learning  and  Deep  Learning  Methods 
for 
Cybersecurity,” IEEE Access, vol. 6, pp. 35365-35381, 2018.  

[13]  M. T. Anwar, E. Winarno, W. Hadikurniawati och M. Novita, ”Rainfall 
prediction  using  Extreme  Gradient  Boosting,”  Journal  of  Physics: 
Conference Series, vol. 1869, nr 1, p. 12078, 2021.  

[14]  S. Aswin , P. Geetha dan R. Vinayakumar, “Deep Learning Models for 
the  Prediction  of  Rainfall,”  2018  International  Conference  on 
Communication and Signal Processing (ICCSP), IEEE (2018), pp. 657-
661, 2018.  

[15]  N. M. M. C. Devi, I. P. A. Bayupati dan N. K. A. Wirdiani, “Prediksi 
Curah Hujan Dasarian dengan Metode Vanilla RNN dan LSTM untuk 
Menentukan Awal Musim Hujan dan Kemarau,” JEPIN (Jurnal Edukasi 
dan Penelitian Informatika), vol. 8, no. 3, pp. 405-411, 2022.  

[16]  J. N. Wulff dan L. Ejlskov, “Multiple Imputation by Chained Equations 
in Praxis: Guidelines and Review,” The Electronic Journal of Business 
Research Methods, vol. 15, no. 1, pp. 41-56, 2017.  

[17]  F.  Zhang  dan  L.  J.  O'Donnell,  “Support  vector  regression,”  dalam 

Machine Learning, Academic Press, 2020, pp. 123-140. 

[18]  M.  Awad  dan  R.  Khanna,  Efficient  Learning  Machines,  Berkeley: 

Apress, 2015.  

[19]  J. Fan, X. Wang, L. Wu, H. Zhou, F. Zhang, X. Yu, X. Lu dan Y. Xiang, 
“Comparison  of  Support  Vector  Machine  and  Extreme  Gradient 
Boosting  for  predicting  daily  global  solar  radiation  using  temperature 
and precipitation in humid subtropical climates: A case study in China,” 
Energy conversion and management, vol. 164, pp. 102-111, 2018.  

[20]  X. Zhang, C. Yan, C. Gao, B. A. Malin dan Y. Chen, “Predicting Missing 
Values  in  Medical  Data  Via  XGBoost  Regression,”  Journal  of 
Healthcare Informatics Research, no. 4, p. 383–394, 2020.  

[21]  H.  Ramchoun,  Y.  Ghanou,  M.  Ettaouil  dan  M.  A.  Janati  Idrissi, 
“Multilayer  Perceptron:  Architecture  Optimization  and  Training,” 
International  Journal  of 
Interactive  Multimedia  and  Artificial 
Intelligence, vol. 4, no. 1, pp. 26-30, 2016.  

[22]  M.  W.  Gardner  dan  S.  R.  Dorling,  “Artificial  neural  networks  (the 
multilayer  perceptron)—a  review  of  applications  in  the  atmospheric 
sciences,” Atmospheric Environment, vol. 32, no. 14-15, pp. 2627-2636, 
1998.  

 7 / 8 

 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

[23]  H. Taud dan J. F. Mas, “Multilayer Perceptron (MLP),” dalam Geomatic 
Approaches  for  Modeling  Land  Change  Scenarios,  Springer,  Cham, 
2018, pp. 451-455. 

[24]  S. Hochreiter dan J. Schmidhuber, “Long Short-Term Memory,” Neural 

Computation, vol. 9, no. 8, pp. 1735-1780, 1997.  

[25]  Y.  Yu,  X.  Si,  C.  Hu  dan  J.  Zhang,  “A  Review  of  Recurrent  Neural 
Networks:  LSTM  Cells  and  Network  Architectures,”  Neural 
Computation, vol. 31, no. 7, pp. 1235-1270, 2019.  

[26]  K. C. Miao, T. T. Han, Y. Q. Yao, H. Lu, P. Chen, B. Wang dan J. Zhang, 
“Application  of  LSTM  for  short  term  fog  forecasting  based  on 
meteorological  elements,”  Neurocomputing,  vol.  408,  pp.  285-291, 
2020.  

[27]  A.  Graves,  “Long  Short-Term  Memory,”  dalam  Supervised  Sequence 
Labelling with Recurrent Neural Networks, Berlin, Springer, 2012, pp. 
37-45. 

[28]  K. Seu, M. S. Kang dan H. Lee, “An Intelligent Missing Data Imputation 
Techniques:  A  Review,”  JOIV:  International  Journal  on  Informatics 
Visualization, vol. 6, no. 1-2, pp. 278-283, 2022.  

[29]  Y. Wang dan X. S. Ni, “A XGBOOST RISK MODEL VIA FEATURE 
HYPER-PARAMETER 

SELECTION 
OPTIMIZATION,” arXiv preprint arXiv:1901.08433, 2019.  

BAYESIAN 

AND 

[30]  C.  Krittanawong,  H.  U.  H.  Virk,  A.  Kumar,  M.  W.  Z.  Aydar,  M.  P. 
Stewart  dan  J.  L.  Halperin,  “Machine  learning  and  deep  learning  to 
predict  mortality 
in  patients  with  spontaneous  coronary  artery 
dissection,” Scientific reports, vol. 11, no. 1, pp. 1-10, 2021.  

 8 / 8 

 
 
 
 
 
","2023-12-19T08:47:25.487071Z",221910721,"[{""start"":1383,""end"":1474,""text"":"""",""labels"":[""Temuan""]},{""start"":33891,""end"":34108,""text"":"""",""labels"":[""Temuan""]},{""start"":601,""end"":873,""text"":""penerapan metode machine\\nlearning dan deep learning, yaitu Support Vector Regression\\n(SVR), Extreme Gradient Boosting (XGBoost), Multilayer\\nPerceptron (MLP), dan Long Short-Term Memory (LSTM),\\ndalam memprediksi curah hujan dasarian (sepuluh harian)"",""labels"":[""Tujuan""]},{""start"":601,""end"":815,""text"":""penerapan metode machine\\nlearning dan deep learning, yaitu Support Vector Regression\\n(SVR), Extreme Gradient Boosting (XGBoost), Multilayer\\nPerceptron (MLP), dan Long Short-Term Memory (LSTM)"",""labels"":[""Metode""]}]",792.476,"2023-12-19T09:47:23.485679Z"
8,"1","Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

Identifikasi Area Prioritas Implementasi Urban 
Green Infrastructure Berdasarkan Ecosystem 
Services Demand Menggunakan Remote Sensing 
Studi Kasus : DKI Jakarta 

Muhamad Al Hafidz Sani (221910726, 4SD1) 
Dosen Pembimbing: Robert Kurniawan, SST, M.Si 

Ringkasan— Besarnya Ecosystem services demand menjadikan 
penurunan  kualitas  lingkungan  di  perkotaan  seperti  Jakarta. 
Penurunan ini ditandai oleh berbagai fenomena bencana seperti 
polusi  udara,  panas  perkotaan,  emisi  karbon,  banjir  dan 
persebaran  bangunan  yang  tidak  terstruktur  yang  memberikan 
risiko pada perkotaan padat dan rentan terhadap anak-anak serta 
lansia.  Sehingga, penelitian in mencoba mengidentifikasi wilayah 
prioritas di Jakarta berdasarkan ecosystem services demand yang 
didekati  penilaian  risiko  bencana.  Metode  digunakan  untuk 
melakukan identifikasi area prioritas adalah menggunakan Fuzzy 
Possibilistic  Partion  Product  C-Means  (FPPPCM).  Sumber  data 
yang  digunakan  berasal  dari  remote  sensing  seperti  NO2,  land 
surface temperature (LST), CO, dan NDWI menyesuaikan 4 jenis 
ecosystem 
juga 
services  yang  difokuskan.  Penelitian 
menggunakan  data  dari  official  statistics  dan  big  data  untuk 
menghitung kepadatan penduduk serta proporsi anak-anak dan 
lansia.  Hasil  penelitian  menunjukkan  bahwa  terdapat  13 
kecamatan  di  Jakarta  dari  42  kecamatan  yang  teridentifikasi 
wilayah risiko bencana dan memiliki permintaan tinggi terhadap 
ini  dapat  berkontribusi  untuk 
ecosystem  services.  Hasil 
services  melalui 
pengoptimalan 
implementasi urban green infrastructure. 

pengelolaan 

ecosystem 

ini 

Kata  Kunci—  ecosystem  services,  risiko  bencana,  FPPPCM, 

urban green infrastructure, remote sensing. 

I.  LATAR BELAKANG  

Kota  Jakarta  merupakan 

ibukota  di  Indonesia  yang 
mengalami proses urbanisasi yang cepat [1]. Di Jakarta, selalu 
terjadi  kemacetan  setiap  harinya  dan  memberikan  kontribusi 
yang  signifikan  terhadap  peningkatan  polutan  dan  konsumsi 
energi  [2].  Kemacetan  menjadi  penyumbang  yang  besar 
terhadap polusi udara seperti NO2, CO, O3, Particular Matter 
dan  dapat  menjadi  penyebab  masalah  kesehatan  seperti 
penyakit  pernapasan,  kardiovaskular,  kanker  paru-paru  dan 
penyakit  lainnya  yang  terkait  polutan  ini  [3],[4].  Buruknya 
kualitas  udara  di  Jakarta  menandakan  tingginya  permintaan 
terkait  kualitas  udara  dan 
terhadap 
minimnya suplai layanan ekosistem terkait kualitas udara [5]. 
Peningkatan populasi di Jakarta mendorong perubahan lahan 
dari  ruang  terbuka  hijau  serta  badan  air  menjadi  kawasan 
perkotaan  yang  mengakibatkan  hilangnya  ecosystem  services  
[1]. Tingginya tingkat migrasi di Jakarta berimplikasi terhadap 
perpindahan 
lahan  dan  deforestasi  yang  mengakibatkan 
pengurangan  tingkat  vegetasi  [6],[7].  Permasalahan  lain  di 
Jakarta  yaitu  banjir  yang  sering  terjadi  ketika  musim  hujan. 

layanan  ekosistem 

Sering kali tingginya curah hujan dan minimnya daerah resapan 
air  menyebabkan  air  hujan  tertahan  di  permukaan  tanah  [8]. 
Ketahanan  air  di  Jakarta  dipengaruhi  oleh  infrastruktur  yang 
tidak memadai seperti layanan hidrologi (hydrological services) 
serta tata kelola yang buruk [9]. 

Berdasarkan permasalahan diatas,  penting untuk dilakukan 
penilaian tingkat permintaan dari layanan ekosistem di Jakarta. 
Pendekatan melalui layanan ekosistem memberikan cara yang 
efisien  dalam  mendukung  perencanaan  urban  green 
infrastructure  [10].  Perencanaan  urban  green  infrastructure 
sangat  penting  untuk  meminimkan  risiko  bencana  dan 
memulihkan  ekosistem  alami  yang  menyediakan  serangkaian 
layanan ekosistem serta kesejahteraan manusia [11]. 

Penilaian  ecosystem  services  demand  dilakukan  melalui 
penedekatan  penilaian  risiko  bencana.  Hasil  penilaian  risiko 
dapat  digunakan  untuk  pengambilan  keputusan  untuk 
memprioritaskan ecosystem services mana yang paling rentan 
[12]. Penilaian risiko bencana (disaster risk assessment) dapat 
hazard-exposure-
dihitung  menggunakan 
vulnerability yang diterbitkan oleh Intergovernmental Panel on 
Climate Change (IPCC) [13]. Empat jenis ecosystem services 
akan  ditinjau  untuk  penilaian  ecosystem  services  demand 
berdasarkan  penedekatan  IPCC  disaster  risk  assessment.  Di 
antaranya  adalah  pemurnian udara  (air  purification),  regulasi 
panas 
(CO 
sequestration) dan regulasi banjir (flood regulation). 

regulation),  penyimpanan  karbon 

pendekatan 

(heat 

Penilaian ecosystem service demand yang didekati disaster 
risk assessment dapat dilakukan melalui remote sensing [14]. 
Layanan  pemurnian  udara  (air  purification)  dihitung  dari 
banyaknya  konsentrasi  NO2,  layanan  regulasi  panas  (heat 
regulation)  diukur  dari  temperatur  permukaan  (land  surface 
temperature), layanan penyerapan karbon (CO sequestration) 
diukur dari banyaknya karbon monoksida dan layanan regulasi 
banjir  diukur  dari  banyaknya  indeks  air  di  suatu  wilayah 
dengan  pendekatan  Normalized  Difference  Water  Index 
(NDWI) [5]. 

Berikutnya,  untuk  mengidentifikasi  area  prioritas  untuk 
implementasi  urban  green  infrastructure  dapat  dilakukan 
dengan  metode 
kami 
mengimplementasikan Fuzzy Possibilistic Product Partition C-
Means  (FPPPCM)  yang  mampu  melakukan  pengelompokkan 
secara geospasial [16]. Selain itu, dalam menilai risiko bencana 
sebagai  kepadatan 
juga  mempertimbangkan 

clustering 

Sehingga, 

exposure 

[15]. 

 1 / 7 

 
 
 
 
 
penduduk  dan  vulnerability  sebagai  proporsi  orang  tua  dan 
anak [5], [17]. 

Berdasarkan  latar  belakang  masalah  yang  disebutkan, 
penelitian  ini  mencoba  melakukan  identifikasi  area  prioritas 
yang  perlu  diimplementasikan  urban  green  infrastructure 
berdasarkan ecosystem services demand pada skala lingkungan 
perkotaan  di  Kota  Jakarta.  Pada  saat  yang  sama,  metode 
penilaian  berdasarkan  ecosystem  services  demand  ini  dapat 
memberikan referensi untuk perencanaan green infrastructure 
di kota lain dengan permasalahan yang sejenis. Pada penelitian 
ini,  kami  mengambil  seluruh  area  Kota  Jakarta  kecuali 
Kepulauan Seribu sebagai area penelitian dan memilih layanan 
ekosistem  yang  mendeskripsikan  permasalahan  di  Jakarta. 
Terakhir,  perbedaan  penelitian  ini  dibandingkan  penelitian 
yang 
teknik  FPPPCM  dalam 
mengidentifikasi  area  prioritas,  dimana  FPPPCM  mampu 
melakukan pengelompokkan secara geospasial. 

lain  adalah  menerapkan 

II.  TUJUAN PENELITIAN 

Tujuan penelitian ini adalah untuk mengidentifikasi area di 
Jakarta  yang  perlu  mengimplementasi  urban  green 
infrastructure  berdasarkan  ecosystem  services  demand. 
Adapun rincian tujuan penelitian ini adalah sebagai berikut.  

1. Memperoleh  variabel-variabel  yang  berkontirubusi 

terhadap risiko bencana secara spasial. 

2. Menentukan  tingkat  ecosystem  services  demand  pada 
setiap  jenis  ecosystem  services  menggunakan  metode 
penilaian  risiko  bencana  hazard-exposure-vulnerability 
secara spasial. 

3. Mengidentifikasi area prioritas menggunakakan metode 
green 

FPPPCM 
infrastructure berdasarkan ecosystem services demand. 

implementasi 

urban 

untuk 

III. PENELITIAN TERKAIT 

Gambar 1. Peta Literatur 

Kami  mengambil  beberapa  penelitian  yang  terkait  sebagai 
rujukan  dan  dasar  pada  penelitian  ini.  Pada  Gambar  1,  studi 
literatur yang kami lakukan berdasarkan beberapa konsep serta 

Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

keterkaitannya  antara  ecosystem  services,  disaster  risk 
assessment,  urban  green  infrastructure,  remote  sensing  dan 
clustering  FPPPCM.  Berangkat  dari  penilaian  kebutuhan 
urban green infrastructure, Merve Ersoy (2022) menerangkan 
bahwa  ada  keterkaitan  antara  urban  green  infrastructure  dan 
ecosystem  services.  Merve  menjelaskan  bahwa  Urban  green 
infrastructure  dapat  direpresentasikan  melalui  ecosystem 
services. Besarnya permintaan ecosystem services menandakan 
kebutuhan  yang  besar  mengenai  kebijakan  urban  green 
infrastructure di perkotaan. [18] 

Untuk  mengukur  besarnya  permintaan  ecosystem  services, 
penelitian  lain  juga  dilakukan  oleh  Wang  (2022).  Penelitian 
tersebut  mencoba  mengukur  besarnya  ecosystem  services 
demand  melalui  pendekatan  disaster  risk  assessment. 
Penelitian ini menerapkan kerangka kerja IPCC dalam menilai 
besarnya  risiko  bencana,  dimana  besarnya  risiko  bencana 
kemudian  akan  menentukan  besarnya  permintaan  ecosystem 
services  yang  mempertimbangkan  hazard,  vulnerability  dan 
exposure [5]. 

Dalam mendapatkan besarnya hazard yang akan digunakan 
pada  pengukuran  besarnya  risiko  bencana,  penelitian  Sakti 
(2023)  menghitung  indeks  risiko  bencana  menggunakan 
metode  remote sensing dalam proses perolehan  datanya [19]. 
Hasil  perolehan  data  menggunakan  remote  sensing  dinilai 
sebagai  hazard  seperti  NO2,  LST,  CO  dan  ukuran  lainnya. 
Selain  itu,  penelitian  Jiang  (2028)  menerapkan  metode  IPCC 
framework dan remote sensing untuk mengevaluasi kerentanan 
ekologi pada perubahan iklim [20]. 

Dalam  melakukan  identifikasi  area  prioritas,  Ghost  (2022) 
menggunakan  sebuah  algoritma  clustering  yaitu  FPPPCM. 
Algoritma ini digunakan untuk mengelompokkan suatu kriteria 
tertentu  menjadi  beberapa  kelompok  yang  sudah  ditentukan. 
Ghost  juga  mengatakan  bahwa  algoritma  ini  bisa  digunakan 
untuk pengelompokan secara geospasial [16]. 

IV. METODE PENELITIAN  

1.  Area Studi 

Penelitian  ini  mengambil  area  studi  pada  Provinsi  Jakarta 
tanpa Kabupaten Kepulauan Seribu. Jakarta menjadi pusat kota 
di Indonesia yang tingkat kepadatan penduduknya paling tinggi 
[21]. Provinsi Jakarta, sebagai kota metropolitan memiliki luas 
wilayah  yang  membentang  seluas  4384  km2  dan  memiliki 
tingkat kepadatan penduduk 13,000 orang per km2 [22]. Jakarta 
berdasarkan geografis, terletak di antara 6° 12′ Lintang Selatan 
dan 106° 48′ Bujur Timur [23]. Provinsi Jakarta memiliki lima 
kota  adminstratif  yaitu  Jakarta  Timur,  Jakarta  Barat,  Jakarta 
Pusat, Jakarta Utara dan Jakarta Selatan [24]. Kondisi geografi 
Jakarta  dan 
juga  sebagai  pusat  ekonomi  di  Indonesia 
menjadikan  Jakarta  sebagai  kota  yang  cukup  rentan  terhadap 
bencana-bencana  seperti  banjir  dan  udara  yang  tidak  sehat 
[25,26].  

 2 / 7 

 
 
 
 
 
 
 
 
 
Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

𝑐

𝑛

𝐽𝐹𝑃𝑃𝑃𝐶𝑀 = ∑ ∑ 𝑢𝑖𝑘

𝑚[𝑡𝑖𝑘

𝑝 𝑑𝑖𝑘

2 + (1 − 𝑡𝑖𝑘)𝑝𝜂𝑖

]

(2) 

𝑖=1

𝑘=1

Parameter dari FPPPCM diantaranya adalah eksponen fuzzy 
𝑚 > 1, ekponen possibilistik 𝑝 > 1, dan penalti possibilistik 𝜂, 
𝑖 = 1 … 𝑐 . Partisi probabilistik mirip dengan partisi  Fuzzy C-
Means  (FCM),  tetapi  jarak  terdistorsi  dan partisi  dipengaruhi 
oleh penalti possibilistik 𝜂𝑖. Dengan bantuan pengali lagrange, 
nilai 𝑡𝑖𝑘 dan 𝑢𝑖𝑘 dapat dihitung sebagai berikut. 

∗ = [1 + (
𝑡𝑖𝑘

=1

1
𝑝−1

]

2
𝑑𝑖𝑘
𝜂𝑖

)

𝑝 𝑑𝑖𝑘

[𝑡𝑖𝑘

2 + 𝜂𝑖(1 − 𝑡𝑖𝑘)𝑝]

−

1
𝑚−1

𝑐
∑ [𝑡𝑖𝑘
𝑗=1

𝑝 𝑑𝑖𝑘

2 + 𝜂𝑖(1 − 𝑡𝑖𝑘)𝑝]

−

1
𝑚−1

∗ =

𝑣⃗𝑖

∑

𝑛
𝑘=1
𝑛
∑
𝑘=1

𝑝
𝑚𝑡𝑖𝑘
𝑥⃗𝑘
𝑢𝑖𝑘
𝑝
𝑚𝑡𝑖𝑘
𝑢𝑖𝑘

(3) 

(4) 

(5) 

5.  Cluster Validation 
Permasalahan umum pada beberapa algoritma klaster seperti 
fuzzy  c-means  dan  FPPPCM  adalah  perlu  menentukan 
banyaknya klaster 𝑘 yang akan dibentuk berdasarkan data yang 
dianalisis  [37].  Sehingga,  untuk  mendapatkan  banyaknya 
klaster  yang  paling  optimum  dapat  melalui  performance 
evaluation  pada  metode  clustering  [38].  Pada  penelitian  ini, 
kami  mengajukan 
indeks  validasi  yaitu  Partition 
Coefficient (PC), Partition Entropy (PE), Silhouette Index (SI), 
Fuzzy Silhouette Index (FSI) dan Modified Partition Coefficient 
(MPC) untuk melakukan performance evaluation pada model 
FGWC pada klaster 2,3,4 dan 5 [39-42]. 

lima 

V.  KERANGKA PIKIR 

Penelitian ini berangkat dari masalah lingkungan di Jakarta. 
Permasalahan  lingkungan  di  Jakarta  seperti  tingginya  polusi 
udara, suhu panas serta banjir mendeskripsikan besarnya risiko 
bencana. Selain itu, tingginya permintaan terhadap ecosystem 
services  menambah  permasalahan  lingkungan  di  Jakarta. 
Berikutnya,  peneliti 
ingin  mengetahui  daerah  yang 
diprioritaskan untuk implementasi  urban green infrastructure 
menggunakan  metode  clustering.  Pertama,  dataset  perlu 
dikumpulkan dari berbagai sumber seperti remote sensing, BPS 
dan Meta High Resolution Population Density. Kedua, indeks 
risiko  bencana  dihitung  menggunakan  IPCC 
framework 
“hazard-exposure-vulnerability”.  Ketiga,  menggunakan 
FPPPCM,  dihasilkan  identifikasi  area  prioritas  berdasarkan 
ecosystem  services  demand  didekati  indeks  risiko  bencana 
untuk  implementasi  urban  green  infrastructure.  Kemudian 
hasil  clustering  menggunakan  FPPPCM  digunakan  untuk 
melakukan analisis autokorelasi spasial  untuk melihat apakah 
terdapat  hubungan  spasial  dengan  hasil  pengelompokan 
ecosystem services demand.  

 3 / 7 

Gambar 2. Area Studi Provinsi Jakarta per Kecamatan 

∗ =

𝑢𝑖𝑘

2.  Sumber Data 
Sumber  data  penelitian  ini  menggunakan  sumber  data 
sekunder,  yatu  penggunaan  remote  sensing,  publikasi  Badan 
Pusat  Statistik  (BPS)  dan  Meta  High  Resolution  Population 
Density. Remote sensing mengumpulkan data konsentrasi NO2, 
CO  menggunakan  citra  Sentinel-5P  [27,28],  land  surface 
temperature (LST) dalam celsius menggunakan citra MODIS 
[29] dan NDWI menggunakan citra Sentinel-2 [30].  

Selanjutnya,  publikasi  Badan  Pusat  Statistik  digunakan 
mengambil data jumlah populasi dan kepadatan penduduk per 
kecamatan di Jakarta tahun 2020 [31]. Meta High Resolution 
Population Density yang merupakan big data digunakan untuk 
menghitung  besarnya  proporsi  anak-anak  dan  lansia  per 
kecamatan di Jakarta tahun 2020 [32]. 

dampak 

3.  Disaster Risk Assessment 
Untuk mengukur risiko suatu bencana, banyaknya frekuensi 
dan 
sepenuhnya 
menggambarkan  besarnya  kerusakan  bencana  (hazard,  H). 
Sehingga  tingkat  keterpaparan  (exposure,  E)  dan  tingkat 
kerentanan  (vulnerability,  V)  juga  perlu  dipertimbangkan 
secara bersamaan [33]. 

biasanya 

kejadian 

tidak 

Karena  itu,  dalam  melakukan  perhitungan  risiko  bencana 
(risk,  R),  kami  menggunakan  sebuah  kerangka  kerja  yang 
diajukan  oleh  Intergovernmental  Panel  on  Climate  Change 
(IPCC)  dalam  menilai  risiko  bencana  melalui  pendekatan 
“Hazard-Exposure-Vulnerability”  [34].  Dimana  perhitungan 
risiko bencana diekspresikan dalam persamaan berikut, 

𝑅 = 𝐻  × 𝐸  × 𝑉 

(1) 

Untuk mengukur besarnya ecosystem services demand, kami 
menggunakan  pendekatan  kerangka  kerja  IPCC  “hazard-
exposure-vulnerability”  dalam  menghitung  disaster  risk 
assessment. 

4.  Fuzzy Possibilistic Partion Product C-Means 
Algoritma  Fuzzy  Possibilistic  Product  Partition  C-Means 
(FPPPCM)  akan  mempartisi  vektor  atau  kumpulan  data 
numerik. Algoritma  ini menghilangkan efek pencilan melalui 
kombinasi  perkalian  dan  menghasilkan  partisi  berkualitas 
[35,36]. Algioritma FPPPCM digambarkan sebagai berikut. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

Untuk  menilai  risiko  bencana,  besarnya  exposure  dan 
vulnerability  perlu  didapatkan  sesuai  bencana  yang  ingin 
dinilai.  Besarnya  exposure  diukur  menggunakan  kepadatan 
penduduk 
diukur 
menggunakan  proporsi  orang  tua  dan  anak  per  kecamatan. 
Gambar  5  menjelaskan  distribusi  spasial  dari  exposure  dan 
vulnerability di Jakarta. 

vulnerability 

kecamatan 

dan 

per 

Gambar 3. Kerangka Pikir Penelitian 

VI. HASIL DAN PEMBAHASAN 

Dengan  remote  sensing,  data-data  terkait  bahaya  bencana 
atau  hazard  dapat  dikumpulkan  melalui  citra  satelit  seperti 
Sentinel-5P,  MODIS  dan  Sentinel-2.  Hasil  pengambilan  data 
melalui  remote  sensing  ditampilkan  pada  Gambar  4  secara 
distribusi  spasial  per  kecamatan  dengan  jenks  natural  breaks 
untuk membaginya menjadi beberapa level. 

Gambar 5. (a) Kepadatan Penduduk, (b) Proporsi Lansia dan Anak di Jakarta 
per Kecamatan 2020 

risiko 

Dengan 

bencana 

pendekatan 

“hazard-exposure-vulnerability”, 
indeks 
yang 
menggambarkan  seberapa  besar  risiko  dari  suatu  peristiwa. 
Distribusi spasial dari indeks risiko yang dibagi menjadi 5 level 
menggunakan  jenks  natural  breaks  pada  setiap  bencana  di 
Jakarta dijelaskan pada Gambar 6. 

dihasilkan 

berhasil 

Gambar 4. (a) Konsentrasi NO2, (b) Land Surface Temperature (LST), (c) 
Konsentrasi CO dan (d) Rata-rata NDWI di Jakarta per Kecamatan 2021 

Level  konsentrasi  NO2  paling  tinggi  berpusat  pada  bagian 
Jakarta  Pusat  dan  Jakarta  Barat.  Selain  itu,  konsentrasi  NO2 
memiliki  level  yang  rendah  pada  bagian  pinggiran  Jakarta. 
Berikutnya,  level  LST  Jakarta  yang  tinggi  berada  di  pusat 
Jakarta dan Jakarta Timur. Level konsentrasi CO yang tinggi 
berada di Kawasan pusat Jakarta. Sebaliknya di wilayah selatan 
Jakarta, level konsentrasi CO paling rendah. Terakhir, rata-rata 
NDWI per kecamatan secara spasial menyebar keseluruhan di 
Jakarta yang levelnya cukup tinggi.  

Gambar 6. (a) Air Pollution Risk, (b) Urban Heat Risk, (c) Carbon Emission 
Risk dan (d) Flood Disaster Risk di Jakarta per Kecamatan 

Berdasarkan Gambar 6, dapat diidentifikasi kecamatan yang 
paling berisiko terhadap bencana berdasarkan Risk Level nya. 
Misalnya,  risiko  polusi  udara  di  Jakarta  sangat  besar  pada 
kecamatan  Tambora,  Cempaka  Putih  dan  Matraman.  Risiko 
panas perkotaan dan risiko emisi karbon paling berisiko pada 
kecamatan Tambora dan Cempaka Putih. Risiko bencana banjir 
sangat  berisiko  pada  kecamatan  Tambora.  Berikutnya, 
besarnya 
ini  mengindikasikan  besarnya 
permintaan  ecosystem  services  dalam  mengatasi  benecana-

risiko  bencana 

 4 / 7 

 
 
  
 
 
 
 
 
 
Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

Jakarta 

bencana  di 
seperti  penerapan  urban  green 
infrastructure. Kami menggunakan FPPPCM clustering untuk 
mengelompokkan  kecamatan  di  Jakarta  menjadi  kelompok 
yang permintaan ecosystem services nya tinggi atau tidak tinggi.  
FPPPCM  perlu  menginisiasi  terlebih  dahulu  banyaknya 
klaster  𝑘  untuk  melakukan  clustering.  Sehingga,  kami 
melakukan evaluasi kinerja FPPPCM melalui Cluster Validity 
Index seperti Partition Coefficient (PC), Partition Entropy (PE), 
Silhouette  Index  (SI),  Fuzzy  Silhouette  Index  (FSI)  dan 
Modified  Partition  Coefficient  (MPC)  untuk  menentukan 
jumlah  klaster  mana  yang  paling  optimal  dalam  membagi 
klaster. 

TABEL 2 
Cluster Validity Index 

Gambar 7. Peta Klaster Level Ecosystem Services Demand dengan algoritma 
FPPPCM di Jakarta 

n_cluster 

PC 

PE 

SI 

FSI 

MPC 

2 

3 

4 

5 

0.4571 

0.5266 

0.7432 

0.7893 

-0.086 

0.5168 

0.7475 

0.5699 

0.6670 

0.2752 

0.4812 

0.8876 

0.6183 

0.7347 

0.3082 

0.4671 

1.0051 

0.5955 

0.6714 

0.3339 

Berdasarkan Tabel 2, didapatkan hasil cluster validaty index 
menggunakan  algoritma  FPPPCM  dengan  inisialisasi  cluster 
prototype  menggunakan  K-Means  dan  parameter  default  dari 
package ppclust di R. Berdasarkan indeks PC, jumlah klaster 3 
merupakan jumlah klaster paling optimal karena memiliki nilai 
indeks PC paling kecil, yaitu 0,5168. Lalu, berdasarkan indeks 
PE,  jumlah  klaster  2  merupakan  yang  paling  optimal  karena 
memiliki nilai indeks paling kecil yaitu 0,5266. Indeks SI dan 
FSI juga memperlihatkan bahwa  jumlah klaster 2 merupakan 
paling  optimal  karena  memiliki  nilai  indeks  terbesar 0,7432 
dan 0,7893. Indeks MPC menunjukkan bahwa jumlah klaster 
paling  optimal  adalah  jumlah  klaster  5  karena  memiliki  nilai 
MPC paling besar yaitu 0,3339. Sehingga berdasarkan 5 index 
yang  ditunjukkan,  kami  memilih  jumlah  klaster  2  untuk 
dilakukan  pengelompokkan  tingkat  permintaan  ecocsystem 
services di DKI Jakarta berdasarkan disaster risk index. 

Hasil  clustering  menggunakan  algoritma  FPPPCM  untuk 
mengelompokkan  permintaan  terhadap  ecosystem  services 
menggunakan risk disaster index di DKI Jakarta diperlihatkan 
pada Gambar 7. Algoritma FPPPCM menunjukkan bahwa dari 
42  kecamatan  di  Jakarta,  terdapat  13  kecamatan  yang  sangat 
berisiko terhadap permasalahan bencana di Jakarta. Besarnya 
risiko 
tingginya  permintaan 
rangka 
masyrakat 
mengurangi  dampak  serta  risiko  dari  bencana  yang  sering 
terjadi  di  Jakarta.  Dalam  13  kecamatan  tersebut,  diantaranya 
adalah  kecamatan  Tambora,  Grogol  Petamburan,  Palmerah, 
Sawah Besar, Kemayoran, Senen, Johar Baru, Cempaka Putih, 
Matraman, Jatinegara, Tebet, Kramat Jati dan Koja. 

juga  menunjukkan  betapa 
terhadap  ecosystem 

services  dalam 

Hasil  Clustering  menggunakan  FPPPCM  memperlihatkan 
efek ketetanggaan di beberapa kecamatan. Misalnya di Jakarta 
Barat, kecamatan Tambora, Grogol Petamburan dan Palmerah 
saling  bertetangga  dan  menjadi  daerah  yang  sangat  berisiko 
terhadap bencana serta memiliki tingkat permintaan yang tinggi 
terhadap ecosystem services. Lalu di Jakarta Pusat, kecamatan 
Sawah  Besar,  Kemayoran,  Senen,  Johar  Baru  dan  Cempaka 
Putih  yang  juga  saling  bertetangga  menjadi  wilayah  paling 
berisiko  akan  bencana  di  Jakarta.  Kecamatan  Matraman, 
Jatinegara,  Kramat  Jati  dan  Tebet  juga  saling  bertetangga 
dimana wilayah tersebut merupakan bagian dari Jakarta Timur 
dan  Jakarta  Selatan  serta  wilayah  tersebut  berisiko  terhadap 
permasalahan  bencana.  Berbeda  di  Jakarta  Utara,  kecamatan 
Koja yang juga dikategorikan berisiko tidak memiliki tetangga 
lain  yang  juga  berkategori  berisiko.  Dapat  dikatakan  bahwa 
besarnya  risiko  bencana  dan  permintaan  ecosystem  services 
diindikasikan  memiliki  efek  spasial  dan  ketetanggaan  di 
kecamatan tersebut. 
Secara  visual 

tampak  hasil  clustering  menggunakan 
FPPPCM terdapat efek spasial pada tingkat ecosystem services 
demands  ataupun  indeks  risiko  bencana  di  Jakarta.  Untuk 
melihat adanya autokorelasi spasial secara statistik pada hasil 
clustering FPPPCM, kami menggunakan pengujian joincount. 
Pengujian  ini  didesain  untuk  menganalisis  variabel  kategorik 
dalam mendeteksi adanya korelasi spasial. Sebelum melakukan 
pengujian, perlu diidentifikasi konektivitas ketetanggaan untuk 
selanjutnya  ketetanggaan  tersebut  akan  digunakan  untuk 
analisis  korelasi  spasial.  Berikut  gambar  hasil  konektivitas 
ketetanggaan menggunakan pendekatan queen.  

 5 / 7 

 
 
 
 
 
 
 
Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

permintaan ecosystem services yang tinggi di kecamatan yang 
berisiko  terhadap  bencana.  Permintaan  yang  tidak  segera 
diatasi  akan  menyebabkan  permasalahan  bencana  seperti 
kualitas  udara  yang  buruk,  fenomena  urban  heat  island  dan 
banjir  yang  implikasinya  menjadi  penyakit,  menurunnya 
kesejahteraan dan bahkan kematian. 

yang 

services 

Dalam  mengurangi  banyaknya  permintaan 

terhadap 
ecosystem  services  di  Jakarta,  salah  satu  solusinya  adalah 
implementasi  urban  green  infrastructure  sebagai  suplai  dari 
ecosystem 
berusaha  menyelesaikan 
permasalahan-permasalahan di perkotaan. Implementasi urban 
green  infrastructure  diutamakan  pada  wilayah  yang  menjadi 
prioritas seperti 13 kecamatan di Jakarta yang memiliki demand 
tinggi  terhadap  ecosystem  services.  Selain  itu,  adanya  efek 
korelasi  spasial  pada  13  kecamatan  yang  ecosystem  services 
tinggi  memberikan  sebuah  solusi  bahwa 
demand  nya 
pengimplementasian  urban  green  infrastructure  yang  baik 
pada satu kecamatan dapat berpengaruh pada kecamatan yang 
menjadi tetangganya. 

kami 

untuk 

Saran 

penelitian 

berikutnya 

perlu 
mempertimbangkan  suplai  dari  ecosystem  services  sehingga 
ketimpangan  ecosystem  services  dapat  terlihat  jelas  di  setiap 
kecamatan.  Selain  itu,  kerentanan  pada  penilaian  risiko 
bencana  perlu  dipertimbangkan  lebih  luas  lagi  berdasarkan 
teori  pendukung  yang  ada  seperti  kemiskinan,  orang 
berpenyakit tertentu dan keadaan yang rentan terhadap bencana 
lainnya.  

DAFTAR PUSTAKA 
[1]  Maheng, D., Pathirana, A., & Zevenbergen, C. (2021). A preliminary study 
on the impact of landscape pattern changes due to urbanization: Case study 
of Jakarta, Indonesia. Land, 10(2), 218. 

[2]  Nanditho,  G.  A.,  &  Yola,  L.  (2022).  Urban  Development  and  Traffic 
Congestion:  Jakarta  Study  during 
In Sustainable 
Development Approaches: Selected Papers of AUA and ICSGS 2021 (pp. 
135-142). Cham: Springer International Publishing. 

the  Pandemic. 

[3]  Rendana,  M.,  Idris,  W.  M.  R.,  &  Rahim,  S.  A.  (2022).  Changes  in  air 
quality during and after large-scale social restriction periods in Jakarta city, 
Indonesia. Acta Geophysica, 70(5), 2161-2169. 

and 

greenhouse 

[4]  Monforti-Ferrario,  F.,  &  Blanco,  M.  P.  (2021).  The  impact  of  power 
network  congestion,  its  consequences  and  mitigation  measures  on  air 
pollutants 
from 
gases 
Germany. Renewable and Sustainable Energy Reviews, 150, 111501. 
[5]  Wang, D., Hu, Y., Tang, P., Liu, C., Kong, W., Jiao, J., ... & Liu, Y. (2022). 
Identification of Priority Implementation Areas and Configuration Types 
for  Green  Infrastructure  Based  on  Ecosystem  Service  Demands  in 
Metropolitan City. International Journal of Environmental Research and 
Public Health, 19(13), 8191. 

emissions.  A 

case 

[6]  Kurniawan, R., Saputra, A. M. W., Wijayanto, A. W., & Caesarendra, W. 
(2022).  Eco-environment  vulnerability  assessment  using  remote  sensing 
approach  in  East  Kalimantan,  Indonesia. Remote  Sensing  Applications: 
Society and Environment, 27, 100791. 

[7]  Abood, S. A., Lee, J. S. H., Burivalova, Z., Garcia‐Ulloa, J., & Koh, L. P. 
(2015). Relative contributions of the logging, fiber, oil palm, and mining 
industries to forest loss in Indonesia. Conservation Letters, 8(1), 58-67. 
[8]  Nasution, B. I., Saputra, F. M., Kurniawan, R., Ridwan, A. N., Fudholi, A., 
&  Sumargo,  B.  (2022).  Urban  vulnerability  to  floods  investigation  in 
jakarta, Indonesia: A hybrid optimized fuzzy spatial clustering and news 
media  analysis  approach. International  Journal  of  Disaster  Risk 
Reduction, 83, 103407. 

[9]  Penney, D., Yantha, M., & Swatuk, L. (2022). A Megacity’s Hydrological 
Risk: An analysis of water security issues in Jakarta City, Indonesia. In The 
Political Economy of  Urban  Water  Security  under Climate  Change (pp. 
81-104). Cham: Springer International Publishing. 

 6 / 7 

Gambar 8. Peta Konektivitas Ketetanggaan Kecamatan dengan Pendekatan 
Queen di Provinsi Jakarta 

Gambar  8  memperlihatkan  bagaimana  bentuk  konektivitas 
ketetanggaan  yang  terjadi  di  Jakarta.  Pendekatan  queen 
memberikan koneksi ketetanggaan pada suatu kecamatan yang 
bersinggungan pada kecamatan lainnya. Setelah mendapatkan 
konektivitas  ketetanggaan,  berikutnya  dengan  menggunakan 
joincount  test  dilakukan  analisis  korelasi  spasial  pada  hasil 
cluster  yang  telah  didapatkan.  Tabel  3  menunjukkan  hasil 
pengujian joincount menggunakan bantuan software R.  

TABEL 3 
Hasil Pengujian JoinCount 

cluster 

p-value 

1 

2 

0.594 

0.002061 

Berdasarkan  hasil  dari  Tabel  3,  hasil  pengujian  joincount 
menghasilkan signifikansi yang berbeda pada tiap klaster nya. 
Pada  klaster  1  (permintaan  ecosystem  services  rendah  dan 
risiko  bencana  rendah)  terlihat  bahwa  p-value  memiliki  nilai 
0,594 .  Jika  hipotesis  nol  adalah  tidak  terdapat  autokorelasi 
spasial,  maka  keputusan  pada  pengujian  joincount  klaster  1 
adalah  gagal  tolak  H0,  artinya  tidak  terdapat  autokorelasi 
spasial pada  klaster 1.  Sebaliknya pada klaster 2 (permintaan 
ecosystem  services  tinggi  dan  risiko  bencana  tinggi),  hasil 
pengujian  menggunakan  joincount  memberikan  nilai  p-value 
sebesar 0,002. Jika menggunakan tingkat kesalahan 5%, maka 
keputusan adalah tolak H0 yang artinya terdapat cukup bukti 
untuk  mengatakan  bahwa  terdapat  autokorelasi  spasial  pada 
klaster 2.  

Walaupun  pada  klaster  1  tidak  signifikan  hasilnya,  namun 
pada  klaster  2  memberikan  hasil  signifikan.  Signifikan  pada 
klaster 2 menandakan memang ada efek korelasi spasial pada 
hasil clustering menggunakan FPPPCM sebelumnya. Selain itu, 
hasil analisis ini juga memberikan pernyataan yang kuat bahwa 
permintaan  ecosystem  services  dan  risiko  bencana  di  Jakarta 
memiliki korelasi spasial pada hasilnya.  

VII. 

PENUTUP 

Pengintegrasian  dan  pengelolaan  ecosystem  services  di 
jumlah 

Jakarta  menjadi  program  yang  bisa  mengatasi 

 
 
 
 
 
 
 
 
[10] Zhang, S., & Ramírez, F. M. (2019). Assessing and mapping ecosystem 
services  to  support  urban  green  infrastructure:  The  case  of  Barcelona, 
Spain. Cities, 92, 59-70. 

[11] Nakamura,  F.  (2022). Green  Infrastructure  and  Climate  Change 
Adaptation: Function, Implementation and Governance (p. 506). Springer 
Nature. 

[12] Boesing,  A.  L.,  Prist,  P.  R.,  Barreto,  J.,  Hohlenwerger,  C.,  Maron,  M., 
Rhodes,  J.  R.,  ...  &  Metzger,  J.  P.  (2020).  Ecosystem  services  at  risk: 
integrating  spatiotemporal  dynamics  of  supply  and  demand  to  promote 
long-term provision. One Earth, 3(6), 704-713. 

[13] Malakar, K., Mishra, T., Hari, V., & Karmakar, S. (2021). Risk mapping 
of Indian coastal districts using IPCC-AR5 framework and multi-attribute 
decision-making  approach. Journal  of  Environmental  Management, 294, 
112948. 

[14] Hu, S., Chen, L., Li, L., Wang, B., Yuan, L., Cheng, L., ... & Zhang, T. 
(2019). Spatiotemporal dynamics of ecosystem service value determined 
by 
the  urbanization  of  Anhui  Province, 
China. International  Journal  of  Environmental  Research  and  Public 
Health, 16(24), 5104. 

land-use  changes 

in 

[15] Gomes, D. S., Andrade, L. A., Ribeiro, C. J. N., Peixoto, M. V. S., Lima, 
S. V. M. A., Duque, A. M., ... & Santos, A. D. (2020). Risk clusters of 
COVID-19  transmission  in  northeastern  Brazil:  prospective  space–time 
modelling. Epidemiology & Infection, 148, e188. 

[16] Ghosh, I., Jana, R. K., & Pramanik, P. (2022). New business capacity of 
developed, developing and least developing economies: inspection through 
state-of-the-art 
PSO-GBR 
frameworks. Benchmarking: An International Journal, (ahead-of-print). 
[17] Nasution,  B.  I.,  Kurniawan,  R.,  Siagian,  T.  H.,  &  Fudholi,  A.  (2020). 
Revisiting social vulnerability analysis in Indonesia: An optimized spatial 
fuzzy  clustering  approach. International  Journal  of  Disaster  Risk 
Reduction, 51, 101801. 

clustering 

fuzzy 

and 

[18] Ersoy Mirici, M. (2022). The ecosystem services and green infrastructure: 
a 
economic 
and 
valuation. Sustainability, 14(1), 517. 

systematic 

review 

gap 

the 

of 

[19] Sakti, A. D., Anggraini, T. S., Ihsan, K. T. N., Misra, P., Trang, N. T. Q., 
Pradhan, B., ... & Wikantika, K. (2023). Multi-air pollution risk assessment 
in  Southeast  Asia  region  using  integrated  remote  sensing  and  socio-
economic data products. Science of The Total Environment, 854, 158825. 
[20] Jiang,  L.,  Huang,  X.,  Wang,  F.,  Liu,  Y.,  &  An,  P.  (2018).  Method  for 
evaluating ecological vulnerability under climate change based on remote 
sensing: A case study. Ecological Indicators, 85, 479-486. 

[21] Dwirahmadi,  F.,  Rutherford,  S.,  Phung,  D.,  &  Chu,  C.  (2019). 
Understanding  the  operational  concept  of  a  flood-resilient  urban 
community  in  Jakarta,  Indonesia,  from  the  perspectives  of  disaster  risk 
reduction, 
development 
agencies. International  journal  of  environmental  research  and  public 
health, 16(20), 3993. 

adaptation, 

climate 

change 

and 

Makalah Seminar Skripsi – Program Studi D-IV Komputasi Statistik 

[29] Wang, D., Chen, Y., Hu, L., Voogt, J. A., Gastellu-Etchegorry, J. P., & 
Krayenhoff, E. S. (2021). Modeling the angular effect of MODIS LST in 
urban  areas:  A  case  study  of  Toulouse,  France. Remote  Sensing  of 
Environment, 257, 112361. 

[30] Singh,  S.,  &  Kansal,  M.  L.  (2022).  Chamoli  flash-flood  mapping  and 
evaluation  with  a  supervised  classifier  and  NDWI  thresholding  using 
Sentinel-2  optical  data 
in  Google  earth  engine. Earth  Science 
Informatics, 15(2), 1073-1086. 

[31] Badina, S., Babkin, R., Bereznyatsky, A., & Bobrovskiy, R. (2022). Spatial 
aspects  of  urban  population  vulnerability  to  natural  and  man-made 
hazards. City and Environment Interactions, 15, 100082. 

[32] Essola, E. B., & Yeom, C. (2022). Population Intersection Densities: An 
Assessment  of  a  Correlation  Using  Spatial  Comparison  and  Regression 
Analysis in Yaoundé, Cameroon. The Open Transportation Journal, 16(1). 
[33] Das, S., Ghosh, A., Hazra, S., Ghosh, T., de Campos, R. S., & Samanta, S. 
(2020). Linking IPCC AR4 & AR5 frameworks for assessing vulnerability 
and risk to climate change in the Indian Bengal Delta. Progress in Disaster 
Science, 7, 100110. 

[34] Malakar, K., Mishra, T., Hari, V., & Karmakar, S. (2021). Risk mapping 
of Indian coastal districts using IPCC-AR5 framework and multi-attribute 
decision-making  approach. Journal  of  Environmental  Management, 294, 
112948. 

[35] Szilágyi,  L.  (2013).  Robust  Spherical  Shell  Clustering  Using  Fuzzy‐
intelligent 

journal  of 

Possibilistic  Product  Partition. International 
systems, 28(6), 524-539. 

[36] Thilagaraj, T., & Sengottaiyan, N. Implementation of Fuzzy Possibilistic 
Product  Partition  C-Means  and  Modified  Fuzzy  Possibilistic  C-Means 
Clustering To Pick the Low Performers Using R-Tool. 

[37] Askari,  S.  (2021).  Fuzzy  C-Means  clustering  algorithm  for  data  with 
unequal cluster sizes and contaminated with noise and outliers: Review and 
development. Expert Systems with Applications, 165, 113856. 

[38] Ahmed, M., Seraj, R., & Islam, S. M. S. (2020). The k-means algorithm: 
A  comprehensive  survey  and  performance  evaluation. Electronics, 9(8), 
1295. 

[39] Ryoo, J. H., Park, S., Kim, S., & Ryoo, H. S. (2020). Efficiency of cluster 
validity  indexes  in  fuzzy  clusterwise  generalized  structured  component 
analysis. Symmetry, 12(9), 1514. 

[40] Zhu, L. F., Wang, J. S., & Wang, H. Y. (2019). A novel clustering validity 
function of FCM clustering algorithm. IEEE Access, 7, 152289-152315. 
[41] Wang,  X.,  &  Xu,  Y.  (2019,  July).  An  improved  index  for  clustering 
validation based on Silhouette index and Calinski-Harabasz index. In IOP 
Conference Series: Materials Science and Engineering (Vol. 569, No. 5, 
p. 052024). IOP Publishing. 

[42] Subbalakshmi, C., Sayal, R., & Saini, H. S. (2020). Cluster validity using 
modified 
set. 
index  on 
In Computational  Intelligence  in  Data  Mining:  Proceedings  of  the 
International Conference on ICCIDM 2018 (pp. 1-14). Springer Singapore. 

large  dynamic  data 

silhouette 

fuzzy 

[22] Martinez, R., & Masron, I. N. (2020). Jakarta: A city of cities. Cities, 106, 

102868. 

[23] Tosepu, R., Gunawan, J., Effendy, D. S., Lestari, H., Bahar, H., & Asfian, 
P. (2020). Correlation between weather and Covid-19 pandemic in Jakarta, 
Indonesia. Science of the total environment, 725, 138436. 

[24] Setiowati,  R.,  Mizuno,  K.,  Hasibuan,  H.  S.,  &  Koestoer,  R.  H.  (2022). 
Urban green spaces for support healthiness in Jakarta during the COVID-
19  pandemic:  A  quantitative 
study. Environmental  Engineering 
Research, 28(2), 210598. 

[25] Syuhada, G., Akbar, A., Hardiawan, D., Pun, V., Darmawan, A., Heryati, 
S. H. A., ... & Mehta, S. (2023). Impacts of Air Pollution on Health and 
Cost  of 
Indonesia. International  Journal  of 
Environmental Research and Public Health, 20(4), 2916. 

in  Jakarta, 

Illness 

[26] Wicaksono, A., & Herdiansyah, H. (2019, December). The impact analysis 
of  flood  disaster  in  DKI  jakarta:  prevention  and  control  perspective. 
In Journal of Physics: Conference Series (Vol. 1339, No. 1, p. 012092). 
IOP Publishing. 

[27] Bodah, B. W., Neckel, A., Maculan, L. S., Milanes, C. B., Korcelski, C., 
Ramírez, O., ... & Oliveira, M. L. (2022). Sentinel-5P TROPOMI satellite 
application  for  NO2  and  CO  studies  aiming  at  environmental 
valuation. Journal of Cleaner Production, 357, 131960.  

[28] Plant, G., Kort, E. A., Murray, L. T., Maasakkers, J. D., & Aben, I. (2022). 
Evaluating  urban  methane  emissions  from  space  using  TROPOMI 
methane  and  carbon  monoxide  observations. Remote  Sensing  of 
Environment, 268, 112756. 

 7 / 7 

 
 
","2023-12-19T08:48:30.164612Z",221910726,"[{""start"":744,""end"":829,""text"":"" mengidentifikasi wilayah\\nprioritas di Jakarta berdasarkan ecosystem services demand"",""labels"":[""Tujuan""]},{""start"":957,""end"":1015,""text"":"" Fuzzy\\nPossibilistic Partion Product C-Means (FPPPCM)"",""labels"":[""Metode""]},{""start"":1398,""end"":1599,""text"":""ngkan\\n\\nc"",""labels"":[""Temuan""]},{""start"":6700,""end"":6836,""text"":""mengidentifikasi area di\\nJakarta yang perlu mengimplementasi urban green\\ninfrastructure berdasarkan ecosystem services demand"",""labels"":[""Tujuan""]}]",295.32,"2023-12-19T08:52:22.737737Z"
9,"1","Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

Analisis Keberlanjutan Penggunaan Platform Belanja 
Online pada Masa Transisi Menuju Endemi Covid-19 

Nazzala Qinthara Nafi (221910692, 4SD2) 
Dosen Pembimbing: Nori Wilantika S.ST., M.TI 

Sebagai 

Ringkasan— 

pengendalian 

covid-19, 
upaya 
pemerintah memberlakukan aturan ketat mengenai pembatasan 
mobilitas  penduduk.  Salah  satu  dampak  adanya  pembatasan 
mobilitas  penduduk  tersebut  adalah  meningkatnya  penggunaan 
platform  belanja  online.  Namun  Pada  masa  transisi  menuju 
endemi  saat  ini,  mobilitas  penduduk  sudah  tidak  dibatasi.  
Sehingga,  muncul  pertanyaan  bagaimana  kondisi  pengguna 
platform  belanja  online  ketika  masa  transisi.  Atas  dasar  itu, 
penelitian 
ini  bertujuan  untuk  mengetahui  keberlanjutan 
penggunaan  platform  belanja  online  pada  masa  transisi  di 
Indonesia dan mengetahui faktor-faktor yang mempengaruhinya. 
Penelitian  ini  menggunakan  kerangka  teoritis  utama  TAM 
dengan  menambahkan  variabel  customer  satisfaction,  trust,  dan 
system quality. Analisis data dilakukan menggunakan SEM PLS. 
Dari  hasil  penelitian  didapatkan  bahwa  mayoritas  tetap  akan 
menggunakan  platform  belanja  online  meski  kondisi  mobilitas 
intention 
tidak  dibatasi  dan  didapati  bahwa  repurchase 
berpengaruh positif pada actual repurchase. 

Kata Kunci— keberlanjutan, belanja online, SEM, PLS, 

TAM 

I.  LATAR BELAKANG 

Perkembangan  e-commerce  berpengaruh  positif  terhadap 
pertumbuhan ekonomi jangka panjang  [1]. Dengan adanya e-
commerce  akan  berdampak  pada  pemerataan  perekonomian 
karena pemasaran produk di wilayah desa sudah tidak terhalang 
oleh  jarak  [2].  Salah  satu  bentuk  e-commerce  adalah  belanja 
online[3].  Aktivitas  belanja  online  sendiri  merupakan  proses 
dimana pelanggan langsung membeli barang atau jasa kepada 
penjual  melalui  internet[3].  Melalui  aktivitas  belanja  online, 
pembeli mampu melakukan transaksi pembelian kapanpun dan 
dimanapun sehingga tidak harus menyesuaikan jam buka toko 
[4],  [5].  Bagi  pelanggan,  aktivitas  belanja  online  dapat 
dilakukan dengan cepat, mudah, dan biaya lebih rendah[6]. 

Daya 

tarik  dan  kelebihan  yang  dirasakan 

telah 
meningkatkan popularitas penggunaan platform belanja online 
[7]. Popularitas belanja online juga dirasakan di Indonesia. Di 
Indonesia,  nilai  aktivitas  belanja  online  meningkat  dari  USD 
1,79  miliar  pada  tahun  2013  menjadi  USD  4,89  miliar  pada 
tahun 2016[7].  Aktivitas belanja online juga meningkat dengan 
adanya  wabah  Covid-19.  Aktivitas  belanja  Online  tumbuh 
secara  eksponensial  ketika  wabah  Covid-19  terjadi  [8]. 
Kebutuhan  akan  belanja  dianggap  sebagai  bagian  penting 
dalam  kehidupan  sehari  hari[9].  Dengan  adanya  wabah 
tersebut, masyarakat disarankan untuk tetap tinggal dan bekerja 
di  rumah.  Kebijakan  itu  diambil  sebagai  upaya  pemutusan 
rantai  penyebaran  penyakit.  Dengan  adanya  pembatasan 
aktivitas di luar ruangan peluang bisnis telah berubah, transaksi 
dan komunikasi tidak lagi melalui jalur tradisional (perjumpaan 
fisik) tetapi melalui platform belanja online [9]. 

Masa pandemi Covid-19 telah memasuki babak baru (masa 
transisi).  Pada  masa  transisi,  pemerintah  mulai  memberikan 

untuk  masyarakat.  Berbagai 
kelonggaran  mobilitas 
seperti 
kelonggaran  yang  dirasakan  oleh  masyarakat 
kelonggaran  untuk  mudik  hingga  perizinan  melepas  masker 
pada  ruang  terbuka.  Pada  Bulan  Juni  2022  pemerintah 
mengeluarkan  Surat  Edaran  Kementerian  Pendidikan, 
Kebudayaan,  Riset,  dan  Teknologi  Nomor  3  Tahun  2022 
mengenai panduan penyelenggaraan pembelajaran secara tatap 
muka penuh dengan kapasitas peserta didik 100 persen. Selain 
itu,  pemerintah  juga  mengeluarkan  Instruksi  Menteri  Dalam 
Negeri Nomor 26 Tahun 2022 yang berisi perizinan pelepasan 
masker  di  area  terbuka.  Sehingga,  dalam  penelitian  ini 
menetapkan  bahwa  masa  transisi  dihitung  sejak  Bulan  Juni 
2022. 

Adanya kelonggaran mobilitas penduduk ini menimbulkan 
pertanyaan  bagaimana  aktivitas  belanja  online  pada  masa 
transisi.  Penelitian  sebelumnya  menyatakan  bahwa  keadaan 
dunia  setelah  pandemi  berbeda  dari  sebelum  pandemi[10]. 
Dalam hal konsumsi, ditemukan bahwa pola permintaan yang 
berubah  akibat  pandemi,  tidak  akan  kembali  seperti  semula. 
Contohnya adalah jumlah gedung bioskop dan teater yang tutup 
sejak  beberapa  tahun  terakhir  sebagai  akibat  adanya  layanan 
streaming.  Pandemi  kemudian  mempercepat  perubahan  pola 
konsumsi  ke  layanan  streaming  [10].  Atas  hal  tersebut, 
penelitian ini ingin melihat bagaimana keberlanjutan aktivitas 
belanja  online  ketika  masa  transisi  di  Indonesia.  Terdapat 
banyak  penelitian  terdahulu  terkait  aktivitas  belanja  online 
pada masa pandemi Covis-19 seperti yang dilakukan oleh [7], 
[10]–[12].  Namun,  penelitian  yang  melihat  keberlanjutan 
aktivitas belanja online tersebut setelah pandemi mereda masih 
terbatas. 

II.  TUJUAN PENELITIAN 

Atas  latar  belakang  yang  telah  dijelaskan  sebelumnya, 

maka didapati tujuan penelitian sebagai berikut: 

1.  Mengetahui keberlanjutan penggunaan platform belanja 
tidak  dilakukan  pembatasan 

online  ketika  sudah 
mobilitas penduduk seperti pada masa transisi saat ini. 
2.  Mengetahui  faktor-faktor  yang  berpengaruh  terhadap 
keberlanjutan  penggunaan  platform  belanja  online  di 
Indonesia. 

III. TINJAUAN PUSTAKA 

A.  Platform Belanja Online 

Dalam  penelitian  ini,  platform  belanja  online  mengikuti 
klasifikasi  bisnis  e-commerce  yang  ada  di  Indonesia[12]. 
Klasifikasi  bisnis  yang  termasuk  dalam  penelitian  ini  yaitu 
iklan  baris,  online  marketplace,  shopping  mall,  Toko  online, 
dan  Toko  online  di  media  sosial.  Contoh  platform  belanja 
Indonesia  seperti  OLS,  Zalora,  Tokopedia, 
online  di 
Bukalapak, Shopee, Matahari mall. 

 1 / 7 

 
 
 
B. 

Pengembangan Hipotesis 

Niat keberlanjutan (continuance intention) didefinisikan 
sebagai  niat  pengguna  untuk  terus  menggunakan  sistem 
informasi  atau  teknologi[13].  Dalam  penelitian  ini,  yang 
ingin  dikaji  adalah  niat  pembelian  kembali  (Repurchase 
Intention)  melalui  platform  belanja  online.  Repurchase 
intention  dalam  konteks  berbelanja  online  didefinisikan 
sebagai  gambaran  keinginan  pelanggan  untuk  dapat 
melakukan  pembelian  kembali  produk  atau 
layanan 
tertentu[14]. 

Repurchase 

intention  dapat  mencirikan  perilaku 
pembelian kembali (Actual Repurchase) di platform belanja 
online  [14].  Dalam  penelitian  ini,  actual  didefinisikan 
sebagai  perilaku  pembelian  dalam  aktivitas  belanja  online, 
ketika pembatasan mobilitas masyarakat sudah tidak dibatasi 
oleh  pandemi  Covid-19.  Sehingga  dapat  dirumuskan 
hipotesis bahwa 
H1  :  Customer  repurchase  intention  dari  platform  belanja 
online berpengaruh positif pada actual repurchase. 

Penelitian 

ini  menggunakan  model  Technology 
Acceptance Model (TAM) karena kerangka teoritis tersebut 
dapat  menjelaskan  adopsi  belanja  online,  seperti  yang 
diimplementasikan  pada  berbagai  penelitian[14]–[16]. 
Selain itu, TAM tidak hanya mampu menjelaskan perilaku 
konsumen  dalam  penerimaan  teknologi  informasi,  tetapi 
juga mampu menjelaskan keberlanjutan dari suatu platform 
teknologi[17]. 

Dalam  TAM  dinyatakan  bahwa  intention  dipengaruhi 
oleh dua faktor yaitu keandalan (Perceived Usefulness) dan 
kemudahan 
(Perceived  Ease  of  Use)[17].  Perceived 
Usefulness  mampu  memberikan  gambaran  sejauh  mana 
seseorang  percaya  bahwa  belanja  menggunakan  platform 
belanja  online  meningkatkan  kinerja  dalam  pembelian 
barang dan /atau jasa[18]. Sedangkan Perceived Ease of Use 
memberikan  gambaran  sejauh  mana  seseorang  percaya 
bahwa  berbelanja  online  memudahkan  dalam  melakukan 
pembelian  barang  dan  /atau  jasa[14].  Sehingga  disusun 
hipotesis sebagai berikut: 
H2:  Perceived  usefulness  dari  platform  belanja  online 
berpengaruh positif pada customer repurchase intention. 
H3:  Perceived  ease  of  use  dari  platform  belanja  online 
berpengaruh positif terhadap customer repurchase intention. 
Selain  itu,  penelitian  ini  menambahkan  model  TAM 
dengan variabel kepuasan pelanggan(customer satisfaction), 
kualitas  sistem(system  quality),  dan  kepercayaan(trust). 
Variabel  customer 
sebagai 
perbedaan  antara  ekspektasi  dan  realita  yang  dirasakan 
pelanggan[14].  Customer  satisfaction  mampu  memberikan 
gambaran  perbedaan 
antara  harapan  pembeli  dan 
pengalaman sebenarnya dalam melakukan aktivitas belanja 
online.  Variabel  ini  diputuskan  masuk  dalam  kerangka 
teoritis 
dapat 
customer 
mempengaruhi  niat  mereka  untuk  membeli  dari  platform 
belanja  online  [14]  serta  sejalan  dengan  penelitian    [17], 
[19]–[22]. Penelitian ini juga ingin menilai apakah customer 
langsung  mempengaruhi  pembelian 
satisfaction  secara 

satisfaction  didefinisikan 

dikarenakan 

satisfaction 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

kembali secara nyata, sehingga disusunlah hipotesis seperti 
berikut: 
H4:  Perceived  usefulness  dari  platform  belanja  online 
berpengaruh positif pada customer satisfaction. 
H5:  Perceived  ease  of  use  dari  platform  belanja  online 
berpengaruh positif terhadap customer satisfaction. 
H6:  Customer  satisfaction  dari  platform  belanja  online 
berpengaruh positif terhadap customer repurchase intention.  
H7:  Customer  satisfaction  dari  platform  belanja  online 
berpengaruh positif pada actual repurchase. 

pula 

pada 

intention 

Nyatanya,  dalam  berbagai  penelitian  intention  dan 
tidak  hanya  dipengaruhi  oleh 
customer  satisfaction 
perceived  usefulness  dan  perceived  ease  of  use.  Dalam 
kerangka  teoritis  D&M  IS  Success  Model,  system  quality 
berpengaruh 
customer 
satisfaction[23].  Sehingga  penelitian  ini  menambahkan 
variabel system quality untuk menilai keberlanjutan aktivitas 
belanja online. Dalam penelitian ini, system quality mengacu 
pada  pengukuran  pemrosesan 
informasi[24]. 
Sehingga dirumuskan hipotesis: 
H8: System quality dari platform belanja online berpengaruh 
positif pada customer satisfaction. 
H9: System quality dari platform belanja online berpengaruh 
positif terhadap customer repurchase intention. 

sistem 

dan 

Variabel terakhir yang juga digunakan dalam penelitian 
ini  adalah 
trust.  Kepercayaan  menjadi  faktor  utama 
berbelanja  online[25].  Telah  banyak  penelitian  yang 
melibatkan  trust  dalam  melihat  keberlanjutan  berbelanja 
online  [17],  [20],  [21].  Aspek  yang  kerap  dikaitkan  dalam 
variabel trust adalah intention. Pada penelitian[26], didapati 
bahwa  trust  berpengaruh  positif  pada  intention.  Hipotesis 
penelitian mengenai trust yaitu: 
H10: Trust dari platform belanja online berpengaruh positif 
terhadap customer repurchase intention. 

Kerangka 

teoritis  penelitian 

secara  menyeluruh 

digambarkan pada Gambar1. 

Gambar 1. Kerangka teoritis 

IV. METODE PENELITIAN  

Individu  yang  dicakup  dalam  penelitian 

ini  adalah 
seseorang  yang  melakukan  pembelian  menggunakan  internet 
untuk  membeli  barang  dan/atau  jasa  melalui  internet  selama 
bulan Maret 2020 sampai Juni 2022. Setelah bulan Juni 2022 

 2 / 7 

 
 
 
 
disebut sebagai masa transisi pandemi covid-19, hal itu karena 
setelah  bulan  Juni  2022  pemerintah  telah  memberlakukan 
berbagai kelonggaran mobilitas penduduk. 

Gambar 2. Alur penelitian. 

Gambar  2  menjelaskan  mengenai  alur  penelitian.  Alur 
penelitian  ini  dimulai  dengan  studi  literatur  sebagai  dasar 
pengembangan  kerangka 
teoritis  penelitian.  Selanjutnya 
menentukan indikator dan hipotesis untuk tiap variabel sebagai 
dasar  penyusunan  kuesioner.  Setelah  kuesioner  sudah  siap, 
maka  dilakukan  pengumpulan  data  dengan  menggunakan 
metode  yang  dijelaskan  pada  poin  selanjutnya.  Ketika  data 
sudah dikumpulkan selanjutnya dilakukan analisis data untuk 
tujuan  penelitian  dan  penarikan  kesimpulan 
menjawab 
penelitian. 

A.  Metode Pengumpulan Data 

Data yang digunakan dalam penelitian ini merupakan data 
primer. Survei disebar melalui google form dan diisi secara self 
enumeration.  Design  sampling  yang  digunakan  adalah 
Convenience  Sampling.  Convenience  sampling  merupakan 
jenis non probability sampling dimana anggota populasi target 
didasari pada kriteria tertentu yang ditentukan oleh peneliti. 

Metode analisis yang digunakan adalah SEM-PLS. SEM-
PLS,  tidak  memiliki  masalah  dengan  ukuran  sampel  yang 
kecil.  Namun,  ukuran  sampel  yang  lebih  besar  mampu 
meningkatkan  presisi.  Salah  satu  cara  untuk  menentukan 
ukuran sampel minimum adalah dengan menggunakan inverse 
square  method  [27].  Jumlah  ukuran  sampel  minimum 
ditentukan oleh dua hal yaitu signifikansi level dan minimum 
path  coefficient.  Penelitian  ini  menggunakan  minimum  path 
coefficient sebesar 0.2 dan level signifikansi 5% Seperti yang 
dilakukan pada penelitian sebelumnya[28]. 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

Sehingga  dalam  penelitian  ini,  nilai  ukuran  sampel 

minimum yang digunakan adalah 155 responden. 

B.  Metode Analisis Data 

Analisis  data  dilakukan  dengan  dua  cara  yaitu  analisis 
deskriptif dan analisis menggunakan SEM-PLS. Analisis SEM-
PLS dibagi menjadi dua bagian yaitu evaluasi inner model dan 
outer  model.  Evaluasi  outer  model  digunakan  untuk  menguji 
validitas  dan  reliabilitas  model  dengan  memperhatikan  nilai 
Outer Loading, Composite Reliability, Cronbach’s Alfa, AVE, 
dan  tabel  Fornel  Larcker.  Sedangkan  evaluasi  inner  model 
digunakan untuk melihat hubungan antar variabel laten dengan 
memperhatikan hasil uji  kolinearitas, uji signifikansi, R2 serta 
Q2 

V.  KERANGKA PIKIR.  
Penelitian  ini  dimulai  dari  pikiran  peneliti  bagaimana 
keberlangsungan  penggunaan  platform  belanja  online  ketika 
mobilitas penduduk tidak dibatasi atau pada saat masa transisi 
saat  ini.  Sehingga  peneliti  berupaya  menyusun  penelitian 
dengan tujuan untuk dapat melihat keberlanjutan penggunaan 
platform  belanja  online  dan  mencari  faktor-faktor  yang 
mempengaruhinya.  Analisis  akan  dilakukan  dengan  cara 
deskriptif dan menggunakan SEM-PLS. Adapun alur kerangka 
pikir dapat dilihat pada Gambar 3 

Gambar 3. Kerangka pikir 

VI. HASIL  

A.  Karakteristik Responden 

Pengumpulan data dilakukan selama 3 minggu mulai dari 
tanggal  9  Februari  hingga  2  Maret  2023  dan  501  data 
berhasil dikumpulkan. Selanjutnya, 58 data dikeluarkan dari 
analisis karena tidak termasuk dalam cakupan penelitian atau 
jawaban tidak valid. 

 3 / 7 

 
 
 
 
 
Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

Data mengenai karakteristik responden dijelaskan dalam 
Tabel  I.  Karakteristik  responden  yang  tertangkap  dari 
ini,  mayoritas  merupakan  wanita  dengan 
penelitian 
persentase  72,36  persen.  Gen  Z  menjadi  kategori  umur 
terbanyak yang menggunakan platform belanja online.  

Jika  dilihat  dari  jenis  pekerjaan,  maka  mayoritas 
responden  adalah  pelajar/mahasiswa  dengan  lokasi  tinggal 
mayoritas berada di Pulau Jawa dengan 82,84 persen. 

Jika  dilihat  dari  nilai  AVE,  setiap  variabel  memiliki  nilai 
diatas 0.5 yang berarti indikator dan variabel yang digunakan 
dalam  penelitian  ini  dapat  dikatakan  memenuhi  prasyarat 
untuk validitas konvergen[14]. 

TABEL II.  
NILAI OUTER LOADING(OL), AVE, COMPOSITE RELIABILITY (CR), 
CRONBACH’S ALPHA (CA) 

No 

Variabel 
Laten 

Indikator  OL 

CR 

CA 

AVE 

% 

82,84 
7,90 
2,48 
2,03 
3,16 
0,90 
0,67 

Variabel 
Gender 
Perempuan 
Laki-Laki 
Umur 
Gen Z 
Milenial 
Gen X 
Baby Boomer 
Tidak Valid 

TABEL I.  
KARAKTERISTIK RESPONDEN 

% 

72,46 
27,54 

Variabel 
Tempat Tinggal 
Jawa 
Sumatera 
Bali/NTB/NTT 

Sulawesi 

69,07  Kalimantan 
13,77 
13,77  Maluku 
1,13 
2,26 

Platform Belanja Online 
Utama 

Shopee 
Bukalapak 
Tokopedia 
Lazada 
Lainnya 
Pekerjaan 

Mengurus Rumah 
Tangga 
Pelajar/Mahasiswa 
Pegawai Negeri Sipil 
(PNS) 
Karyawan Swasta 
Wirausaha 
Belum/Tidak Bekerja 

Papua 
Pertama Kali Menggunakan 
Platform Belanja Online 
Kurang dari 1 Tahun 
Terakhir 

2,71 

81,94 
0,68 
13,31 
1,59 
2,48 

1 Tahun Lalu 
2 Tahun Lalu 
3 Tahun Lalu 
4 Tahun Lalu 
5 Tahun Lalu 
Lebih Dari 5 Tahun  

3,84 
11,74 
18,74 
18,96 
12,64 
31,38 

6,32 

Keberlanjutan Penggunaan 
Platform Belanja Online 

53,50  Berlanjut 
11,96  Tidak Berlanjut 

98,4 
1,6 

19,41 
2,71 
6,09 

B.  Analisis Outer Model 

Evaluasi outer model digunakan untuk melihat validitas 
dan  reliabilitas  untuk  tiap  variabel[29].  Tahap  pertama 
adalah  menilai  validitas  konvergen  dengan  meninjau  dua 
nilai  yaitu  outer  loading  dan  AVE  dengan  nilai  tergolong 
valid  jika  masing  masing memiliki  nilai  lebih  dari  0,7  dan 
0,5  [28].  Selanjutnya  diuji  internal  consistency  reliability 
dengan melihat nilai Composite Reliability dan Cronbach’s 
alpha  dengan  nilai  minimum  yang  diterima  untuk 
Cronbach’s  alpha  adalah  0.7[30].  Analisis  terakhir  adalah 
menilai diskriman validity melalui tabel Fornell and Larckers 
dengan  membandingkan  nilai  antar  variabel  laten  (matrik 
(matrik 
dan 
diagonal) 
nondiagonal)[18]. 

variabel 

lainnya 

laten 

Dari hasil pada Tabel II didapati bahwa hanya terdapat 
satu  indikator  yang  memiliki  nilai  outer  loading  di  bawah 
0,7.  Pada  penelitian  ini,  didapati  bahwa  indikator  tersebut 
tetap  digunakan  karena  dengan  menghilangkan  SQ4  tidak 
signifikan mengubah nilai AVE dan Composite Reliability. 

1 

2 

3 

4 

5 

6 

Actual 
Repurchase 

Customer 
Satisfaction 

Repurchase 
Intention 

Perceived 
Ease of Use 

Perceived 
Usefulness 

System 
Quality 

7 

Trust 

AR1 
AR2 
AR3 
CS1 
CS2 
CS3 
RI1 
RI2 
RI3 
RI4 
PEOU1 
PEOU2 
PEOU3 
PU1 
PU2 
PU3 
PU4 
SQ1 
SQ2 
SQ3 
SQ4 
TR1 
TR2 
TR3 

0,86 
0,882 
0,903 
0,87 
0,892 
0,862 
0,753 
0,895 
0,879 
0,716 
0,891 
0,916 
0,913 
0,825 
0,862 
0,798 
0,721 
0,771 
0,841 
0,726 
0,616 
0,82 
0,819 
0,865 

0,913 

0,857 

0,777 

0,907 

0,846 

0,765 

0,887 

0,827 

0,663 

0,933 

0,892 

0,822 

0,879 

0,815 

0,645 

0,83 

0,722 

0,552 

0,874 

0,785 

0,698 

Pada  pengujian  internal  consistency  reliability,  dari  hasil 
analisis didapati bahwa nilai composite reliability berada antara 
0.830 hingga 0.933 yang berarti baik dan memuaskan[27]. Pada 
Tabel  II  juga  didapati  bahwa  semua  nilai  Cronbach’s  alpha 
berada diatas 0,7 yang berarti variabel laten dikatakan reliable 
untuk menilai konsistensi hasil di seluruh item pada penelitian 
ini[27]. 

TABEL III. 

TABEL FORNELL-LARCKER 

Variabel 
Laten 
AR 
CS 
PEOU 
PU 
RI 
SQ 
TR 

CS 

PEOU 

AR 
0,882  
0,375  0,875   
0,361  0,415  0,907   
0,432  0,476  0,553 
0,585  0,540  0,481 
0,334  0,563  0,476 
0,232  0,546  0,447 

PU 

RI 

SQ 

TR 

0,803  
0,530  0,814  
0,457  0,489  0,743  
0,405  0,350  0,538  0,835 

Note: AR= Actual Repurchase, CS= Customer Satisfaction, PEOU = 
Perceived Ease of Use, PU= Perceived Usefulness , RI= Repurchase Intention, 
SQ= System Quality, TR=Trust. 

Dalam  Tabel  III  didapati  bahwa  nilai  antar  variabel  laten 
(matrik diagonal) lebih besar dari pada dengan variabel laten 
lainnya (matrik nondiagonal). Hal ini mengindikasikan variabel 
laten  secara  empiris  berbeda  dari  variabel  laten  lain  dalam 
model struktural. 

 4 / 7 

 
 
 
 
 
 
 
 
 
 
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
C.  Analisis Inner Model 

Inner  model  menggambarkan  model  hubungan  antara 
valiabel  laten  yang  telah  dibentuk  atas  dasar  substansi  teori 
[31].  Analisis  awal  yang  dilakukan  adalah  melihat  potensi 
masalah  kolinearitas.  Uji  masalah  kolineritas  digunakan  nilai 
VIF,  jika  nilai  diatas  5  merupakan  indikasi  kemungkinan 
adanya masalah kolinearitas antara variabel bebas lainnya[27]. 
Pada  Tabel  IV  didapati  bahwa  tidak  terdapat  masalah 
kolinearitas  berat  karena  untuk  tiap  indikator  memiliki  nilai 
VIF dibawah 5. 

TABEL IV. NILAI VIF 

Indikator  VIF 

Variabel 
Laten 

Indikator  VIF 

AR 

CS 

RI 

PEOU 

AR1 
AR2 
AR3 
CS1 
CS2 
CS3 
RI1 
RI2 
RI3 
RI4 
PEOU1 
PEOU2 
PEOU3 

1,87 
2,307 
2,527 
2,106 
2,303 
1,853 
1,872 
3,136 
2,596 
1,449 
2,365 
2,918 
2,789 

PU 

SQ 

TR 

PU1 
PU2 
PU3 
PU4 
SQ1 
SQ2 
SQ3 
SQ4 
TR1 
TR2 
TR3 

1,956 
2,243 
1,743 
1,451 
1,693 
1,928 
1,37 
1,141 
1,586 
1,668 
1,661 

Pengujian hipotesis dilakukan dengan melihat nilai p-value 
atau t-statistik. Penelitian ini menggunakan tingkat signifikansi 
5%  dengan  uji  satu  arah.  Nilai  p-value  dibawah  5% 
menunjukan bahwa signifikan secara statistik. 

Dari Tabel V didapati dari 10 hipotesis yang dikembangkan 
berdasarkan  teori,  terdapat  3  hipotesis  belum  dapat  diterima 
karena tidak signifikan. 

TABEL V. 
HASIL SIGNIFIKANSI HUBUNGAN STRUCTURAL 

P
a
t
h

c
o
e
f
f
i
c
i
e
n
t
s

0,540 
0,245 
0,179 
0,241 
0,085 
0,300 
0,083 
0,413 
0,165 
-0,081 

T
S

t
a
t
i
s
t
i
c
s

9,942 
4,448 
3,060 
4,105 
1,284 
5,142 
1,517 
7,930 
2,905 
1,645 

P
V
a
l
u
e
s

0,000 
0,000 
0,001 
0,000 
0,099 
0,000 
0,0648 
0,000 
0,001 
0,0502 

H
a
s
i
l

Signifikan 
Signifikan 
Signifikan 
Signifikan 
Tidak signifikan 
Signifikan 
Tidak signifikan 
Signifikan 
Signifikan 
Tidak signifikan 

RI -> AR 
PU-> RI 
PEOU -> RI 
PU -> CS 
PEOU -> CS 
CS -> RI 
CS -> AR 
SQ  -> CS 

  SQ -> RI 
TR - >RI 

Penelitian ini melibatkan 3 variabel endogen yaitu Actual 
Repurchase,  Customer  Satisfaction,  dan  Repurchase 
Intention  dengan  nilai  R2  (Tabel  VI)  antara  0.3469  hingga 
0,4311.  Berdasarkan  literatur  didapati  bahwa  nilai  antara 
0,25  hingga  0,50  dianggap  sebagai  hubungan  sedang[27]. 
Hal  ini  dapat  diartikan  bahwa  variabel  eksogen  dalam 
penelitian  ini  mampu  menjelaskan  variabel  endogen  tidak 
terlalu tinggi tetapi tidak rendah pula (sedang). 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

TABEL VI. NILAI  R2 DAN Q2 

Actual Repurchase 
Customer Satisfaction 
Repurchase Intention 

R Square 
0.3469 
0.3825 
0.4311 

Q square 
0.2656 
0.2862 
0.2804 

Analisis  lanjutan  adalah  menilai  prediction  relevance  (Q 
square). Uji ini dilakukan untuk mengetahui seberapa baik nilai 
obeservasi  yang  dihasilkan  dengan  proses  blindfolding.  Nilai 
Q2  >  0  menunjukan  bukti  bahwa  nilai-nilai  yang  dilakukan 
observasi  sudah  direkonstruksi  dengan  baik  sehingga  model 
dapat dikatakan relevance predictif. Dari hasil analisis didapati 
bahwa  seluruh  variabel  endogen  memiliki  nilai  Q2  diatas  0 
(Tabel VI), yang berarti model sudah relevance predictive atau 
dapat  dikatakan  bahwa  model  dapat  digunakan  untuk 
memprediksi pada observasi lain dengan kondisi yang sama. 

VII. 

PEMBAHASAN 

Dari hasil analisis pada Tabel I didapati bahwa  mayoritas 
pengguna  akan  tetap  melakukan  pembelian  melalui  platform 
belanja  online  meskipun  kebijakan  mobilitas  tidak  dibatasi. 
Hanya  terdapat  1,6%  atau  7  responden  yang  tidak  lagi 
menggunakan platform belanja online di masa transisi. 

Namun  demikian,  43%  responden  menurunkan  frekuensi 
tidak 
penggunaannya  ketika  mobilitas  penduduk  sudah 
dibatasi.  Sedangkan  28% 
tidak  mengalami 
perubahan  frekuensi  penggunaan,  selebihnya  29%  justru 
mengalami peningkatan pada masa transisi ini.  

responden 

Jika  dilakukan  analisis  terhadap  98,4%  responden  yang 
berlanjut  menggunakan  platform  belanja  online  ketika 
mobilitas tidak dibatasi, didapati bahwa 158 orang atau 36,24% 
merupakan pengguna baru ketika pandemi terjadi. Sedangkan 
63,76%  sisanya  telah  menggunakan  platform  belanja  online 
sebelum  pandemi  terjadi.  Untuk  lebih  lengkap  dapat  dilihat 
pada Gambar 4.  

Gambar 4. Lama penggunaan berdasar pengguna yang berlanjut. 

Pada Tabel I dapat dilihat dari seluruh pengguna, mayoritas 
menggunakan  platform  shopee  untuk  melakukan  aktivitas 
belanja  online.  81,94%  menyatakan  bahwa  shopee  menjadi 
platform  utama  yang  digunakan  untuk  belanja  online  dan 
29,06% sisanya menggunakan platform lain seperti bukalapak, 
tokopedia, lazada dan lainnya. 

 5 / 7 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
Jika dilihat dari Gambar 5, sebelum masa transisi kategori 
barang  yang  paling  banyak  dibeli  adalah  fashion&aksesoris. 
Sedangkan  pada  masa  transisi,  kategori  yang  paling  banyak 
dibeli juga fashion&aksesoris yang berarti bahwa tidak terjadi 
perubahan minat pembelian antara sebelum masa transisi dan 
saat masa transisi. Jika ditinjau lebih jauh, yang paling banyak 
mengalami 
kategori 
kesehatan&kecantikan. 

penurunan 

pembelian 

adalah 

Gambar 5. Perbandingan kategori barang yang dibeli sebelum masa 

transisi dan saat masa transisi 

Jika  dilihat  berdasar  variabel  yang  berpengaruh,  faktor 
utama  yang  mempengaruhi  pembelian  kembali  berdasarkan 
hasil pada Tabel V adalah repurchase intention. Sehingga dapat 
dinyatakan  bahwa  meningkatnya 
intention 
signifikan  meningkatkan  actual  repurchase.  Hal  itu  sejalan 
dengan  penelitian  psikologi  yang  menyatakan  bahwa  niat 
merupakan keinginan seseorang untuk bertindak dan menurut 
theory  of  planned  behavior  dinyatakan  bahwa  perilaku 
seseorang  dipengaruhi  oleh  niat  untuk  melakukan  perilaku 
tersebut[32].  

repurchase 

(repurchase 

Berdasarkan  nilai  R2  pada  Tabel  VI,  dijelaskan  bahwa 
variabel  eksogen 
intention  dan  customer 
satisfaction)  dapat  menjelaskan  variabel  actual  repurchase 
sebesar  34,69%  dan  sisanya dijelaskan  oleh  variabel  lainnya. 
Sedangkan untuk customer satisfaction jika dilihat dari Tabel 
V, bisa dikatakan tidak secara langsung dapat  mempengaruhi 
actual repurchase karena p-value (0,064) lebih besar dari 0,05. 
Selanjutnya berdasar nilai R2 pada Tabel VI, penelitian ini 
menangkap  bahwa  variabel  repurchase 
intention  dapat 
dijelaskan  oleh  variabel  eksogennya  sebesar  43,11%  dan 
sisanya dijelaskan oleh variabel lain diluar penelitian. 

tidak 

langsung 

Niat  (intention) 

tumbuh  begitu  saja. 
Penelitian  ini  juga  melihat  bahwa  repurchase  intention 
dipengaruhi  oleh  beberapa  faktor.    Faktor  yang  berpengaruh 
menurut  hasil  dari  Tabel  V  adalah  customer  satisfaction, 
perceived ease of use, perceived usefulness dan system quality 
dengan masing-masing nilai p-value berada dibawah 0,5.  

intention 

repurchase 

Dari  beberapa  variabel  tersebut,  yang  paling  signifikan 
customer 
mempengaruhi 
satisfaction  dengan  nilai  path  coefficient  tertinggi  dibanding 
variabel  eksogen  lain  yaitu  sebesar  0,300  (Tabel  V).  Hal  ini 
sejalan dengan penelitian sebelumnya  yang menyatakan bahwa 
kepuasan pelanggan terkait penggunaan platform e-commerce 
akan mempengaruhi niat mereka untuk membeli dari platform 
tersebut [14]. 

adalah 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

Dari sisi kepuasan pelanggan, didapati bahwa faktor yang 
paling  mempengaruhinya  yaitu  system  quality  dengan  nilai 
path  coefficient  pada  Tabel  V  tertinggi  yaitu  sebesar  0,413. 
System  quality  selain  mempengaruhi  peningkatan  kepuasan 
pelanggan,  juga  mempengaruhi  repurchase  intention  secara 
langsung.  Hal  ini  sejalan  dengan  penelitian  [15],  [33]  yang 
menyatakan  bahwa  platform  belanja  online  yang  memiliki 
sistem  dengan  mutu  yang  baik  akan  berpengaruh  pada 
kepuasan  pengguna  dan  juga  dapat  mempengaruhi  niat 
keberlanjutan pelanggan. 

Variabel  lain  yang  mampu  mempengaruhi  repurchase 
intention jika dilihat pada Tabel V adalah perceived usefulness. 
Hal  itu  didasari,  sistem  yang  memiliki  usability  yang  tinggi 
dapat  meningkatkan  pengalaman  pembelian.  Selain  itu  dari 
perspektif  adopsi  teknologi,  manfaat  yang  dirasakan  menjadi 
penentu  niat  penggunaan[26].  Jika  dilihat  pada  Tabel  V 
variabel  perceived  ease  of  use,  juga  nyata  mempengaruhi 
repurchase 
ini  berkaitan  dengan 
kemudahan  yang  dirasakan,  kesederhanaan,  dan  kemudahan 
yang digunakan dalam sistem dapat menarik lebih banyak niat  
adopsi teknologi [18]. 

intention.  Variabel 

VIII.  KESIMPULAN DAN SARAN 
Berdasarkan  hasil  temuan  didapati  bahwa  mayoritas 
pengguna  yang  melakukan  pembelian  melalui  platform 
belanja  online  ketika  pandemi  tetap  akan  menggunakan 
platform tersebut meski kebijakan mobilitas penduduk sudah 
tidak  dibatasi.  Dari  hasil  analisis  hanya  didapati  1,67% 
pengguna melakukan pemberhentian aktivitas belanja online. 
Atas  hal  tersebut,  maka  penelitian  ini  mendukung  ungkapan 
bahwa  keadaan dunia setelah pandemi berbeda dari sebelum 
pandemi[10]. 

Hasil penelitian ini juga mendukung model teoritis utama 
(TAM)  yang  digunakan.  Berdasar  hasil  evaluasi  inner  model 
bahwa  model  teoritis  TAM  mampu  menjelaskan  kondisi 
keberlanjutan  platform  belanja  online  di  Indonesia.  Hasil  ini 
sejalan  dengan  penelitian[14],  mengenai 
  keberlanjutan 
aktivitas  belanja  online  di  negara  berkembang  yang 
menggunakan TAM sebagai kerangka teoritis utamanya. 

Dari  penelitian  ini  diketahui  bahwa,  faktor  yang  paling 
berpengaruh  secara  langsung pada  pembelian  kembali  adalah 
repurchase intention. Customer satisfaction juga  tidak  secara 
langsung  mempengaruhi  pembelian  kembali,  tetapi  melalui 
repurchase intention. Namun, dalam penelitian ini belum dapat 
disimpulkan  bahwa  perceived  ease  of  use  berpengaruh 
langsung  terhadap  customer  satisfaction.  Selain  itu,  variabel 
trust  juga  belum  dapat  disimpulkan  berpengaruh  terhadap 
repurchase intention. 

Penelitian  selanjutnya  dapat  mendalami  variabel-variabel 
yang  tidak  signifikan  tersebut  dalam  konteks  keberlanjutan 
penggunaan  platform  belanja  online.  Selain  itu,  penelitian 
selanjutnya  dapat  mengkajii  alasan  pengguna  berhenti 
menggunakan 
setelah 
menggunakannya selama pandemi. 

platform 

belanja 

online 

DAFTAR PUSTAKA 

[1]  G.  Dianari,  “Pengaruh  E-Commerce  Terhadap  Pertmubuhan  Ekonomi 

 6 / 7 

 
 
 
 
 
 
 
Indonesia,” Bina Ekon. Maj. Ilm. Fak. Ekon. Univ. Katolik Parahyangan, 
vol. Vol.22 No, no. Vol. 22 No. 1 (2018): Bina Ekonomi: Majalah Ilmiah 
Fakultas Ekonomi Universitas Katolik Parahyangan, pp. 43–60, 2018, doi: 
https://doi.org/10.26593/be.v22i1.3619.45-64. 

[2]  P. B. Widagdo, “Analisis Perkembangan E-commerce Dalam Mendorong 

Pertumbuhan Ekonomi Wilayah di Indonesia”. 

[3]  H. Tang et al., “Factors Affecting E-Shopping Behaviour: Application of 
Theory  of  Planned  Behaviour,”  Behav.  Neurol.,  vol.  2021,  2021,  doi: 
10.1155/2021/1664377. 

[4]  V. Frick and E. Matthies, “Everything is just a click away. Online shopping 
efficiency  and  consumption  levels  in  three  consumption  domains,” 
Sustain.  Prod.  Consum.,  vol.  23,  pp.  212–223,  2020,  doi: 
10.1016/j.spc.2020.05.002. 

[5]  J. Chu, M. Arce-Urriza, J. J. Cebollada-Calvo, and P. K. Chintagunta, “An 
Empirical  Analysis  of  Shopping  Behavior  Across  Online  and  Offline 
Channels for Grocery Products: The Moderating Effects of Household and 
Product Characteristics,” J. Interact. Mark., vol. 24, no. 4, pp. 251–268, 
2010, doi: 10.1016/j.intmar.2010.07.004. 

[6]  M.  S.  Honata,  “Industri  E-Commerce  Dalam  Menciptakan  Pasar  Yang 
Kompetitif Berdasarkan Hukum Persaingan Usaha,” J. Huk. Bisnis Bonum 
Commune, vol. I, no. 1, pp. 73–88, 2017. 

[7]  T. B. Joewono, M. Rizki, P. F. Belgiawan, and M. Z. Irawan, “Why do 
shoppers keep making online shopping trips? Learning from evidence in 
Bandung,  Indonesia,”  Asian  Transp.  Stud.,  vol.  6,  no.  May,  p.  100016, 
2020, doi: 10.1016/j.eastsj.2020.100016. 

[8]  M. A. Camilleri, “E-commerce websites, consumer order fulfillment and 
after-sales service satisfaction: the customer is always right, even after the 
shopping cart check-out,” J. Strateg. Manag., vol. 15, no. 3, pp. 377–396, 
2022, doi: 10.1108/JSMA-02-2021-0045. 

[9]  I. L. Wu, K. W. Chen, and M. L. Chiu, “Defining key drivers of online 
impulse purchasing: A perspective of both impulse shoppers and system 
users,”  Int.  J.  Inf.  Manage.,  vol.  36,  no.  3,  pp.  284–296,  2016,  doi: 
10.1016/j.ijinfomgt.2015.11.015. 

[10] T. Watanabe and Y. Omori, “Online Consumption During and After the 
COVID 19 Pandemic: Evidence from Japan,”  Cent. Res. Educ. POLICY 
Eval. Univ. TOKYO, no. 91, 2020, doi: 10.51432/978-1-8381524-8-2_4. 

[11] N.  Abdin,  M.  Mustikasari,  and  R.  Romalita,  “Sosialisasi  Mencegah 
Penyebaran Covid-19 Di Masa (New Normal),” Batuah J. Pengabdi. Kpd. 
Masy. , vol. 1, no. 2, pp. 40–44, 2021. 

[12] D. Hernikawati, “Analisis Dampak Pandemi COVID-19 terhadap Jumlah 
Kunjungan  pada  Situs  E-Commerce  di  Indonesia  Menggunakan  Uji  T 
Berpasangan,”  J. Stud. Komun. dan Media, vol. 25, no. 2, p. 191, 2021, 
doi: 10.31445/jskm.2021.4389. 

[13] A. Mishra, A. Shukla, N. P. Rana, W. L. Currie, and Y. K. Dwivedi, “Re-
examining post-acceptance model of information systems continuance: A 
revised theoretical model using MASEM approach,” Int. J. Inf. Manage., 
doi: 
vol. 
10.1016/j.ijinfomgt.2022.102571. 

no.  April 

102571, 

2023, 

2022, 

68, 

p. 

[14] V. Lee, S. Park, and D. Lee, “The Effect of E-commerce Service Quality 
Factors on Customer Satisfaction, Purchase Intention, and Actual Purchase 
in Uzbekistan,” Glob. Bus. Financ. Rev., vol. 27, no. 3, pp. 56–74, 2022, 
doi: 10.17549/gbfr.2022.27.3.56. 

[15] F. X. H. Prasetya, B. Harnadi, A. D. Widiantoro, A. N. Hidayanto, and A. 
C. Nugroho, “Investigating the impact of system and service qualities on 
customer  loyalty  in  acceptance  of  E-marketplace,”  2020  5th  Int.  Conf. 
Informatics 
doi: 
ICIC 
10.1109/ICIC50835.2020.9288597. 

Comput. 

2020, 

2020, 

[16] H.  Luo,  Y.  Yu,  X.  Han,  and  Y.  Zhang,  “The  effect  of  online  shops’ 
unexpected services on Costumer Citizenship Behaviors,” 2016 13th Int. 
Conf.  Serv.  Syst.  Serv.  Manag. 
ICSSSM  2016,  2016,  doi: 
10.1109/ICSSSM.2016.7538538. 

[17] Y.  Cho,  “A  Consumer  Satisfaction  Model  Based  on  the  eIntegration  of 

Makalah Skripsi – Program Studi D-IV Komputasi Statistik 

EDT and TAM: Comparative Study of Korean and US Consumers,” Asia 
Pacific J. Mark. Logist., vol. 34, no. 1, pp. 1–5, 2017. 

[18] M.  Salem,  K.  M.  Nor,  M.  A.  Salem,  and  K.  Md  Nor,  “The  Effect  Of 
COVID-19  On  Consumer  Behaviour  In  Saudi  Arabia:  Switching  From 
Brick And Mortar Stores To E-Commerce,” Artic. Int. J. Sci. Technol. Res., 
no. August, 2020, [Online]. Available: www.ijstr.org 

[19] A. Ngubelanga and R. Duffett, “Modeling mobile commerce applications’ 
antecedents of customer satisfaction among millennials: An extended tam 
perspective,”  Sustain.,  vol.  13,  no.  11,  pp.  1–29,  2021,  doi: 
10.3390/su13115973. 

[20] Y.  M.  Ginting,  T.  Chandra,  I.  Miran,  and  Y.  Yusriadi,  “Repurchase 
intention of e-commerce customers in Indonesia: An overview of the effect 
of  e-service  quality,  e-word  of  mouth,  customer  trust,  and  customer 
satisfaction mediation,” Int. J. Data Netw. Sci., vol. 7, no. 1, pp. 329–340, 
2022, doi: 10.5267/j.ijdns.2022.10.001. 

[21] N.  Kassim  and    nor  Asiah  Abdullah,  “The  effect  of  perceived  service 
quality  dimensions  on  customer  satisfaction,  trust,  and  loyalty  in  e-
commerce  settings:  A  cross  cultural  analysis,”  Asia  Pacific  J.  Mark. 
Logist., 
doi: 
no. 
10.1108/13555851011062269. 

351–371, 

2010, 

vol. 

pp. 

22, 

3, 

[22] T. Wiboyo, “Pengaruh Consumer Trust Dan Expectation Terhadap Online 
Repurchase Intention Melalui Customer Satisfaction Pada Situs Jual Beli 
Online Bukalapak Di Kota Yogyakarta,” J. Ekobis Dewantara, Vol. 1, No. 
9, Pp. 96–107, 2018. 

[23] W. H. DeLone and E. R. McLean, “The DeLone and McLean model of 
information systems success: A ten-year update,” J. Manag. Inf. Syst., vol. 
19, no. 4, pp. 9–30, 2003, doi: 10.1080/07421222.2003.11045748. 

[24] U.  Sharkey,  M.  Scott,  and  T.  Acton,  “The  Influence  of  Quality  on  e-
commerce success: An empirical application of the delone and Mclean is 
success Model,”  Int. J. E-bus. Res., vol. 6, no. 1, pp. 68–84, 2010, doi: 
10.4018/jebr.2010100905. 

[25] Gefen and Straub, “Managing User Trust in B2C e-Services,” e-Service J., 

vol. 2, no. 2, p. 7, 2003, doi: 10.2979/esj.2003.2.2.7. 

[26] Y.  W.  Sullivan  and  D.  J.  Kim,  “Assessing  the  effects  of  consumers’ 
product  evaluations  and  trust  on  repurchase  intention  in  e-commerce 
environments,” Int. J. Inf. Manage., vol. 39, no. December 2017, pp. 199–
219, 2018, doi: 10.1016/j.ijinfomgt.2017.12.008. 

[27] J. F. Hair Jr, G. T. M. Hult, C. M. R. Ringle, M. Sarstedt, N. P. Danks, and 
S.  Ray,  Review  of  Partial  Least  Squares  Structural  Equation  Modeling 
(PLS-SEM) Using R. 2022. doi: 10.1080/10705511.2022.2108813. 

[28] I.  Adaji  and  J.  Vassileva,  “Perceived  Effectiveness,  Credibility  and 
Continuance Intention in E-commerce: A Study of Amazon,” Springer Int. 
Publ. AG, vol. 10171 LNCS, pp. 293–306, 2017, doi: 10.1007/978-3-319-
55134-0. 

[29] Irwan  et  al.,  “METODE  PARTIAL  LEAST  SQUARE  (PLS)  DAN 
TERAPANNYA  (Studi  Kasus:  Analisis  Kepuasan  Pelanggan  terhadap 
Layanan  PDAM  Unit Camming  Kab.  Bone),”  JurnalTeknosains,  vol.  9, 
no. 1, pp. 53–68, 2015. 

[30] M. R. Miah, A. Hossain, R. Shikder, T. Saha, and M. Neger, “Evaluating 
the impact of social media on online shopping behavior during COVID-19 
pandemic: A Bangladeshi consumers’ perspectives,”  Heliyon, vol. 8, no. 
9, p. e10600, 2022, doi: 10.1016/j.heliyon.2022.e10600. 

[31] H. Siagian and E. Cahyono, “Analisis Website Quality, Trust Dan Loyalty 
Pelanggan  Online  Shop,”  J.  Manaj.  Pemasar.,  vol.  8,  no.  2,  pp.  55–61, 
2014, doi: 10.9744/pemasaran.8.2.55-61. 

[32] R.  Faridawati  and  M.  Silvy,  “Pengaruh  niat  berperilaku  dan  kecerdasan 
spiritual terhadap pengelolaan keuangan keluarga,” J. Bus. Bank., vol. 7, 
no. 1, 2019, doi: 10.14414/jbb.v7i1.1465. 

[33] N. W. Masri, J. J. You, A. Ruangkanjanases, S. C. Chen, and C. I. Pan, 
“Assessing  the  effects  of  information  system  quality  and  relationship 
quality on continuance intention in e-tourism,” Int. J. Environ. Res. Public 
Health, vol. 17, no. 1, 2020, doi: 10.3390/ijerph17010174. 

 7 / 7 

 
 
 
","2023-12-19T09:09:43.134820Z",221910692,"[{""start"":792,""end"":943,""text"":""au\\nja"",""labels"":[""Tujuan""]},{""start"":1181,""end"":1300,""text"":""ban tidak valid.\\n\\n3 \/ 7\\n\\n\\n\\n\\n\\n\\n\fMakalah Skripsi – Program Studi D-IV Komputasi Statistik\\n\\nData mengenai karakteristik responden dijelaskan dalam\\nTabel I. Karakteristik responden yang tertangkap dari\\nini, mayoritas merupakan wanita dengan\\npenelitian\\npersentase 72,36 persen. Gen Z menjadi kategori umur\\nterbanyak yang menggunakan platform belanja online.\\n\\nJika dilihat dari jenis pekerjaan, maka mayoritas\\nresponden adalah pelajar\/mahasiswa dengan lokasi tinggal\\nmayoritas berada di Pulau Jawa dengan 82,84 persen.\\n\\nJika dilihat dari nilai AVE, setiap variabel memiliki nilai\\ndiatas 0.5 yang berarti indikator dan variabel yang digunakan\\ndalam penelitian ini dapat dikatakan memenuhi prasyarat\\nuntuk validitas konvergen[14].\\n\\nTABEL II.\\nNILAI OUTER LOADING(OL), AVE, COMPOSITE RELIABILITY (CR),\\nCRONBACH’S ALPHA (CA)\\n\\nNo\\n\\nVariabel\\nLaten\\n\\nIndikator OL\\n\\nCR\\n\\nCA\\n\\nAVE\\n\\n%\\n\\n82,84\\n7,90\\n2,48\\n2,03\\n3,16\\n0,90\\n0,67\\n\\nVariabel\\nGender\\nPerempuan\\nLaki-Laki\\nUmur\\nGen Z\\nMilenial\\nGen X\\nBaby Boomer\\nTidak Valid\\n\\nTABEL I.\\nKARAKTERISTIK RESPONDEN\\n\\n%\\n\\n72,46\\n27,54\\n\\nVariabel\\nTempat Tinggal\\nJawa\\nSumatera\\nBali\/NTB\/NTT\\n\\nSulawesi\\n\\n69,07 Kalimantan\\n13,77\\n13,77 Maluku\\n1,13\\n2,26\\n\\nPlatform Belanja Online\\nUtama\\n\\nShopee\\nBukalapak\\nTokopedia\\nLazada\\nLainnya\\nPekerjaan\\n\\nMengurus Rumah\\nTangga\\nPelajar\/Mahasiswa\\nPegawai Negeri Sipil\\n(PNS)\\nKaryawan Swasta\\nWirausaha\\nBelum\/Tidak Bekerja\\n\\nPapua\\nPertama Kali Menggunakan\\nPlatform Belanja Online\\nKurang dari 1 Tahun\\nTerakhir\\n\\n2,71\\n\\n81,94\\n0,68\\n13,31\\n1,59\\n2,48\\n\\n1 Tahun Lalu\\n2 Tahun Lalu\\n3 Tahun Lalu\\n4 Tahun Lalu\\n5 Tahun Lalu\\nLebih Dari 5 Tahun\\n\\n3,84\\n11,74\\n18,74\\n18,96\\n12,64\\n31,38\\n\\n6,32\\n\\nKeberlanjutan Penggunaan\\nPlatform Belanja Online\\n\\n53,50 Berlanjut\\n11,96 Tidak Berlanjut\\n\\n98,4\\n1,6\\n\\n19,41\\n2,71\\n6,09\\n\\nB. Analisis Outer Model\\n\\nEvaluasi outer model digunakan untuk melihat validitas\\ndan reliabilitas untuk tiap variabel[29]. Tahap pertama\\nadalah menilai validitas konvergen dengan meninjau dua\\nnilai yaitu outer loading dan AVE dengan nilai tergolong\\nvalid jika masing masing memiliki nilai lebih dari 0,7 dan\\n0,5 [28]. Selanjutnya diuji internal consistency reliability\\ndengan melihat nilai Composite Reliability dan Cronbach’s\\nalpha dengan nilai minimum yang diterima untuk\\nCronbach’s alpha adalah 0.7[30]. Analisis terakhir adalah\\nmenilai diskriman validity melalui tabel Fornell and Larckers\\ndengan membandingkan nilai antar variabel laten (matrik\\n(matrik\\ndan\\ndiagonal)\\nnondiagonal)[18].\\n\\nvariabel\\n\\nlainnya\\n\\nlaten\\n\\nDari hasil pada Tabel II didapati bahwa hanya terdapat\\nsatu indikator yang memiliki nilai outer loading di bawah\\n0,7. Pada penelitian ini, didapati bahwa indikator tersebut\\ntetap digunakan karena dengan menghilangkan SQ4 tidak\\nsignifikan mengubah nilai AVE dan Composite Reliability.\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\nActual\\nRepurchase\\n\\nCustomer\\nSatisfaction\\n\\nRepurchase\\nIntention\\n\\nPerceived\\nEase of Use\\n\\nPerceived\\nUsefulness\\n\\nSystem\\nQuality\\n\\n7\\n\\nTrust\\n\\nAR1\\nAR2\\nAR3\\nCS1\\nCS2\\nCS3\\nRI1\\nRI2\\nRI3\\nRI4\\nPEOU1\\nPEOU2\\nPEOU3\\nPU1\\nPU2\\nPU3\\nPU4\\nSQ1\\nSQ2\\nSQ3\\nSQ4\\nTR1\\nTR2\\nTR3\\n\\n0,86\\n0,882\\n0,903\\n0,87\\n0,892\\n0,862\\n0,753\\n0,895\\n0,879\\n0,716\\n0,891\\n0,916\\n0,913\\n0,825\\n0,862\\n0,798\\n0,721\\n0,771\\n0,841\\n0,726\\n0,616\\n0,82\\n0,819\\n0,865\\n\\n0,913\\n\\n0,857\\n\\n0,777\\n\\n0,907\\n\\n0,846\\n\\n0,765\\n\\n0,887\\n\\n0,827\\n\\n0,663\\n\\n0,933\\n\\n0,892\\n\\n0,822\\n\\n0,879\\n\\n0,815\\n\\n0,645\\n\\n0,83\\n\\n0,722\\n\\n0,552\\n\\n0,874\\n\\n0,785\\n\\n0,698\\n\\nPada pengujian internal consistency reliability, dari hasil\\nanalisis didapati bahwa nilai composite reliability berada antara\\n0.830 hingga 0.933 yang berarti baik dan memuaskan[27]. Pada\\nTabel II juga didapati bahwa semua nilai Cronbach’s alpha\\nberada diatas 0,7 yang berarti variabel laten dikatakan reliable\\nuntuk menilai konsistensi hasil di seluruh item pada penelitian\\nini[27].\\n\\nTABEL III.\\n\\nTABEL FORNELL-LARCKER\\n\\nVariabel\\nLaten\\nAR\\nCS\\nPEOU\\nPU\\nRI\\nSQ\\nTR\\n\\nCS\\n\\nPEOU\\n\\nAR\\n0,882\\n0,375 0,875\\n0,361 0,415 0,907\\n0,432 0,476 0,553\\n0,585 0,540 0,481\\n0,334 0,563 0,476\\n0,232 0,546 0,447\\n\\nPU\\n\\nRI\\n\\nSQ\\n\\nTR\\n\\n0,803\\n0,530 0,814\\n0,457 0,489 0,743\\n0,405 0,350 0,538 0,835\\n\\nNote: AR= Actual Repurchase, CS= Customer Satisfaction, PEOU =\\nPerceived Ease of Use, PU= Perceived Usefulness , RI= Repurchase Intention,\\nSQ= System Quality, TR=Trust.\\n\\nDalam Tabel III didapati bahwa nilai antar variabel laten\\n(matrik diagonal) lebih besar dari pada dengan variabel laten\\nlainnya (matrik nondiagonal). Hal ini mengindikasikan variabel\\nlaten secara empiris berbeda dari variabel laten lain dalam\\nmodel struktural.\\n\\n4 \/ 7\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\fC. Analisis Inner Model\\n\\nInner model menggambarkan model hubungan antara\\nvaliabel laten yang telah dibentuk atas dasar substansi teori\\n[31]. Analisis awal yang dilakukan adalah melihat potensi\\nmasalah kolinearitas. Uji masalah kolineritas digunakan nilai\\nVIF, jika nilai diatas 5 merupakan indikasi kemungkinan\\nadanya masalah kolinearitas antara variabel bebas lainnya[27].\\nPada Tabel IV didapati bahwa tidak terdapat masalah\\nkolinearitas berat karena untuk tiap indikator memiliki nilai\\nVIF dibawah 5.\\n\\nTABEL IV. NILAI VIF\\n\\nIndikator VIF\\n\\nVariabel\\nLaten\\n\\nIndikator VIF\\n\\nAR\\n\\nCS\\n\\nRI\\n\\nPEOU\\n\\nAR1\\nAR2\\nAR3\\nCS1\\nCS2\\nCS3\\nRI1\\nRI2\\nRI3\\nRI4\\nPEOU1\\nPEOU2\\nPEOU3\\n\\n1,87\\n2,307\\n2,527\\n2,106\\n2,303\\n1,853\\n1,872\\n3,136\\n2,596\\n1,449\\n2,365\\n2,918\\n2,789\\n\\nPU\\n\\nSQ\\n\\nTR\\n\\nPU1\\nPU2\\nPU3\\nPU4\\nSQ1\\nSQ2\\nSQ3\\nSQ4\\nTR1\\nTR2\\nTR3\\n\\n1,956\\n2,243\\n1,743\\n1,451\\n1,693\\n1,928\\n1,37\\n1,141\\n1,586\\n1,668\\n1,661\\n\\nPengujian hipotesis dilakukan dengan melihat nilai p-value\\natau t-statistik. Penelitian ini menggunakan tingkat signifikansi\\n5% dengan uji satu arah. Nilai p-value dibawah 5%\\nmenunjukan bahwa signifikan secara statistik.\\n\\nDari Tabel V didapati dari 10 hipotesis yang dikembangkan\\nberdasarkan teori, terdapat 3 hipotesis belum dapat diterima\\nkarena tidak signifikan.\\n\\nTABEL V.\\nHASIL SIGNIFIKANSI HUBUNGAN STRUCTURAL\\n\\nP\\na\\nt\\nh\\n\\nc\\no\\ne\\nf\\nf\\ni\\nc\\ni\\ne\\nn\\nt\\ns\\n\\n0,540\\n0,245\\n0,179\\n0,241\\n0,085\\n0,300\\n0,083\\n0,413\\n0,165\\n-0,081\\n\\nT\\nS\\n\\nt\\na\\nt\\ni\\ns\\nt\\ni\\nc\\ns\\n\\n9,942\\n4,448\\n3,060\\n4,105\\n1,284\\n5,142\\n1,517\\n7,930\\n2,905\\n1,645\\n\\nP\\nV\\na\\nl\\nu\\ne\\ns\\n\\n0,000\\n0,000\\n0,001\\n0,000\\n0,099\\n0,000\\n0,0648\\n0,000\\n0,001\\n0,0502\\n\\nH\\na\\ns\\ni\\nl\\n\\nSignifikan\\nSignifikan\\nSignifikan\\nSignifikan\\nTidak signifikan\\nSignifikan\\nTidak signifikan\\nSignifikan\\nSignifikan\\nTidak signifikan\\n\\nRI -> AR\\nPU-> RI\\nPEOU -> RI\\nPU -> CS\\nPEOU -> CS\\nCS -> RI\\nCS -> AR\\nSQ -> CS\\n\\nSQ -> RI\\nTR - >RI\\n\\nPenelitian ini melibatkan 3 variabel endogen yaitu Actual\\nRepurchase, Customer Satisfaction, dan Repurchase\\nIntention dengan nilai R2 (Tabel VI) antara 0.3469 hingga\\n0,4311. Berdasarkan literatur didapati bahwa nilai antara\\n0,25 hingga 0,50 dianggap sebagai hubungan sedang[27].\\nHal ini dapat diartikan bahwa variabel eksogen dalam\\npenelitian ini mampu menjelaskan variabel endogen tidak\\nterlalu tinggi tetapi tidak rendah pula (sedang).\\n\\nMakalah Skripsi – Program Studi D-IV Komputasi Statistik\\n\\nTABEL VI. NILAI R2 DAN Q2\\n\\nActual Repurchase\\nCustomer Satisfaction\\nRepurchase Intention\\n\\nR Square\\n0.3469\\n0.3825\\n0.4311\\n\\nQ square\\n0.2656\\n0.2862\\n0.2804\\n\\nAnalisis lanjutan adalah menilai prediction relevance (Q\\nsquare). Uji ini dilakukan untuk mengetahui seberapa baik nilai\\nobeservasi yang dihasilkan dengan proses blindfolding. Nilai\\nQ2 > 0 menunjukan bukti bahwa nilai-nilai yang dilakukan\\nobservasi sudah direkonstruksi dengan baik sehingga model\\ndapat dikatakan relevance predictif. Dari hasil analisis didapati\\nbahwa seluruh variabel endogen memiliki nilai Q2 diatas 0\\n(Tabel VI), yang berarti model sudah relevance predictive atau\\ndapat dikatakan bahwa model dapat digunakan untuk\\nmemprediksi pada observasi lain dengan kondisi yang sama.\\n\\nVII.\\n\\nPEMBAHASAN\\n\\nDari hasil analisis pada Tabel I didapati bahwa mayoritas\\npengguna akan tetap melakukan pembelian melalui platform\\nbelanja online meskipun kebijakan mobilitas tidak dibatasi.\\nHanya terdapat 1,6% atau 7 responden yang tidak lagi\\nmenggunakan platform belanja online di masa transisi.\\n\\nNamun demikian, 43% responden menurunkan frekuensi\\ntidak\\npenggunaannya ketika mobilitas penduduk sudah\\ndibatasi. Sedangkan 28%\\ntidak mengalami\\nperubahan frekuensi penggunaan, selebihnya 29% justru\\nmengalami peningkatan pada masa transisi ini.\\n\\nresponden\\n\\nJika dilakukan analisis terhadap 98,4% responden yang\\nberlanjut menggunakan platform belanja online ketika\\nmobilitas tidak dibatasi, didapati bahwa 158 orang atau 36,24%\\nmerupakan pengguna baru ketika pandemi terjadi. Sedangkan\\n63,76% sisanya telah menggunakan platform belanja online\\nsebelum pandemi terjadi. Untuk lebih lengkap dapat dilihat\\npada Gambar 4.\\n\\nGambar 4. Lama penggunaan berdasar pengguna yang berlanjut.\\n\\nPada Tabel I dapat dilihat dari seluruh pengguna, mayoritas\\nmenggunakan platform shopee untuk melakukan aktivitas\\nbelanja online. 81,94% menyatakan bahwa shopee menjadi\\nplatform utama yang digunakan untuk belanja online dan\\n29,06% sisanya menggunakan platform lain seperti bukalapak,\\ntokopedia, lazada dan lainnya.\\n\\n5 \/ 7\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\fJika dilihat dari Gambar 5, sebelum masa transisi kategori\\nbarang yang paling banyak dibeli adalah fashion&aksesoris.\\nSedangkan pada masa transisi, kategori yang paling banyak\\ndibeli juga fashion&aksesoris yang berarti bahwa tidak terjadi\\nperubahan minat pembelian antara sebelum masa transisi dan\\nsaat masa transisi. Jika ditinjau lebih jauh, yang paling banyak\\nmengalami\\nkategori\\nkesehatan&kecantikan.\\n\\npenurunan\\n\\npembelian\\n\\nadalah\\n\\nGambar 5. Perbandingan kategori barang yang dibeli sebelum masa\\n\\ntransisi dan saat masa transisi\\n\\nJika dilihat berdasar variabel yang berpengaruh, faktor\\nutama yang mempengaruhi pembelian kembali berdasarkan\\nhasil pada Tabel V adalah repurchase intention. Sehingga dapat\\ndinyatakan bahwa meningkatnya\\nintention\\nsignifikan meningkatkan actual repurchase. Hal itu sejalan\\ndengan penelitian psikologi yang menyatakan bahwa niat\\nmerupakan keinginan seseorang untuk bertindak dan menurut\\ntheory of planned behavior dinyatakan bahwa perilaku\\nseseorang dipengaruhi oleh niat untuk melakukan perilaku\\ntersebut[32].\\n\\nrepurchase\\n\\n(repurchase\\n\\nBerdasarkan nilai R2 pada Tabel VI, dijelaskan bahwa\\nvariabel eksogen\\nintention da"",""labels"":[""Temuan""]},{""start"":1322,""end"":1378,""text"":""cust"",""labels"":[""Temuan""]},{""start"":1129,""end"":1136,""text"":"""",""labels"":[""Metode""]},{""start"":7062,""end"":7103,""text"":"""",""labels"":[""Metode""]},{""start"":13508,""end"":13525,""text"":"""",""labels"":[""Metode""]},{""start"":28573,""end"":28776,""text"":""mayoritas\\npengguna yang melakukan pembelian melalui platform\\nbelanja online ketika pandemi tetap akan menggunakan\\nplatform tersebut meski kebijakan mobilitas penduduk sudah\\ntidak dibatasi"",""labels"":[""Temuan""]},{""start"":29155,""end"":29263,""text"":"" model teoritis TAM mampu menjelaskan kondisi\\nkeberlanjutan platform belanja online di Indonesia"",""labels"":[""Temuan""]}]",1088.876,"2023-12-19T09:10:33.400217Z"
10,"1","Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Analisis Kebutuhan dan Perancangan Prototipe 
Sistem Informasi Reviu Laporan Keuangan pada 
Inspektorat Utama BPS RI Menggunakan 
Pendekatan User Centered Design 

Syahrul Toha Saputra (221910696, 4SI2) 
Dosen Pembimbing: Nori Wilantika, S.S.T., M.T.I. 

Ringkasan—  Inspektorat  Utama  selaku  auditor 

internal 
bertugas  melakukan  reviu  laporan  keuangan  dari  tiap  satuan 
kerja  BPS  sebelum  diserahkan  kepada  BPK.  Selama  ini  belum 
ada  sistem  informasi  khusus  untuk  melakukan  proses  tersebut 
dan  hanya  mengandalkan  google  spreadsheet  sebagai  pengolah 
data, google sites sebagai dashboard, dan google data studio untuk 
monitoring. Permasalahan utama adalah keamanan, dikarenakan 
dashboard sementara tidak adanya fitur login sehingga siapa saja 
yang mempunyai link dashboard bisa masuk dan mengakses data 
di  dalamnya.  Oleh  karena  itu  untuk  mengatasi  permasalahan 
analisis  kebutuhan  dan 
tersebut  dilakukan  penelitian 
perancangan  prototipe  sistem  informasi  reviu  keuangan dengan 
pendekatan  User  Centered  Design,  dengan 
implementasi 
melakukan perancangan prototipe aplikasi berbasis web. Untuk 
oleh 
evaluasi  menggunakan  metode 
narasumber. Penelitian ini dilakukan dalam dua siklus. Penelitian 
siklus  kedua  dilakukan  berdasarkan  hasil  evaluasi  hasil  siklus 
pertama. Hasil yang diperoleh dari penelitian ini adalah dokumen 
pengembangan  sistem  berupa  Product  Requirement  Document 
(PRD)  dan  Functional  Specification  Development  (FSD),  serta 
prototipe  aplikasi  berbasis  web  dengan  sistem  login  untuk  tiap 
role pengguna. 
Kata Kunci— Laporan Keuangan, UCD, Prototipe. 

langsung 

evaluasi 

I.  LATAR BELAKANG 

Badan  Pusat  Statistik  (BPS)  adalah  salah  satu  Lembaga 
Pemerintah Nonkementrian (LPNK) yang berada di bawah dan 
bertanggung  jawab  langsung  kepada  presiden.  Sebagai  salah 
tugas  untuk 
satu  Lembaga  Eksekutif  yang  mempunyai 
menjalankan pemerintahan  maka  BPS  mempunyai  kewajiban 
untuk  menyusun  Laporan  Keuangan 
sebagai  bentuk 
pertanggungjawaban kepada anggaran yang telah diberikan. 

Lembaga  pemerintah  baru  diwajibkan  untuk  menyusun 
laporan  keuangan  pada  tahun  2004,  dikarenakan  undang-
undang  yang  mengatur  baru  dikeluarkan  tahun  2003  yaitu 
Undang-Undang  Republik  Indonesia  Nomor  17  tahun  2003 
tentang Keuangan Negara. Undang–undang tersebut pada pasal 
9 tepatnya pada poin g menyatakan bahwa  Menteri/pimpinan 
lembaga  sebagai  Pengguna  Anggaran/  Pengguna  Barang 
kementerian  negara/lembaga  yang  dipimpinnya  mempunyai 
tugas  yaitu  menyusun  dan  menyampaikan  laporan  keuangan 
kementerian  negara/lembaga  yang  dipimpinnya[1].  Sebelum 
adanya  UU  RI  No  17  tahun  2003,  laporan  keuangan  hanya 
disusun oleh perusahaan sebagai pertanggungjawaban  kepada 
para  pemegang  saham.  Lembaga  pemerintah  masih  terlalu 

untuk 

menggunakan 

tanpa 
berkuasa 
pertanggungjawaban yang jelas. Dikarenakan adanya tuntutan 
untuk transparasi terhadap lembaga pemerintah maka undang–
undang tersebut dikeluarkan. 

APBN 

Laporan Keuangan disusun dari tiap Satuan Kerja (Satker) 
BPS yang terdiri atas kantor BPS tiap kabupaten/kota, provinsi, 
hingga pusat, Sekretariat Utama, Pusdiklat BPS, dan Politeknik 
Statistika STIS, kemudian wilayah, sehingga menjadi Laporan 
Keuangan  satu  instansi  yaitu  BPS.  Laporan  Keuangan  ini 
kemudian akan diserahkan kepada Badan Pemeriksa Keuangan 
(BPK) untuk diperiksa dan diserahkan hasilnya kepada Dewan 
Perwakilan  Rakyat  (DPR)  selaku  lembaga  legislatif  yang 
mempunyai  tugas  untuk  mengawasi  jalannya  pemerintahan. 
Hal  tersebut  bisa  dilihat  pada  pasal  30  ayat  1  yang  berbunyi 
Presiden  menyampaikan  rancangan  undang-undang  tentang 
pertanggungjawaban pelaksanaan APBN kepada  DPR berupa 
laporan keuangan yang telah diperiksa oleh Badan Pemeriksa 
Keuangan,  selambat-lambatnya  6  (enam)  bulan  setelah  tahun 
anggaran berakhir[1]. 

Setiap  lembaga  pemerintah  diwajibkan  untuk  mempunyai 
auditor  internal  yang  bertugas  memeriksa  laporan  keuangan 
sebelum diserahkan kepada BPK selaku auditor eksternal. Pada 
BPS peran auditor internal dijalankan oleh Inspektorat Utama. 
BPK  tidak  perlu  memeriksa  laporan  keuangan  di  tiap  satuan 
kerja, hanya perlu melihat laporan keuangan dari Instansi BPS 
yang disusun oleh  inspektorat  utama.  Jika  didapatkan  sebuah 
temuan  maka  BPK  baru  akan  menelusuri  temuan  tersebut 
hingga ke laporan keuangan tiap satuan kerja BPS. 

Selama ini belum ada aplikasi khusus yang dikembangkan 
untuk  reviu  laporan  keuangan  di  Inspektorat  Utama.  Sistem 
yang  ada  sementara  menggunakan  google  sites,  google 
spreadsheet,  dan  google  data  studio  dengan  keamanan  yang 
masih kurang. Selain itu juga terdapat permasalahan lain yaitu 
kurangnya  dokumentasi  dalam  pengembangan  sistem  di  BPS 
sehingga  menyulitkan  untuk  melakukan  pengembangan 
berkelanjutan. 

II.  TUJUAN PENELITIAN 

Berdasarkan latar belakang di atas tujuan dari penelitian ini 

adalah sebagai berikut: 
1.  Menganalisis  kebutuhan  dan  merancang  spesifikasi 
sistem  reviu  laporan  keuangan  di  Inspektorat  Utama 
Badan Pusat Statistik Republik Indonesia. 

 1 / 8 

 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

akhir  belum  sesuai  dengan  kebutuhan  pengguna.  Pada 
penelitian ini dilakukan iterasi dengan dua siklus. Metode UCD 
ini  sangat  bergantung  kepada  narasumber  atau  pengguna, 
adapun narasumber pada penelitian ini dijelaskan pada tabel 1. 

TABEL I 
DAFTAR NARASUMBER 

Nama 
(1) 

Nurjannah Fitriany, S.S.T. 

Vony Wahyunurani S.S.T.,  
M.S.A 

Putu Hadi Purnama Jati  
S.S.T., M.Sc 

Jabatan 
(2) 
Auditor Pertama Inspektorat Utama BPS 
RI 
Perencana Muda Inspektorat Utama BPS 
RI 

Tim IT Inspektorat Utama BPS RI 

Berdasarkan ISO 13407:1999 terdapat empat tahapan utama 
dalam  UCD  yaitu  Understand  &  Specify  the  Context  of  Use 
(Memahami  dan  Menentukan  Konteks  Penggunaan),  Specify 
User  and  Organizational  Requirements 
(Menentukan 
Kebutuhan  Pengguna  dan  Organisasi),  Produce  Design 
Solutions (Pengembangan Solusi Desain), dan Evaluate Design 
againts  Requirements  (Evaluasi  Desain).  Alur  penelitian 
digambarkan pada gambar 1 beserta penjelasannya di bawah. 

2.  Merancang  prototipe  sistem  reviu  laporan  keuangan 
berdasarkan hasil analisis dan rancangan spesifikasi. 

3.  Mendokumentasikan 

dan 
kebutuhan, 
prototipe  sistem  reviu  laporan  keuangan  ke  dalam  
Product  Requirement  Document  (PRD)  dan  Functional 
Specification Development (FSD). 

spesifikasi, 

4.  Mengevaluasi  hasil  analisis  kebutuhan  dan  perancangan 
sistem berupa PRD dan FSD, serta prototipe aplikasi reviu 
laporan keuangan. 

Perancangan  dan  pengembangan  prototipe  aplikasi  Sistem 
Reviu  Laporan  Keuangan  menggunakan  pendekatan  User 
Centered  Design.  Metode  ini  mempunyai  aspek  utama  yaitu 
keterlibatan  pengguna  dalam  proses  perancangan  dan 
pengembangan  sehingga  diharapkan  prototipe  sistem  yang 
dibuat bisa memenuhi kebutuhan pengguna khususnya bagi tim 
reviu  laporan  keuangan  Inspektorat  Utama  maupun  Satuan 
Kerja.  

III. PENELITIAN TERKAIT 

Beberapa  penelitian 

terdahulu  yang  berkaitan  dengan 

prototipe 

pengembangan 

penelitian yang akan dilakukan diurakan sebagai berikut. 
1.  Dalam jurnal ini dilakukan penelitian terkait perancangan 
dan 
informasi 
manajemen  program  studi  informatika  menggunakan 
pendekatan  User  Centered  Design  (UCD).  Prototipe 
merupakan  perancangan 
tampilan  antarmuka  yang 
mewakili  nilai  produk  yang  akan  dibangun.  Dengan 
telah  dibangun  maka  akan 
adanya  prototipe  yang 
lain  untuk  melanjutkan 
mempermudah  programmer 
proses front end maupun back end developing[2]. 

sistem 

ini 

jurnal 

penelitian 

2.  Dalam 

terkait 
dilakukan 
pengembangan  prototipe  dengan  pendekatan  User 
Centered Design (UCD). Dalam penelitian ini disebutkan 
metode  UCD  terdiri  dari  empat  tahap  yaitu  Specify  the 
context  of  use,  Specify  User  and  Organizational 
Requirements,  Design  Solutions,  dan  Evaluate  Againts 
Requirements. Dalam penelitian ini juga dijelaskan secara 
lengkap metodologi dan hasil dari tiap tahapan UCD[3]. 
3.  Pada  penelitian  ini  dilakukan  analisis  sistem  berjalan, 
analisis proses bisnis, analisis permasalahan, dan analisis 
kebutuhan  yang  menjadi 
rujukan  penulis  dalam 
melakukan  tahap  pertama  UCD.  Penelitian  ini  juga 
terdapat  diagram  use  case,  activity  diagram,  serta 
rancangan antarmuka yang menjadi rujukan peneliti[4]. 

IV. METODE PENELITIAN  
Metode pengembangan prototipe yang akan dipakai peneliti 
dalam  penelitian  ini  adalah  metode  User  Centered  Design 
(UCD). Metode UCD dianggap paling tepat dalam penelitian 
ini  dikarenakan  UCD  mempunyai  aspek  utama,  yaitu 
keterlibatan  pengguna  pada  keseluruhan  proses  perancangan 
dan  pengembangan  prototipe,  atau  bisa  dikatakan  bahwa 
prototipe  yang  akan  dibuat  berorientasi  terhadap  kebutuhan 
pengguna[2]. Hasil perancangan dan pengembangan prototipe 
sistem  reviu  laporan  keuangan  diharapkan  akan  sesuai  dan 
dapat  memenuhi  setiap  kebutuhan  pengguna.  Metode 
pengembangan dengan UCD bisa terjadi dalam beberapa siklus, 
dikarenakan pada metode UCD dapat terjadi iterasi jika hasil 

Gambar 1. Diagram alur penelitian 

 2 / 8 

 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Functional 

penyusunan 

masalah  dan  kebutuhan  kemudian  menuliskannya  menjadi 
dokumen  Product  Requirement  Document (PRD)  yang  berisi 
antara  lain  Business  Needs  dan  Daftar  Pengguna.  Serta 
dilakukan 
Specification 
Document (FSD) yang berisi Deskripsi Sistem, Ruang Lingkup 
Sistem, Kebutuhan Fungsional, User Acces Matrix, Use Case 
& Business Proces, Sequence Diagram, serta Wireframe. Dan 
pada  akhirnya  akan  dilakukan  perancangan  prototipe  aplikasi 
reviu  laporan  keuangan  berbasis  web.  Selanjutnya  dilakukan 
evaluasi terhadap PRD dan FSD serta prototipe dengan evaluasi 
langsung dengan narasumber. 

A.  Menentukan Konteks Penggunaan 
Tahap  pertama  dalam  UCD  adalah  menentukan  konteks 
penggunaan  sistem.  Pada  tahap  ini  harus  dipastikan  siapa 
pengguna sistem, tugas apa yang harus dijalankan sistem, serta 
perangkat  apa  yang  akan  digunakan  untuk  mengakses  sistem 
dan  jenis  aplikasi  sistem[5].  Pada  tahap  ini  akan  dihasilkan 
Deskripsi  Sistem,  Ruang  Lingkup  Sistem,  Daftar  Pengguna, 
serta Analisis Sistem Berjalan. Untuk mencapai tujuan tersebut 
pada  tahap  ini  dilakukan  pengumpulan  data  tentang  sistem 
informasi reviu laporan keuangan. Metode pengumpulan data 
yang  dilakukan  peneliti  adalah  dengan  studi 
literatur, 
wawancara  dengan  narasumber  pegawai  Inspkektorat  Utama 
BPS, serta observasi terhadap sistem yang ada. Hal – hal yang 
ditanyakan  saat  wawancara  antara  lain  proses  bisnis  sistem, 
permasalahan, serta aktor yang terlibat. 

tahap 

ini  dilakukan  wawancara 

B.  Menentukan Kebutuhan Pengguna dan Organisasi 
Tahap  kedua  adalah  menentukan  kebutuhan  pengguna  dan 
organisasi.  Tahap  ini  mempunyai  tujuan  untuk  menganalisis 
kebutuhan  fungsional  sistem  sehingga  kebutuhan  pengguna 
dan kebutuhan organisasi dapat tergambarkan dengan jelas[5]. 
Pada 
lanjutan  terhadap 
narasumber  terkait  tentang  sistem  reviu  keuangan  sehingga 
peneliti  mendapatkan  bahan untuk  melakukan  analisis  sistem 
berjalan dan analisis kebutuhan. Topik wawancara dalam tahap 
ini adalah konfirmasi terkait diagram  use case, proses bisnis, 
serta hal lain yang belum tercakup di wawancara sebelumnya. 
Pada  tahap  ini  dihasilkan  analisis  kebutuhan  yang  terdiri 
antara lain Analisis Kebutuhan Fungsional, User Acces Matrix, 
& Business Needs (Keperluan Bisnis). Selain itu pada tahap ini 
juga  akan  dilakukan  penyusunan  Use  Case,  Business  Proces 
Diagram, dan Sequence Diagram. Hasil dari analisis kebutuhan 
sistem pada tahap ini dan tahap sebelumnya akan dituangkan 
ke  dalam  Product  Requirement  Document  (PRD)  dan 
Functional Specification Development (FSD). 

C.  Pengembangan Solusi Desain 
Tahap  ketiga  adalah  pengembangan 

solusi  desain. 
Berdasarkan  hasil  analisis  sistem  dan  kebutuhan  di  tahap 
sebelumnya, pada  tahap  ini  dilakukan  penyusunan  wireframe 
yang merupakan kerangka dari suatu website. Setelah itu akan 
dilakukan  pengembangan  prototipe  aplikasi  berbasis  web 
menggunakan  framework  PHP  Laravel  dan  framework  CSS 
Tailwind. 

D.  Evaluasi Desain 
Pada  tahap  ini  akan  dilakukan  evaluasi  terhadap  hasil 
analisis  kebutuhan  sistem  yang  berupa  Product  Requirement 
Document  (PRD)  dan  Functional  Specification  Development 
(FSD).  Selain  itu  juga  akan  dilakukan  evaluasi  terhadap 
prototipe  yang  telah  dibangun.  Metode  evaluasi  yang  akan 
digunakan  adalah  evaluasi  dengan  menerima  saran  dan 
masukan langsung dari pengguna atau narasumber. Metode ini 
digunakan  karena  narasumber  yang  berjumlah  3  orang 
sehingga  kurang  efektif  jika  menggunakan  metode  evaluasi 
berbasis  survei.  Hasil  dari  evaluasi  akan  digunakan  sebagai 
bahan untuk pengembangan siklus berikutnya. 

Gambar 2. Diagram alur kerangka pikir 

VI. HASIL DAN PEMBAHASAN 

Hasil yang dilampirkan pada makalah ini adalah hasil dari 

penelitian siklus kedua. 
A.  Memahami dan Menentukan Konteks Penggunaan 

a)  Deskripsi Sistem 
Aplikasi  reviu  laporan  keuangan  adalah  aplikasi  yang 
digunakan  sebagai  sarana  reviu  laporan  keuangan  seluruh 
satuan  kerja  Badan  Pusat  Statistik.  Aplikasi  ini  digunakan 
sebagai protal untuk proses auditor internal laporan keuangan 
instansi BPS oleh Insektorat Utama sebelum dilaporkan kepada 
Badan  Pemeriksa  Keuangan.  Aplikasi  ini  memuat  prosedur 
analitis, kertas kerja tim pereviu, serta kertas kerja tindak lanjut. 

V.  KERANGKA PIKIR 

Gambaran  alur  pemikiran  peneliti  dalam  melakukan 
penelitian dijelaskan pada gambar 2. Diawali dengan analisis 

b)  Ruang Lingkup Sistem 
Aplikasi  Reviu  Laporan  Keuangan  merupakan  aplikasi 
berbasis web yang berfungsi untuk memfasilitasi pengumpulan 

 3 / 8 

 
 
 
laporan  keuangan  oleh  satuan  kerja  BPS  kepada  Inspektorat 
Utama  dalam  rangka  pengawasan  oleh  pihak  internal  BPS. 
Aplikasi ini diharapkan dapat menjadi portal untuk proses reviu 
laporan keuangan dari seluruh satuan kerja BPS. Aplikasi ini 
digunakan  oleh  pegawai  internal  BPS  yaitu  pegawai  satuan 
kerja  yang  bertugas  terkait  laporan  keuangan  satuan  kerja, 
pegawai  BPS  bagian  akuntansi,  serta  tim  pereviu  dan  admin 
dari Inspektorat Utama BPS. 
c)  Daftar Pengguna 
Daftar  pengguna  atau  aktor  dari  sistem  reviu  laporan 

keuangan akan dijelaskan pada tabel 2. 

TABEL 2 

DAFTAR PENGGUNA SISTEM 

Aktor 
(1) 

Admin 

 Satuan Kerja 
(Satker) 

Anggota Tim 
Pereviu 

Ketua Tim 
Pereviu 

Pengendali Teknis 
Tim Pereviu 

reviu 

terkait 

Deskripsi 
(2) 
Merupakan  pegawai  dari  Inspektorat  Utama  BPS 
yang  mempunyai  tugas  untuk  mengalokasikan 
satuan kerja yang akan direviu pada tahun tersebut, 
mengalokasikan  tim  pereviu  untuk  satuan  kerja 
tertentu,  mengatur  daftar  dokumen  sumber  yang 
akan dikumpulkan oleh satuan kerja, serta mengatur 
dokumen  –  dokumen 
laporan 
keuangan. 
Merupakan  pegawai  BPS  tiap  pada  satuan  kerja 
seluruh  Indonesia  yang  mempunyai  tugas  untuk 
mengisi  neraca  percobaan  pada  prosedur  analitis, 
mengumpulkan  dokumen  laporan  keuangan  dan 
dokumen sumber, serta mengisi kertas kerja tindak 
lanjut. 
Merupakan pegawai  Inspektorat  Utama BPS  yang 
mempunyai tugas untuk mengisi kertas kerja reviu 
pada  kolom  anggota  tim  dan  monitoring  kertas 
kerja  tindak  lanjut.  Setiap  tim  terdiri  lebih  dari  1 
anggota tim. 
Merupakan pegawai  Inspektorat  Utama BPS  yang 
mempunyai tugas untuk mengisi kertas kerja reviu 
pada kolom ketua tim dan monitoring kertas kerja 
tindak lanjut. Setiap tim terdiri dari 1 ketua tim. 
Merupakan pegawai  Inspektorat  Utama BPS  yang 
mempunyai tugas untuk mengisi kertas kerja reviu 
pada kolom ketua tim dan monitoring kertas kerja 
tindak lanjut serta memfinalisasinya, mengunggah 
Laporan Hasil Reviu & Tindak Lanjut serta Catatan 
Hasil  Reviu  dan  Tindak  Lanjut.  Setiap  tim  terdiri 
dari 1 pengendali teknis. 

Bagian Akuntansi  Merupakan  pegawai  BPS  bagian  Akuntansi  yang 
mempunyai tugas untuk mengisi kertas kerja tindak 
lanjut pada kolom bagian akuntansi. 

Mengelola 
Pengguna 

d)  Analisis Sistem Berjalan 
Dari  analisis  sistem  berjalan  dihasilkan  diagram  yang 
menggambarkan  input,  proses,  dan  output  dari  sistem  reviu 
laporan keuangan pada gambar 3. 

Mengelola 
Dokumen Sumber 

Mengisi Prosedur 
Analitis 

Unggah Dokumen 
Laporan Keuangan 
& Dokumen 
Sumber 

Melihat Prosedur 
Analitis 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Gambar 3. Diagram proses bisnis berjalan 

Pada  sistem  yang  telah  ada  saat  ini  proses  bisnis  reviu 
laporan  keuangan  yang  pertama  adalah  user  satker  akan 
mengisi  prosedur  analitis  pada  bagian  neraca  percobaan, 
mengunggah  dokumen  sumber,  serta  mengunggah  dokumen 
laporan  keuangan.  Neraca  percobaan  diolah  secara  otomatis 
menjadi  Laporan  Operasional,  Laporan  Realisasi  Anggaran 
Pendapatan  dan  Belanja,  Laporan  Perubahan  Ekuitas,  serta 
Neraca.  Lalu  tim  pereviu  akan  melakukan  reviu  berjenjang 
pada kertas kerja reviu. Setelah itu akan dihasilkan kertas kerja 
tindak  lanjut  yang  berfungsi  untuk  menindaklanjuti  reviu 
laporan  keuangan,  diisi  oleh  satker,  bagian  akuntansi,  serta 
direviu lagi oleh tim pereviu. Pada akhirnya akan menghasilkan 
output  Laporan  Hasil  Reviu  dan  Tindak  Lanjut  serta  Catatan 
Hasil Reviu dan Tindak Lanjut. 
B.  Menentukan Kebutuhan Pengguna dan Organisasi 

a)  Analisis Kebutuhan Fungsional 
Daftar kebutuhan fungsional sistem akan dijelaskan pada 

tabel 3. 

Fitur 
(1) 

Login 

TABEL 3 
KEBUTUHAN FUNGSIONAL SISTEM 
Keterangan 
(2) 
Halaman yang berfungsi sebagai pintu masuk atau 
proses  pengaturan  identifikasi  pengguna  dan 
memberikan  akses  penuh  terhadap  pengguna 
sesuai role masing – masing dengan fitur  Single 
Sign On (SSO). 
Halaman untuk mengelola daftar pengguna sistem 
baik  pengguna  dari  satuan  kerja  maupun  tim 
pereviu oleh admin. 
Halaman untuk mengelola dafar dokumen sumber 
yang dikumpulkan oleh satuan kerja. 

Halaman untuk mengisi prosedur analitis. 

Halaman  untuk  mengunggah  dokumen  sumber 
dan dokumen laporan keuangan satuan kerja BPS. 

Halaman  untuk  melihat  Prosedur  Analitis  serta 
dokumen laporan keuangan dan dokumen sumber 
bagi bagian akuntansi. 

 4 / 8 

 
 
 
 
 
Mengisi Kertas 
Kerja Reviu 

Catatan Hasil Reviu 
& Laporan Hasil 
Reviu 

Unggah LHR & 
CHR 

Halaman untuk mengisi kertas kerja tim pereviu. 
Dilakukan  reviu  secara  berjenjang  oleh  anggota 
tim, ketua tim, serta pengendali teknis. 
Halaman  untuk  menampilkan  Catatan  Hasil 
Reviu  dan  Laporan  Hasil  reviu  yang  terbuat 
secara  otomatis  dari  kertas  kerja  reviu.  Dapat 
melakukan unduh dokumen. 
Halaman  untuk  mengunggah  file  Laporan  Hasil 
Reviu dan Catatan Hasil Reviu bagi tim pereviu. 

Mengisi Kertas 
Kerja Tindak Lanjut 

Halaman untuk mengisi kertas kerja tindak lanjut 
bagi satker, tim pereviu, dan bagian akuntansi. 

Catatan Tindak 
Lanjut & Laporan 
Tindak Lanjut 

Halaman  untuk  menampilkan  Catatan  Tindak 
Lanjut  dan  Laporan  Tindak  Lanjut  yang  terbuat 
secara  otomatis  dari  kertas  kerja  tindak  lanjut. 
Dapat melakukan unduh dokumen. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Unggah LTL & 
CTL 

Dokumen Pedoman 

Monitoring 

Halaman untuk mengunggah file Laporan Tindak 
Lanjut  dan  Catatan  Tindak  Lanjut  bagi  tim 
pereviu. 
Halaman  untuk  mengelola  dokumen  daftar 
dokumen  pedoman  bagi  admin,  serta  melihat  & 
mengunduh dokumen pedoman bagi user lain. 
Halaman  untuk  melihat  monitoring  progres 
pengisian  prosedur  analitis,  kertas  kerja  reviu, 
maupun tindak lanjut. 

b)  User Access Matrix 
User  Acess  Matrix  atau  tabel  yang  menjelaskan  tentang 

akses pengguna akan dijelaskan pada tabel 4.  

TABEL 4 
USER ACCESS MATRIX 

Admin 

Satker 

Anggota 
Tim 
Pereviu 

Ketua Tim 
Pereviu 

Pengendali Teknis Tim 
Pereviu 

Bagian Akuntansi 

R 
C,R,U,D 

C,R,U,D 

Login 
Mengelola Pengguna 

Mengelola Dokumen 
Sumber 
Prosedur Analitis 

Dokumen Sumber 

Kertas Kerja Reviu 

Catatan Hasil Reviu & 
Laporan Hasil Reviu 
Unggah LHR & CHR 

Kertas Kerja Tindak 
Lanjut 
Catatan Tindak Lanjut & 
Laporan Tindak Lanjut 
Unggah LHTL & CHTL 

Dokumen Pedoman 

C,R,U,D 

Monitoring 

R 

R 

R 

R 

R 

R 

R,U 

R,U,D 

R 

R,U 

R 

R,U 

R 

R,U 

R 

R,U 

R 

R,U 

R,U 

R,U 

R 

R 

R 

R 

R 

R 

R 

R 

R 

R,U 

R 

R,U 

R 

U,D 

R,U 

R 

U,D 

R 

R 

R,U 

R 

Keterangan: C = Create, R = Read, U = Update, D = Delete 

c)  Business Needs (Keperluan Bisnis) 
Sistem reviu laporan keuangan ini dibangun untuk : 

1.  Menyediakan proses pengisian prosedur analitis untuk 

satuan kerja BPS dan tim pereviu. 

2.  Mengumpulkan 

laporan  keuangan  dan  dokumen 

pendukung dari seluruh satuan kerja BPS. 

3.  Menyediakan  proses  reviu  laporan  keuangan  dari 

seluruh satuan kerja BPS untuk tim pereviu. 

4.  Menyediakan  proses  tindak  lanjut  hasil  reviu  untuk 

satker, tim akuntasi, dan tim pereviu. 

5.  Menyediakan  monitoring  progres  pengisian  kertas 
kerja  oleh  satuan  kerja  dan  progres  reviu  laporan 
keuagan. 

6.  Mengumpulkan  file  dan  dokumen  terkait  laporan 

keuangan. 

7.  Meningkatkan keamanan data laporan keuangan, data 
hanya dapat di akses oleh pihak yang berkepentingan 

d)  Diagram Use Case 
Pada  bagian  ini  terdapat  perubahan  yang  disebabkan 
berubahnya  istilah  Kertas  Kerja  Satker  menjadi  Prosedur 
Analitis dan menu Catatan Hasil Reviu yang digabung dengan 
Laporan Hasil Reviu, serta menu Catatan Tindak Lanjut yang 
digabung  dengan  Laporan  Tindak  Lanjut.  Sehingga  use  case 
yang awalnya mempunyai 15 fungsi utama menjadi 13 fungsi 
utama. Diagram use case ditunjukkan oleh gambar 4. 

 5 / 8 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Gambar 5. Activity diagram mengisi kertas kerja reviu 

Gambar 6. Sequence diagram mengisi kertas kerja reviu 

•  Mengunggah Neraca Percobaan 

Gambar 7. Activity diagram mengunggah neraca percobaan 

 6 / 8 

Gambar 4. Diagram use case 

a)  Diagram Proses Bisnis dan Sequence Diagram 

Berikut adalah cuplikan dari diagram proses bisnis (activity 

diagram) & sequence diagram untuk siklus kedua. 

•  Mengisi Kertas Kerja Reviu 

Gambar  5  menunjukkan  diagram  proses  bisnis  mengisi 
kertas  kerja  reviu  untuk  pengguna  tim  pereviu.  Proses 
pengisian  kertas  kerja  reviu  dimulai  dari  anggota  tim  yang 
mengisi  keterangan  penjelasan  lalu  mengirim  ke  ketua  tim 
untuk dilakukan reviu berjenjang. Selanjutnya ketua tim akan 
mereviu  keterangan  penjelasan  dari  anggota  tim,  membuat 
kesimpulan,  lalu  mengirim kertas  kerja  ke  pengendali  teknis. 
teknis  bertugas  untuk  mereviu  keterangan 
Pengendali 
penjelasan  dan  kesimpulan  oleh  anggota  tim  dan  ketua  tim, 
membuat rekomendasi, serta finalisasi proses reviu dengan klik 
tombol selesai. Untuk sequence diagram mengisi kertas kerja 
reviu ditunjukkan pada gambar 6. 

 
 
 
 
 
 
 
 
Gambar 7 menunjukkan diagram proses mengunggah neraca 
percobaan  untuk  pengguna  satker.  Pengguna  membuka 
halaman isi prosedur analitis, kemudian memilih sheet neraca 
percobaan.  Setelah  itu  pada  form  unggah  file,  pengguna 
memilih  file  output  aplikasi  monsakti  yang  akan  diunggah 
dengan format excel yang ditentukan. Jika file yang diunggah 
memiliki  format  yang  sesuai  maka  data  neraca  percobaan 
berhasil diisi, namun jika format tidak sesuai maka data neraca 
percobaan gagal untuk diisi. Untuk sequence diagram unggah 
neraca percobaan ditunjukkan pada gambar 8. 

Gambar 8. Sequence diagram mengunggah neraca percobaan 

C.  Pengembangan Solusi Desain 

Perancangan wireframe dan prototipe disusun berdasarkan 
tahapan UCD yang ketiga yaitu Pengembangan Solusi Desain. 
Wireframe ini merupakan gambaran tampilan antarmuka yang 
masih kasar sebelum dilakukan perancangan prototipe aplikasi 
berbasis  web.  Prototipe  aplikasi  berbasis  web  dirancang 
menggunakan  framework  PHP  yaitu  Laravel  versi  9.52.4, 
framework  CSS  TailwindCSS  versi  3.2.7,  serta 
library 
komponen  UI  TailwindCSS  Flowbite  versi  1.6.4.  Berikut 
adalah cuplikan dari wireframe dan prototipe aplikasi. 

a)  Halaman Isi Prosedur Analitis 
Halaman 

isi  prosedur  analitis  adalah  halaman  yang 
digunakan oleh satker untuk mengisi neraca percobaan dengan 
mengunggah  output  aplikasi  MonSakti  yang  nantinya  secara 
otomatis  akan  diolah  menjadi  laporan  keuangan  (LO,  LRA, 
LPE, Neraca) dan tim pereviu mengisi tabel di prosedur analitis. 
Pada halaman ini pengguna bisa berpindah – pindah sheet atau 
tabel  pada  halaman  yang  sama.  Wireframe  dan  prototipe 
halaman isi prosedur analitis bisa dilihat pada gambar 9, 10, dan 
11. 

D.  Evaluasi Desain 

Setelah  melakukan  revisi  pada  FSD  dan  prototipe  sesuai 
permintaan  narasumber,  maka  siklus  kedua  dapat  dikatakan 
selesai.  Namun  masih 
terdapat  beberapa  masukan  dari 
narasumber  yaitu  untuk  membuat  pseudocode  pada  proses 
validasi  neraca  percobaan  dan  membuat  rancangan  tabel 
monitoring. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

Gambar 9. Wireframe isi prosedur analitis 

Gambar 10. Prototipe isi prosedur analitis (1) 

Gambar 11. Prototipe isi prosedur analitis (2) 

VII. 

PENUTUP 

Berdasarkan  penelitian yang telah dilakukan dapat diambil 

beberapa kesimpulan antara lain: 
1. Telah dilakukan penelitian tentang analisis kebutuhan dan 
perancangan  prototipe  Aplikasi  Reviu  Laporan  Keuangan 
dengan menggunakan metode User Centered Design dalam 
dua siklus. Setelah selesai melakukan siklus pertama hingga 
tahap evaluasi desain, maka dilakukan siklus kedua dengan 
mengulang keseluruhan tahap pada metode penelitian. 
2. Telah  mendokumentasikan  hasil  analisis  kebutuhan  yang 
berupa  Deskripsi  Sistem,  Ruang  Lingkup  Sistem,  Daftar 
Pengguna,  Analisis  Sistem  Berjalan,  Analisis  Kebutuhan 
Fungsional, User Acces Matrix, Business Needs (Keperluan 
Bisnis),  Diagram  Use  Case,  Diagram  Proses  Bisnis 
(Activity  Diagram),  dan  Sequence  Diagram  ke  dalam 
Product  Requirement  Document  (PRD)  dan  Functional 
Specification Development (FSD). 

 7 / 8 

 
 
 
 
 
 
 
 
 
 
 
3. Telah 

dilakukan 

dan 
perancangan 
pengembangan prototipe aplikasi berbasis web berdasarkan 
hasil  analisis  kebutuhan,  kemudian  mendokumentasikan 
hasilnya  ke  dalam  Functional  Specification  Development 
(FSD). 

wireframe 

4. Telah dilakukan evaluasi terhadap hasil analisis kebutuhan 
dan prototipe aplikasi dalam siklus pertama maupun siklus 
kedua. Evaluasi dilakukan dengan cara menunjukkan hasil 
secara 
langsung  kepada  narasumber  dan  menerima 
masukan untuk perbaikan serta pengembangan selanjutnya. 
Hasil  dari  penelitian  ini  masih  belum  sempurna  dan 
mempunyai  banyak  kekurangan.  Berdasarkan  hasil  evaluasi 
siklus  kedua  dan  keterbatasan  penelitian  maka  dapat  disusun 
saran untuk penelitian selanjutnya: 

1.  Membuat  pseudocode  untuk  proses  validasi  neraca 

percobaan pada fungsi prosedur analitis. 

2.  Membuat rancangan tabel monitoring untuk menentukan 

tampilan pada menu monitoring. 

3.  Merancang  basis  data  untuk  menyimpan  data  prosedur 
analitis,  kertas  kerja  reviu,  kertas  kerja  tindak  lanjut, 
daftar pengguna, serta fungsi lain yang memerlukan basis 
data. 

4.  Menjalankan  fungsi  –  fungsi  aplikasi  yang 

telah 

disebutkan pada hasil penelitian. 

DAFTAR PUSTAKA 
[1]  Pemerintah  Indonesia  (2003),  “Undang-Undang  Republik 
Indonesia  Nomor  17  Tahun  2003  tentang  Keuangan 
Negara”. 

[2]  Y.  A.  Rahman,  E.  D.  Wahyuni,  and  D.  S.  Pradana, 
“Rancang Bangun Prototype Sistem Informasi Manajemen 
Program Studi Informatika Menggunakan Pendekatan User 
Centered  Design,”  J.  Repos.,  vol.  2,  no.  4,  pp.  503–510, 
2020,  

[3]  I.  K.  Resika  Arthana,  G.  R.  Dantes,  L.  J.  E.  Dewi,  K. 
Setemen,  and  N.  W.  Marti,  “Pengembangan  Prototype 
Frequently  Asked  Question  (Faq)  Undiksha  Dengan 
Pendekatan  User  Centered  Design,”  J.  Pendidik.  Teknol. 
dan Kejuru., vol. 18, no. 1, p. 77, 2021,  

[4]  Muh.  Shamad.  (2017).  Pembangunan  Sistem  Informasi 
Manajemen  Administrasi,  Monitoring,  dan  Evaluasi 
Anggara STIS. Jakarta:Politeknik Statistika STIS. 

[5]  T.  Jokela,  N.  Iivari,  J.  Matero,  and  M.  Karukka,  “The 
standard of user-centered design and the standard definition 
of usability: Analyzing ISO 13407 against ISO 9241-11,” 
ACM Int. Conf. Proceeding Ser., vol. 46, pp. 53–60, 2003. 

Makalah Sidang Skripsi – Program Studi D-IV Komputasi Statistik 

 8 / 8 

 
 
 
 
 
","2023-12-19T09:14:45.824621Z",221910696,"[{""start"":1018,""end"":1131,""text"":""oran ke"",""labels"":[""Tujuan""]},{""start"":1450,""end"":1578,""text"":"""",""labels"":[""Temuan""]},{""start"":8858,""end"":8895,""text"":"""",""labels"":[""Metode""]}]",1736.821,"2023-12-19T09:39:36.396817Z"
